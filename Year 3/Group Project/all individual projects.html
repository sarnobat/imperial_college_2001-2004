<?xml version="1.0" encoding="iso-8859-1"?>
<!DOCTYPE html
	PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
	 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US"><head><title>Undergraduate Proposals List</title>
</head><body bgcolor="#FFFFFF"><CENTER>
<H2>Undergraduate Proposals List</H2><HR><BR>
</CENTER><BR>
<!-- about to run query "SELECT Ref,Supervisor,Title,LastModified FROM project WHERE Display='Y' AND (Level='Undergraduate' OR Level='Both' OR Level='Any student')  ORDER BY LastModified Desc"-->
<CENTER><H2>A Bottleneck Search Tool</H2></CENTER>
<B>Supervisor:</B>Tony Field and Andy Cheadle<BR>
<B>Room No.:</B>376<BR>
<B>E-mail:</B><A HREF="mailto:ajf@doc.ic.ac.uk">ajf@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>

Understanding the performance characteristics of application software is becoming

increasingly important, particularly as software size and complexity increases along

with the supporting compilers, run-time systems and underlying system architecture.



Many tools exist that assist in or automate the search for performance bottlenecks and

no matter whether sample-based (stop the PC at fixed intervals and tell me where you

are) or instrumentation-based (tell me every time you reach this point in the program),

the amount of diagnostic data created is often overwhelming. In addition, the tools

available for the analysis of the data are often primitive or language- architecture- or
even window-manager dependent.


<BR><BR>
The aim of this project is to create a generic framework for the collection and

visualisation of a range of performance metrics from a range of bottleneck search

tools, with an emphasis on scalability and data presentation. The system will ideally

be capable of processing traces generated a priori (offline) and interactively (online),

handling sample- and instrumentation-based metrics, displaying program callgraphs,

updating histogram and scatter plots in real time, aggregating data and creating

summary statistics. The model should be of a client generating a trace that is fed to a

server that will do the trace analysis and visualisation.  The communication between

client and server will require a generic data exchange format that is simple and

efficient and that can be used to collect data from such tools as JVMPI, JUDI,

TaskGraph, gprof, hprof, cachegrind/valgrind, PAPI and Rabbit.  The metrics

collected must not however be limited to time, memory usage or cache metrics.



A well designed and developed solution would potentially make use of the following

technologies:



*  Java for portability and GUI construction (this is not a simple GUI; it must be slick,

fast and scalable!)



*  Networking protocols (must you use TCP or is UDP an option?) and client-server

communication.



Extensions might include:



*  Data stream compression techniques



*  Callgraph construction from Java class files



*  Bytecode rewriting for instrumentation insertion



To demonstrate the generic applicability of the tool and ease of integration, you

should aim to have working interfaces for perhaps JVMPI, PAPI and h/gprof.



To wet your appetite, look at the slickness of Kcachegrind and Calltree, could you

better it in Java?




<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>A New Programming Language for Business Applications</H2></CENTER>
<B>Supervisor:</B>Tony Field<BR>
<B>Room No.:</B>376<BR>
<B>E-mail:</B><A HREF="mailto:ajf@doc.ic.ac.uk">ajf@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>
Fancy implementing a new programming language?  I have been in contact with David Beddington who has produced a language proposal called ASL.  The details can be found at http://www.doc.ic.ac.uk/~ajf/Public/Language.doc.
<BR><BR>
If you're looking for a language implementation project this could be for you.  As far as I know the ideas are unpublished, but the language is well thought through and is based on many years of industrial experience with business applications.  The project will evaluate the language and will constructa prototype implementation (probably of a subset to start with) of the language.
<BR><BR>
I am happy to supervise this project with David Beddington acting as an external co-supervisor.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Image mosaicing from video sequences </H2></CENTER>
<B>Supervisor:</B>Guang-Zhong Yang<BR>
<B>Room No.:</B>374<BR>
<B>E-mail:</B><A HREF="mailto:gzy@doc.ic.ac.uk">gzy@doc.ic.ac.uk</A><BR>
<HR><BR>Building 3D image mosaic from tracked video sequences<BR>
<HR><BR>Image mosaicing is a process of transforming, wrapping and blending multiple images from different view points into a common coordinate system.  The purpose of this project is to extend the current static image mosaicing for video series. The project involves real-time 3D video tracking, image registration and warping, and is suited for students with reasonable background in image manipulation and a strong mathematical and programming background.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Bronchoscopy Navigation System</H2></CENTER>
<B>Supervisor:</B>Guang-Zhong Yang<BR>
<B>Room No.:</B>374<BR>
<B>E-mail:</B><A HREF="mailto:gzy@doc.ic.ac.uk">gzy@doc.ic.ac.uk</A><BR>
<HR><BR>Building an interactive navigation for bronchoscopy simulation which involves modelling, photorealistic rendering, navigation and collision detection.<BR>
<HR><BR>Bronchoscopy is a minimally invasive medical procedure to examine and treat problems of the respiratory tract. This project involves the development of an interactive navigation system for 3D bronchoscopy data obtained from real patients via computed tomography and bronchoscopy video. An important and necessary feature of the navigation system is a method for planning a relevant path to follow through the data set. This requires that a suitable collision detection system be implemented that will operate on large datasets at interactive rates. 

Requires very good programming skills and solid background in graphics. Further details: http://www.doc.ic.ac.uk/~ajchung/bronchoscopy_navigation.html
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Flexible Execution for Java</H2></CENTER>
<B>Supervisor:</B>Sophia Drossopoulou<BR>
<B>Room No.:</B>559<BR>
<B>E-mail:</B><A HREF="mailto:scd@doc.ic.ac.uk">scd@doc.ic.ac.uk</A><BR>
<HR><BR>To produce more flexible execution of Java, which defer linking to an even later stage than currently done.<BR>
<HR><BR><p align="justify">
Java compilation  is less flexible than Java linking, because
compilation takes place in the context of some classes, which
however may be different form the classes in which execution
(and thus also linking will take place), cf a sequence of
examples given in
<a href="http://joint.org/use2002/sub/drossopoulou-Manifestations.pdf">http://joint.org/use2002/sub/drossopoulou-Manifestations.pdf</a>
</p>

<p align="justify">
The expectations from used classes are hard coded in the
compiled class by the compiler. Thus e.g., if we compile
</p>

<p>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new A().m( new B(). f)
</p>

<p>
in an environment where class A has a method m which expects
an argument of class D, and class B has a field f of class D,
then these expectations will be hard coded in the code, and will not
allow the code to run in an environment where class A has a method m 
which expects an argument of class C, and class B has a field f of class C.
</p>

<p align="justify">
These issues are discussed in work in progress in
<a href=" http://www.doc.ic.ac.uk/~scd/PermissiveSepCompi/PermissiveCompilation2.pdf"> http://www.doc.ic.ac.uk/~scd/PermissiveSepCompi/PermissiveCompilation2.pdf</a>
</p>

<p align="justify">

The aim of the  project would be to develop a prototype
for such a permissive JVM, which
links in the classes as lazily as possible. This could be
done either by writing  JVM from scratch, or by
modifying the SUN  JVM.
</p>
<p> As an extension, the student could also develop the corresponding Java compiler.
<p>
The ideas are currently under development. The student
 would have the opportunity to contribute to thair development
- if they want to.
<p>
The project is a mixture of implementation and research.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Automatic  Wrapper Induction: Automatic Spider Training for Information Extraction from Web Sources</H2></CENTER>
<B>Supervisor:</B>Moustafa M Ghanem<BR>
<B>Room No.:</B>358<BR>
<B>E-mail:</B><A HREF="mailto:mmg@doc.ic.ac.uk">mmg@doc.ic.ac.uk</A><BR>
<HR><BR>Design and implement a trainable tool that automatically extracts specified information from multiple web pages.<BR>
<HR><BR>Imagine you need to do a comparative study between different products 
(Shares (Stocks), Cars, Books, Restaurants or anything really). 
Your aim is to compare the specs, features and prices. 
<br><br>
Most of this information is publically available over the web through an html interface on many sites. This is good for display purposes, but not for automatic information extraction, where you may want to collect information from these different web sources and put it in a structured form for automatic analysis.
<br><br>
You can collect the information manually, going to each web page and cutting and pasting the required information. With a lot of information to cut and past, you may decide to write some specialised spider that autoamtically downloads the pages and extract the required information. This is typically a couple just a few parsing rules in terms of the html structure of document. --- But with a large number of web sites to connect to and extract information from, you have to hand tune the spider (or effectively re-writing it) for each new source. 
<br><br>
Imagine this scenario: You go to the web page and click on the text on the screen and label them ("Product Name", "Description", "Price", etc). Your repeat this process over a couple of pages to train the system, which can now generate the parsing rules automatically and thus generating spider code for you.
<br><br>

Skills: Java, XML

<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Interactive GIS / Data Mining for Air Pollution Data</H2></CENTER>
<B>Supervisor:</B>Moustafa M Ghanem<BR>
<B>Room No.:</B>358<BR>
<B>E-mail:</B><A HREF="mailto:mmg@doc.ic.ac.uk">mmg@doc.ic.ac.uk</A><BR>
<HR><BR>Design and develop an integrated GIS/data mining system for Air Pollution Data Mining<BR>
<HR><BR>Interactive map systems (Geographic Information Systems) are a useful tool for the displaying data arising in many scientific applications. Integrating GIS with data mining systems allows users to analyze and identify complex dependencies and patterns in their data sets and display them in the context of a map, and also allows them to use the map as front-end for driving complex data mining procedures. In many cases the data to be analyzed is not held centrally but distributed over the Internet either in public databases or remote proprietary databases.
<br><br>
Examples of such scientific applications are environmental modeling where air pollution data and traffic patterns are co-analyzed over a map. Examples also include geo-hazard prediction are integrating a map, satellite & radar images and information about landslides. Other examples arise in epidemiology for identifying disease patterns and studying their causing factors. 
<br><br>
In this project you will design an integrated and scalable GIS data-mining system allowing users to access, display and analyze data from various sources on a map. Your design should include methods for intelligently managing and structuring the data when drilling up/down a map and overlaying it with satellite/radar images. You will also investigate integrating the map system with various data mining algorithms.
<br><br>
You will be provided with various libraries and classes at the beginning of the project including a basic map viewer and various data mining algorithms.
<br><br>
Skills: Java
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Integrated Data Analysis of Biological Data using Co-training and Validation</H2></CENTER>
<B>Supervisor:</B>Moustafa M Ghanem<BR>
<B>Room No.:</B>358<BR>
<B>E-mail:</B><A HREF="mailto:mmg@doc.ic.ac.uk">mmg@doc.ic.ac.uk</A><BR>
<HR><BR>Develop tools to validate patterns in one data set (e.g. gene expression data) by using reference information contained in other data sets (e.g. metabolic pathway data, Medline abstracts, etc) <BR>
<HR><BR>The aim of this project is to build tools and case studies that will allow the validation of patterns found in experimental gene expression data. <br><br>

The approach aims for the integrated analysis of gene expression obtained from experimental results in conjunction with  publically available data sets. By applying standard data analysis techniques to experimental gene expression data, relationships between different genes can be found, e.g. which genes are expressed in each cell line - what are their levels of expression - which gene groups are expressed at the same level - which gene groups display similar variations in expression levels in response to an external stimulus.

<br><br>

Having found these patterns, a researcher is typically interesting in assessing their significance and possibly finding a biological explanation for such patterns. This can be achieved by referencing and analysing information about these genes that is contained in public data set. 

<br><br>

This approach falls nicely within the wider concept in machine learning known as co-training. This project aims to automate the framework and to provide interactive tools that would allow the user to define the required workflow and interaction between the data sets and databases of interest.

<br><br>
Skills Needed: Java. 
<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects.

<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Using text mining to analyze public databases (Automatically Building the Proteome Map)</H2></CENTER>
<B>Supervisor:</B>Moustafa M Ghanem<BR>
<B>Room No.:</B>358<BR>
<B>E-mail:</B><A HREF="mailto:mmg@doc.ic.ac.uk">mmg@doc.ic.ac.uk</A><BR>
<HR><BR>The aim of this project is to develop methods to extract useful information by automatically analyzing public text bases. A specific case study for identifying relationships between different proteins by analyzing Medline abstracts is to be conducted based on the developed methods.<BR>
<HR><BR>Proteins play a crucial role in nearly all biological processes from how our ears are shaped to immune protection and intracellular signaling. The role a protein plays is dependant not only on its chemical definition but also on its interactions with other proteins and enzymes.  With thousands of available proteins and enzymes, a full map describing interactions is not currently available.
<br><br>
This project aims to develop a tool that can build such relationships by automatically analyzing text documents that contain references to such relationships. For example, the Medline database holds research publications in the area of medicine and biology. These publications provide a wealth of knowledge since they typically document the results of disparate researchers and may include sentences such as
<br>
Enzyme A catalyzes Protein B.
<br>
Protein B inhibits Protein C.
<br><br>
The project involves the application and development of text mining and simple natural language parsing tools. Typically there is a list of known protein names (and their synonyms), and a list of interaction verbs (and their natural language grammatical variations). Your tool should be able to cope with these variations and as an output produce a protein-protein interaction map.
<br><br>
Ideas for extensions include developing either more complex natural language parsing or statistical methods to find out the conditions under which the interactions occur.
<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Image Mining Applications</H2></CENTER>
<B>Supervisor:</B>Moustafa M Ghanem<BR>
<B>Room No.:</B>358<BR>
<B>E-mail:</B><A HREF="mailto:mmg@doc.ic.ac.uk">mmg@doc.ic.ac.uk</A><BR>
<HR><BR>Develop automatic image analysis and feature extraction tools.<BR>
<HR><BR>Image analysis and mining has a wide range of application including medical diagnostics. The goal of this project is to be able to automatically extract features from images that can be used in classifying and clustering such images.
<br><br>
This is a very challenging project that will build on existing work. You are expected to be an independent student, innovative student who is already interested in the subject.

<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>PPI: Protein-protein interactions</H2></CENTER>
<B>Supervisor:</B>Moustafa M Ghanem<BR>
<B>Room No.:</B>358<BR>
<B>E-mail:</B><A HREF="mailto:mmg@doc.ic.ac.uk">mmg@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR><p>The aim of this project is to produce a browser that searches the web for PPIs given a single protein as input. It will go to chosen web servers, and return a list of proteins known or conjectured to interact with that protein. Then the user will be able to query every PPI, and return to the source HTML (or text) page to review the associated data. Every protein in a living cell will interact with a variety of others, and the network of proteins functions like the parts of a car, each with its own function. The list of PPIs will be incomplete for some time to come, but accessing the available data for proteins as they occur in different organisms is crucial to our current understanding of disease and normal cell processes.</p>

<p><b>Required:</b> Java, GET and POST CGI scripting desirable</p>
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Interactive graphical user interface for the analysis of data from petroleum data wells</H2></CENTER>
<B>Supervisor:</B>Moustafa M Ghanem<BR>
<B>Room No.:</B>358<BR>
<B>E-mail:</B><A HREF="mailto:mmg@doc.ic.ac.uk">mmg@doc.ic.ac.uk</A><BR>
<HR><BR>The aim of this project is to develop a graphical user interface for
an existing C program which analyzes well test data from petroleum
wells. The interface should run on both Windows 2000/XP and Linux and
should allow display and graphical editing of data and analysis and allow the user to intutively drive the parameter settings of the program.<BR>
<HR><BR>This project is co-supervised with Thomas von Schroeter from the Earths Sciences Department.
<br><br>
When hydrocarbons are produced from a reservoir at constant flow rate,
the reservoir pressure drops over time in a fashion characteristic of
the geometry and material properties of the reservoir and fluid. The
analysis of this pressure behaviour is routinely used in Petroleum
Engineering in order to characterize the dynamic properties of a
reservoir.
<br>
In practice, it is rarely possible or desirable to produce a
reservoir at constant rate. Instead, one records the flow rate and the
pressure over time, and computes from these two signals an estimate of
what the pressure signal would have been had the reservoir been
produced at constant rate. This is roughly what the C program already
does. (Mathematically speaking, this is a deconvolution problem.)
<br>
The quality of the estimate can be assessed in various ways. The most
important one is to graphically compare the measured pressure signal
with the one obtained from the model estimate. There are also various
ways to estimate bias and variance of the result.
<br>
The main task of the project is the development of a user interface
with the functionality to carry out all these steps interactively and
repeatedly, and display the results in a meaningful way. In
particular, it is important that the input data can be edited in
graphical mode in order to remove outliers, insert missing rate
periods, etc. This is also desirable for the solution, in order to allow the
user to restart the algorithm with an initial guess different from the
default. 
<br>
Ideas for extensions include implementing a set of model type curves
based on specific reservoir geometries, and algorithms which fit their
parameters to the data as well as to the response estimate. 
<br>
The resulting software must be well documented in order to allow
future modifications. 
<br>
<br>
Required:Java,C/C++ for extensions,Maths/Physics background desirable
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Seismic Data Mining for Oil & Gas exploration</H2></CENTER>
<B>Supervisor:</B>Moustafa M Ghanem<BR>
<B>Room No.:</B>358<BR>
<B>E-mail:</B><A HREF="mailto:mmg@doc.ic.ac.uk">mmg@doc.ic.ac.uk</A><BR>
<HR><BR>Develop a data analysis and pattern matching tool for analysing seismic data.<BR>
<HR><BR>Analysis of seismic data gives earth scientists and data specialists their first clues as to the whereabouts of valuable resource locations including Oil & Gas. 
<br>
Sesimic scans generate huge 4-dimensional data sets (X, Y, T, V), where X, Y are co-ordinates of a location, T is time and V is the value measured. Using pattern recognition and data mining techniques, the goal of the project is to develop a tool that to automatically analyse and find interesting data patterns both temporaly and spatially in the available data sets. Your tools should have a friendly user interface to allow a data analyst to interpret the individual patters and find correlations between different patterns. Additionally, since the data sets can be massive developing an efficient implementation for such a tools will be your challenge. 
<br>
This can be a very exciting project involving a mixture of data analysis, pattern recognition, image analysis, databases, etc.
<br>
A background in engineering is an asset.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Automatic Information Extraction from Text Documents Challenge</H2></CENTER>
<B>Supervisor:</B>Moustafa M Ghanem<BR>
<B>Room No.:</B>358<BR>
<B>E-mail:</B><A HREF="mailto:mmg@doc.ic.ac.uk">mmg@doc.ic.ac.uk</A><BR>
<HR><BR>Investigate and Implement algorithms for automatic information extraction from text documents<BR>
<HR><BR>What is required is simply described as can you extract useful information from unstructured text documents and put it into a structured form? Example can you automatically browse car ads and populate a database with the car make, type, colour, price and contact detail information. Can you extract information about protein interactions or drug-disease efects by scanning medical publications.
<br><br>
If you are interested in the topic and are a very good student check for the our entry in the KDD CUP competition 2002.
<br>
You will be expected to improve on our results.
<br><br>

The project will be involve using a mixture of NLP, text parsing and statistical techniques.
<br><br>
Skills: Java

<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Automatic Text Classification Challenge</H2></CENTER>
<B>Supervisor:</B>Moustafa M Ghanem<BR>
<B>Room No.:</B>358<BR>
<B>E-mail:</B><A HREF="mailto:mmg@doc.ic.ac.uk">mmg@doc.ic.ac.uk</A><BR>
<HR><BR>Investigate and Implement Automatic Text Classification Algorithms<BR>
<HR><BR>Automatic Text Classification is an important research area that goes beyond information retrieval. Whereas the concept behind the approach may be simple and so is providing an initial prototype, providing a scalable implementation with acceptable run-time performance is challenging. 
<br><br>
If you are interested in the topic and are a very good student check for the our entry in the KDD CUP competition 2002.
<br>
You will be expected to improve on our results.
<br><br>
The project aims to implement a robust and accurate text classifiers. Emphasis is one the software engineering aspects of designing this tool, as well as on their accuracy.

<br><br>
Skills: Java
<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Automatic Interpretation of Bioinformatics Data Analysis Results</H2></CENTER>
<B>Supervisor:</B>Moustafa M Ghanem<BR>
<B>Room No.:</B>358<BR>
<B>E-mail:</B><A HREF="mailto:mmg@doc.ic.ac.uk">mmg@doc.ic.ac.uk</A><BR>
<HR><BR>Design an information retrieval system takes data analysis results and annotates them with known fact from the online databases and literature bases.<BR>
<HR><BR>Scenario: You are scientist who just ran an experiment about the behaviour of some genes as measured by their gene expression profile, you performed some data analysis task and got some results that you display on your screen using some visualisation method. 
<br><br>
You scratch your head and ask yourself what is interesting about this set of results. You press a button and the system tells you: a) I can tell you that most results look normal, the first set of genes in your experiment behave similarly because they are all part of the same metabolic pathway. But it seems that they are behaving contrary to similar results that were previously reported in the literature, you either did something wrong in the experiment or they may be all implicated in the same disease. All other behaviours seem unintersting.
<br><br>

<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Text Mining over Protein Databases</H2></CENTER>
<B>Supervisor:</B>Moustafa M Ghanem<BR>
<B>Room No.:</B>358<BR>
<B>E-mail:</B><A HREF="mailto:mmg@doc.ic.ac.uk">mmg@doc.ic.ac.uk</A><BR>
<HR><BR>Developing Text Mining Tools for Protein Databases<BR>
<HR><BR>Biological research proceeds on the basis of a body of knowledge. Much of a researcher’s time is spend surfing the web (PubMed particularly) and reading papers about proteins that s/he is working on, and protein systems related by function, prior research or even simply on location (the new emphasis is that proteins work in connection with the complete environment in which they are found, and this includes a range of proteins).
<br><br>
This project involves designing a text-mining engine that assimilates paragraphs of data from the published literature, for one protein (others may be included in the search). Maintain tags to the URLs, and permit drilling deeper into the data. If there is time, supply a simple graphical output of all of the proteins found, so that the researcher may have an overview of the results of the text search (initially this can be a list in HTML).
<br><br>
Skills Needed: Java, XML
<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Multi-stage portfolio optimisation</H2></CENTER>
<B>Supervisor:</B>Berc Rustem<BR>
<B>Room No.:</B>370<BR>
<B>E-mail:</B><A HREF="mailto:br@doc.ic.ac.uk">br@doc.ic.ac.uk</A><BR>
<HR><BR>Classical single period mean-variance optimisation or mean-downside risk optimisation generalised to optimal portfolio decisions over two or three periods.<BR>
<HR><BR>The existence of transaction costs means that repeated application of a single period optimal decision may not be optimal in a multi-stage setting. Unnecessary transaction costs may be involved if one needs to sell some of the stocks (just purchased) at the end of the period in order to improve portfolio performance in the next stage. An optimal decision will need to take into account of all the periods and optimise the portfolio position for all stages given that transaction costs will be applied if portfolio needs to be rebalanced at any future stage. You will use an off-the-shelf quadratic programming solver and integrate it with a C - like language and design an appropriate GUI to illustrate the investment at every stage. There will be at least two stages.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Mean-variance optimisation with integer variables</H2></CENTER>
<B>Supervisor:</B>Berc Rustem<BR>
<B>Room No.:</B>370<BR>
<B>E-mail:</B><A HREF="mailto:br@doc.ic.ac.uk">br@doc.ic.ac.uk</A><BR>
<HR><BR>To compute the solution of the mean-variance optimisation problem (quadratic programming-QP) for integer variables.<BR>
<HR><BR>The application of the branch-and-bound (b-b) algorithm to QP. You will use an off-the-shelf QP solver and implement the b-b algorithm. You need to address the question of incoropoating a Fortan QP solver with essentially a C or related language. You also need to design an appropriate GUI to exhibit the "efficient" frontier. The GUI needs to be designed so one clicks on the efficient frontier and obtains the best investment decision (all integer numbers of stocks).
Parallelisation of the b-b procedure is an optional extra. Suitable for fourth year projects and any MSc - background permitting. Computing for optimal decisions and/or Advanced Operations Research and Parallel Algorithms are desirable (but not absolutely essential) fourth year courses.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Teaching Software Design</H2></CENTER>
<B>Supervisor:</B>Emil C. Lupu<BR>
<B>Room No.:</B>564<BR>
<B>E-mail:</B><A HREF="mailto:ecl1@doc.ic.ac.uk">ecl1@doc.ic.ac.uk</A><BR>
<HR><BR>To investigate existing tools and develop new means of applying software design techniques which focus on cognitive aspects. <BR>
<HR><BR>Many of the existing software design tools allow drawing multiple UML diagrams, yet few check that the content across diagrams is consistent. 

Many of the software design tools allow for re-factoring, yet few are able to identify new ways of improving design. 

This project aims to review the existing techiniques and propose new ways of improving software desing. <BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Visual Turing machine</H2></CENTER>
<B>Supervisor:</B>Ian Hodkinson<BR>
<B>Room No.:</B>426<BR>
<B>E-mail:</B><A HREF="mailto:imh@doc.ic.ac.uk">imh@doc.ic.ac.uk</A><BR>
<HR><BR>To implement a visual Turing machine simulator to help teach students on the 2nd year algorithms course how to program them. It should therefore be very user-friendly and simple to use, and have copious help. Notation used should conform with the course.
<BR>
<HR><BR><b>I am available to discuss this and my other projects at 1pm on Mondays and 12 noon on Fridays.</b><P>

The proposed software has 3 parts:
<p><b>1.&nbsp; Facility to enter "programs" in a high-level language to
design TMs.</b> Eg.:
<br>
</p>
<pre style="margin-left: 40px;">read curent char into X<br>while current char is not blank<br>&nbsp;&nbsp;&nbsp; move right<br>end while<br>write X<br>halt + succeed</pre>
Basic TM head movements, reads, writes are controlled by conventional
if-then,
while structures.&nbsp; If possible, procedure calls could be
included.&nbsp;
The language should be not too far from the original definition of TM
(see
course notes).
&nbsp;
<p>You will have to design the language, an editor/syntax checker, and
a compiler/interpreter to connect with the second part:
</p>
<p><b>2.&nbsp; Turing machine engine,</b> to assemble a TM from the
output
of part 1 and run it with initial tape contents as specified by the
user.&nbsp;
Screen should show the tape(s) and head position(s) after each
instruction,
animating the TM execution.
</p>
<p>Requirements include:
</p>
<ul>
  <li>Support for multiple tracks and tapes. <br>
  </li>
  <li>Various alphabets (using keyboard characters).
  </li>
</ul>
<p><b>3. Help system.&nbsp;</b> As well as help on using the system,
some
explanation of the nature and purpose of a TM should be included.&nbsp;
This might stretch to including parts of the 2nd year notes, photos and
material from sound archives on Turing - as you will.&nbsp;
</p>
<p><b>Supporting material:</b>
</p>
<p>Sample TMs (eg palindrome detector) should be written and
loadable-in
from files.<br>
If feasible, support for running 2 TMs simultaneously, so as to
illustrate
simulation of 2-tape TM by a 1-tape TM.
<br>
&nbsp;
</p>
<p>Implementation should ideally be in HTML for www use.  You may be able to make the package available for external use as an educational
tool. Advise you compare some other available simulators &amp; see how
they can be improved.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Constraint-guided Enterprise Portal</H2></CENTER>
<B>Supervisor:</B>Frank Kriwaczek<BR>
<B>Room No.:</B>431<BR>
<B>E-mail:</B><A HREF="mailto:frk@doc.ic.ac.uk">frk@doc.ic.ac.uk</A><BR>
<HR><BR>The project involves building tools in a principled fashion for communicating with, analysing and displaying information from a logic-based and constraint-guided workspace portal.<BR>
<HR><BR>The work would build upon and integrate with earlier developments by Hogger, Kriwaczek and Ahmed. The technology would include Prolog and CLP, and might also involve Java or Visual Basic for imploementing the interface. 

This project is suitable for a 4th year MEng or a MAC student.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Solving Rubik cube</H2></CENTER>
<B>Supervisor:</B>Ian Hodkinson<BR>
<B>Room No.:</B>426<BR>
<B>E-mail:</B><A HREF="mailto:imh@doc.ic.ac.uk">imh@doc.ic.ac.uk</A><BR>
<HR><BR>To write software to scramble the Rubik cube and then return it to its original state by legal moves (rotations of faces). <BR>
<HR><BR><b>I am available to discuss this and other projects at 1pm on Mondays and 12 noon on Fridays.</b><p>

The <a href="http://www.rubiks.com/cube_online.html">3x3x3 Rubik cube</a> is
a notoriously difficult 3D puzzle that was very popular a few years
back.&nbsp; This project is to find and implement an algorithm to solve
the puzzle. The software will<br>
<ul>
  <li>randomise the cube,</li>
  <li>calculate a sequence of legal steps to return it to its initial
(solved) state,</li>
  <li>display the cube in colour (<a href="http://www.schubart.net/rc/">here</a>
is one possible approach to this) showing the effect of each step of
the solution.</li>
  <li>The user should be able to interact with the software, by
attempting to solve the cube manually (by inputting moves to
make).&nbsp; The software could provide hints, and rate the quality of
the user's moves.<br>
  </li>
</ul>
The algorithm could use AI search techniques and/or group theory —
working out an algorithm is a major part of the project.&nbsp; Several
different algorithms could be implemented and compared if time allows.<br>
<br>
The project report should include a survey of known methods of solving
the sube, and implementations of them.&nbsp; Project extensions include
doing the same for the 2x2x2, 4x4x4, and 5x5x5 Rubik cubes (or even <a
 href="http://byrden.com/puzzles/Catalogue/BigBoxes.shtml">this one</a>),
and other similar puzzles.
<br><br>
This project was Derek Brough's and I thank him for letting me post it.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>The Self-Managed Cell</H2></CENTER>
<B>Supervisor:</B>Emil C. Lupu<BR>
<B>Room No.:</B>564<BR>
<B>E-mail:</B><A HREF="mailto:ecl1@doc.ic.ac.uk">ecl1@doc.ic.ac.uk</A><BR>
<HR><BR>To develop and implement a prototype of a new paradigm for the management of policy-driven autonomic systems.<BR>
<HR><BR>Traditional network and systems management has focussed on a functional decomposition of management functions such as monitoring, event correlation, or for performing control actions. This approach causes significant problems in terms of clearly attributing management responsibility for managed objects and structuring large scale systems. This project aims to prototype a new framework for network and systems management based on the composition of self-managed (autonomic) administrative domains called managed cells or m-cells for short. This project is based on the latest developments in policy-based systems (including access control), management software such as JDMK and the autonomic computing initiative. 
Suitable for: MEng 4, Distributed Systems required.
<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>A profile of my life</H2></CENTER>
<B>Supervisor:</B>Emil Lupu<BR>
<B>Room No.:</B>564<BR>
<B>E-mail:</B><A HREF="mailto:ecl1@doc.ic.ac.uk">ecl1@doc.ic.ac.uk</A><BR>
<HR><BR>To design an information model and tool support able to capture the activities, context and information of a user during a day of his life.<BR>
<HR><BR>Pervasive computing advocates that computing devices included in objects of our daily life will collaborate in order to make our life easier. This is very difficult if these computers do not have an idea of what our life "profile" is and  therefore cannot anticipate our activities in the next moments. <br>

This project aims to explore how a life profile can be captured and used to anticipate our activities. <br>

Suitable for 4th year and Advanced MSc students. <BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>A contract management framework for ousourced security functions. </H2></CENTER>
<B>Supervisor:</B>Emil C. Lupu<BR>
<B>Room No.:</B>564<BR>
<B>E-mail:</B><A HREF="mailto:ecl1@doc.ic.ac.uk">ecl1@doc.ic.ac.uk</A><BR>
<HR><BR>To design and develop a framework which allows the specification of contracts regarding the provision of security services and the enforcement of the provisions of the contract. Note that this assumes the contract management framework itself is secure.   <BR>
<HR><BR><BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Service discovery in self-managed networks</H2></CENTER>
<B>Supervisor:</B>Emil Lupu<BR>
<B>Room No.:</B>564<BR>
<B>E-mail:</B><A HREF="mailto:ecl1@doc.ic.ac.uk">ecl1@doc.ic.ac.uk</A><BR>
<HR><BR>To investigate current techniques and develop a new framework for using service discovery in self-managed networks. <BR>
<HR><BR>Recently a lot of emphasis has been put towards the development of self-managed (autonomic) networks. This project aims to define a new architecture for self managed networks which identifies the core managed functions that elements must support and relies on service discovery in order to identify the available management services and compose the management framework within a specific domain. <BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>A framework for Agile Security</H2></CENTER>
<B>Supervisor:</B>Emil C. Lupu<BR>
<B>Room No.:</B>564<BR>
<B>E-mail:</B><A HREF="mailto:ecl1@doc.ic.ac.uk">ecl1@doc.ic.ac.uk</A><BR>
<HR><BR>To design and implement a framework for agile security. <BR>
<HR><BR>Security is a process. This is a slogan by which many wise people have started to advocate. Yet there are very few tools that allow to manage security as a process which can adapt to changing circumstances and react according to events occuring in the system. This project aims to take the first steps towards a new generation of security tools which aim to manage security at multiple levels and to adapt the system's security configuration according to changes in circumstances. 
More suitable for 4th year and Advanced MSc students. Good programming level required. <BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Distributed Access control in Virtual organisations</H2></CENTER>
<B>Supervisor:</B>Emil C. Lupu<BR>
<B>Room No.:</B>564<BR>
<B>E-mail:</B><A HREF="mailto:ecl1@doc.ic.ac.uk">ecl1@doc.ic.ac.uk</A><BR>
<HR><BR>The objective is to design and implement a framework for distributed access control in Virtual Organisations.<BR>
<HR><BR>Companies frequently create joint ventures, and collaborate with each other in pursuit of new profit opportunities. This is expected to lead to the creation of "virtual organisations" where, in essence, the newly created company exists only in "cyberspace". The computational and service resources will be provided by the founding organisations. However, this creates numerous problems in terms of enforcing access control to resources and implementing the contracts based on which the virtual organisation was formed. This project will seek to take the first steps towards a solution to this problem. <BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>A collaborative framework for Intrusion Detection and Reaction</H2></CENTER>
<B>Supervisor:</B>Emil C. Lupu<BR>
<B>Room No.:</B>564<BR>
<B>E-mail:</B><A HREF="mailto:e.c.lupu@imperial.ac.uk">e.c.lupu@imperial.ac.uk</A><BR>
<HR><BR>The objective of the project is to define and implement an architecture for exhange of intrusion detection information and development of coordinated plans for responding to the intrusion. The framework is particularly aimed at working across organisational boundaries. <BR>
<HR><BR>Most suitable for 4th year and MSc students. Outstanding 3rd year students will be considered. <BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Massively Distributed Cycle Stealing</H2></CENTER>
<B>Supervisor:</B>Moustafa M Ghanem<BR>
<B>Room No.:</B>358<BR>
<B>E-mail:</B><A HREF="mailto:mmg@doc.ic.ac.uk">mmg@doc.ic.ac.uk</A><BR>
<HR><BR>The aim of this project is to develop a robust, high-availability system for the distribution, execution and management computational intensive jobs. The project will require the development of a generic windows “screensaver” component for execution, and a middleware component for job management. <BR>
<HR><BR>Distributed computing is becoming increasingly important as organisations seek to improve the utilisation and production of computer infrastructure. One strategy for distributed computing is to use the unused cycles on many of the organisations PC technology. Example of this type of Cycle stealing approach would be the SETI@home client. There are many examples of parallel computer jobs that can benefit from this type of computing environment including those from bioinformatics or cheminformatics.

The aim of this project is to develop a robust, high-availability system for the distribution, execution and management computational intensive jobs. The project will require the development of a generic windows “screensaver” component for execution, and a middleware component for job management. <BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Implementation of Atoms of Mobile Processes </H2></CENTER>
<B>Supervisor:</B>Nobuko Yoshida<BR>
<B>Room No.:</B>556<BR>
<B>E-mail:</B><A HREF="mailto:yoshida@doc.ic.ac.uk">yoshida@doc.ic.ac.uk</A><BR>
<HR><BR>To learn and implement atoms for concurrent interactive computation. <BR>
<HR><BR>
In the real world, there exists the atoms hypothesis that is
every material can be decomposed into finite elements called atoms.
But are there any atoms for computations?

The aim of this project is to learn and implement
atoms for concurrent interactive
computations. First you will learn about a simple concurrent language
called the pi-calculus
which is similar with CSP taught in Concurrent Programming course.
You will then learn the decomposition rules from the pi-calculus
into concurrent interactive atoms. Finally 
you will implement a graphical toolkit to demonstrate their computation.
One of non-trivial and interesting aspects of this project is
that you can learn the international level concurrency theory
as well as programming for a graphical interface.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>User-Oriented Email Memos, or, ‘Memos By Mail’</H2></CENTER>
<B>Supervisor:</B>Sophia Drossopoulou<BR>
<B>Room No.:</B>559<BR>
<B>E-mail:</B><A HREF="mailto:scd@doc.ic.ac.uk">scd@doc.ic.ac.uk</A><BR>
<HR><BR>To create an email filters that will support activities such as keeping, and publishing address books, logbooks, etc.<BR>
<HR><BR><it> This project has been suggested by Alex Buckley, and also Christopher Anderson. It will be co-supervised by A lex Buckley and Sophia Drossopoulou</it>
<p>
<p>
People in DoC tend to have their email clients open all the time. The easiest and quickest way to electronically make a note of something is to start composing an email. However, hardly anyone tries to use an email client as a personal information management tool because it doesn’t seem natural to start writing an email that you never intend to send to anyone. Plus, a ‘Drafts’ mail folder that’s full of never-sent emails can only be read by the author; sometimes we might want to be more collaborative.
<p>
An alternative - using text files to store snippets of information - is also bothersome: you have to start an editor, remember where you saved your ‘snippets’ file or otherwise think of a filename for a new snippet, set the permissions on a new file so that your friend can see it…and when you’re finished with all that, you can look forward to learning a lot about grep in order to search, sort and summarise.
<p>
<bf>Idea:</bf> When email is sent to memo@doc.ic.ac.uk, a mail filter appends the body of the email to a ‘memo file’ associated with the sender of the email. Each email thus creates a new memo. If the email has a subject, then it can be used to categorise the memo. A Web interface allows the sender to review their memos by date or category.
<p>
This service should be popular because it is user-oriented:
<ul>
<li>
It is very quick to use. Just hit Compose in your email client.
</li><li>
It is very simple to use. Just one field has to be filled out; there’s no form filling, no authentication, no administration.
</li><li>
It embodies the idea that a user’s information is valuable. Email is popular because it turns the ordinarily rather administrative task of typing on a computer into an enjoyable communicative task; you write something and your friend receives and appreciates it. This memo system, with email as its authoring mechanism instead of a work-a-day word processor or a dry Web form, hopes to replicate the ‘fun’ of email: you send a snippet of information into the system, which interprets and stores it safely, and sometimes later the information is read and appreciated (possibly by you alone, possibly by others.)
</li>
</ul>
<p>
<p>
<bf> Design points</bf>
It is very important to keep the system simple. Therefore:
<ul>
<li> The body of an email is expected to be roughly plaintext. When it is presented as a logbook entry on a Web page, it should feature the same line-breaks and layout as the email (e.g. by using the <it>pre</it> tag.) If the sender puts basic HTML tags in their email’s body (e.g. <it>em</it>, <it>strong</it>), then they should carry through to the HTML of the page.
</li> <li>
The subject field can be used to categorise the entry, but there is no pre-defined (either globally or per-user) list of categories. (To keep categories ‘clean’, the logbook mail filter should normalize the subject fields: all lowercase text, no preceding or trailing spaces, no punctuation.)
</li><li>
Security is (probably) orthogonal. While world-readability may be excessive, DoC-only read access may be perfectly acceptable. Alternatively, memos from user X are visible only to user X plus relevant staff.
</li><li>
Basic options for reviewing memos are to categorise by month, by term and by category.
</li><li>
There is a fixed and low limit on the size of the email bodies. This will not be a system you can share uuencoded mp3s with.
</li><li>
There is no write-access to an entry once it has been received by the system.
</li>
</ul>
If we are aiming for a straightforward way to support note-taking from arbitrary locations, we might also consider a Wiki. However, security concerns over server-side scripting languages can lead to CGI environments being disabled rather suddenly. Since email is now ‘mission-critical’, the dependence on, and reliability of, SMTP servers is arguably much higher than Web servers. An email-based system employing server-side mail filters is far more robust.
<p>
<bf>More Ideas</bf>
<ul>
<li>
Specialist subject fields can receive specialist treatment. That is, the system could have some pre-defined subjects for which it understands the content of the email body. Some example ‘specialised memos’:
<l>
Subject: contact
<l>
Body:<l>
170 Queens Gate<l>
London SW7<l>
020 7123 4567
<l>
Subject: paper<l>
Body:<l>
Fibonacci: A Programming Language for Object Databases<p>
Albano, Ghelli, Orsini<l>
<l>
<l>
Subject: meeting<l>
Body:<l>
14th October 2pm<l>
jk<l>
Room 567<l>
<l>
Memos with these subjects might offer extra options when viewed in the Web interface:
<p>
<ul>
<li>A ‘contact’ memo could offer an option to download a .VCF file.
</li><li>A ‘meeting’ memo could offer to email a meeting reminder to the relevant people.
</li><li>A ‘paper’ memo could conduct a Citeseer search for the title, scrape the Bibtex entry and append it to the memo.
</ul><l>
If memo content can be kept fairly standardized, the system could semantically link memos together. Consider:
 <l>
Subject: meeting.actions <l>
Body: <l>
jk 14/10 <l>
Re-draw diagram on page 5. <l>
Decide on abstract class design. <l>
 <l>
Suppose that subject fields with a ‘.’ represent super-specialised memos. Whereas a ‘meeting’ subject indicates a meeting with someone, a ‘meeting.actions’ subject represents the outcome of some meeting. A clever system would inspect the meeting.actions memo, find some who/when/where info on the meeting, and seek out the original meeting memo. The Web interface could then show a link between the meeting and its actions.

</li><li>
Updateable memos
<l>
Although we say that memos are not writeable once submitted, there could be a way to append critical information to them. For example, if you have a meeting with your supervisor and emailed the meeting actions to the system, then you ought to be able to append an action which your supervisor thinks up later that day (and after you’ve emailed.) 
<l></li><li>
<bf>Other ideas</bf>
<l>
<ul>
<li> Integration with a Wiki
</li><li>Two-way memos. Use case: Send in an email with ‘iknow’ in the subject line and your technical competency in the body. When someone sends an email with ‘whoknows’ in the subject and the competency they need help with in the body, the system emails them back with the list of people who said ‘iknow’ that competency.
</ul></ul><BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Visual Turing machine</H2></CENTER>
<B>Supervisor:</B>Ian Hodkinson<BR>
<B>Room No.:</B>426<BR>
<B>E-mail:</B><A HREF="mailto:imh@doc.ic.ac.uk">imh@doc.ic.ac.uk</A><BR>
<HR><BR>To implement a visual Turing machine simulator to help teach students on the 2nd year algorithms course how to program them. It should therefore be very user-friendly and simple to use, and have copious help. Notation used should conform with the course.
<BR>
<HR><BR><span style="font-weight: bold;">I am available to discuss this and
other projects at 1pm on Mondays and 12 noon on Fridays.</span><br>
<br>
The proposed software has 3 parts:
<p><b>1.&nbsp; Facility to enter "programs" in a high-level language to
design TMs.</b> Eg.:
<br>
</p>
<pre style="margin-left: 40px;">read curent char into X<br>while current char is not blank<br>&nbsp;&nbsp;&nbsp; move right<br>end while<br>write X<br>halt + succeed</pre>
Basic TM head movements, reads, writes are controlled by conventional
if-then,
while structures.&nbsp; If possible, procedure calls could be
included.&nbsp;
The language should be not too far from the original definition of TM
(see
course notes).
&nbsp;
<p>You will have to design the language, an editor/syntax checker, and
a compiler/interpreter to connect with the second part:
</p>
<p><b>2.&nbsp; Turing machine engine,</b> to assemble a TM from the
output
of part 1 and run it with initial tape contents as specified by the
user.&nbsp;
Screen should show the tape(s) and head position(s) after each
instruction,
animating the TM execution.
</p>
<p>Requirements include:
</p>
<ul>
  <li>Support for multiple tracks and tapes. <br>
  </li>
  <li>Various alphabets (using keyboard characters). </li>
</ul>
<p><b>3. Help system.&nbsp;</b> As well as help on using the system,
some
explanation of the nature and purpose of a TM should be included.&nbsp;
This might stretch to including parts of the 2nd year notes, photos and
material from sound archives on Turing - as you will.&nbsp;
</p>
<p><b>Supporting material:</b>
</p>
<p>Sample TMs (eg palindrome detector) should be written and
loadable-in
from files.<br>
If feasible, support for running 2 TMs simultaneously, so as to
illustrate
simulation of 2-tape TM by a 1-tape TM.
<br>
&nbsp;
</p>
<p>Implementation should ideally be in HTML for www use. You may be
able to make the package available for external use as an educational
tool. Advise you compare some other available simulators &amp; see how
they can be improved.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Task Sequencing and Visualisation</H2></CENTER>
<B>Supervisor:</B>Sophia Drossopoulou<BR>
<B>Room No.:</B>559<BR>
<B>E-mail:</B><A HREF="mailto:scd@doc.ic.ac.uk">scd@doc.ic.ac.uk</A><BR>
<HR><BR>The aim is to build a tool that sequences taks on a mashine taking into account the dates the tasks are due, the duration of each taks, and the swirch over
costs from taks to taks.<BR>
<HR><BR>The project will be concerned with developing
</p>

<ol>
<p>
<li>a precise formulation of the problem</li>
<li>heuristics to solve the problem</li>

<li>software to visualise the problem and solution</li>
<li>tools to help the user guide the process for finding solutions</li>
</p>
</ol>

<p align="justify">
The particular problem and constraints has been supplied by an existing software
company; the data come from applications  concerned with the production of paper.
</p>

<p align="justify">
This is a good project for students interested in development of algorithms,
complexity and mathematics.
</p>

<p> An earlier version of the project has been implemented by Argyrios Skouloudis, a Conversion MSc student in 2002/03. His thesis will be available in the technical library. The current project should develop further heuristics (eg employing
genetic algorithms), better 
support for the user to specify part of the solution only,  
better visualization, and extend the problem to several mashines.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Use of Eclipse to Generate Security for Existing Programs</H2></CENTER>
<B>Supervisor:</B>Morris Sloman<BR>
<B>Room No.:</B>572<BR>
<B>E-mail:</B><A HREF="mailto:mss@doc.ic.ac.uk">mss@doc.ic.ac.uk</A><BR>
<HR><BR>To investigate the Aspect Oriented Programming features of Eclipse as a means of retrofitting security in terms of access control and authentication into existing programs. <BR>
<HR><BR>This could make use of existing certificate libraries and Java security or implement a authorisation server which interprets Ponder policies.  

Onlys sutable for an MENG student.    
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Mobile Computing Using Wireless PDAs</H2></CENTER>
<B>Supervisor:</B>Morris Sloman<BR>
<B>Room No.:</B>572<BR>
<B>E-mail:</B><A HREF="mailto:mss@doc.ic.ac.uk">mss@doc.ic.ac.uk</A><BR>
<HR><BR>To use Microsoft's .net environment to implement a suitable mobile demonstrator using a wireless IPAQ<BR>
<HR><BR>If  you have an interesting mobile/ubiquitous computing application that you would like to implment on wireles PDA come and discuss it with me.  <BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Use of Ponder for Specifying Web Services Access Control</H2></CENTER>
<B>Supervisor:</B>Morris Sloman<BR>
<B>Room No.:</B>572<BR>
<B>E-mail:</B><A HREF="mailto:mss@doc.ic.ac.uk">mss@doc.ic.ac.uk</A><BR>
<HR><BR>To implement a back end for the Ponder comiler to generate XACML.
To investigate implementations techniques for XACML based access control for web services.<BR>
<HR><BR>XACML is a XML based language for specifying access control for web services.  However, it is not very readable and not as powerful as Ponder.
This project will investigat the use of Ponder to generate XACML to make use of the object-oriented features of Ponder.  This will obviously require developing suitable web services with XACML access control. 
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Ponder Authorisation Server</H2></CENTER>
<B>Supervisor:</B>Morris Sloman<BR>
<B>Room No.:</B>572<BR>
<B>E-mail:</B><A HREF="mailto:mss@doc.ic.ac.uk">mss@doc.ic.ac.uk</A><BR>
<HR><BR>To modify the XML generator for the Ponder Compiler to produce better XML.  to implement an authorisation server which interprets Ponder XML policies and makes access control decisions for other servers.  <BR>
<HR><BR>The current back end generates very verbose XML which is very difficult to read or understand. This project will implmeent a new backend which produces more optimal XML.  

The Ponder authorisation server should interpret XML rather than source policies. It can then be queried by other servers to determine whether to permit operations.  This will require the server determining information about the client such as source address etc. which may be operating sytem dependent. Ponder policies specify subjects in terms of domain membership so investigation of how to group addresses etc into domains will also be required. <BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Interplanetary trajectories</H2></CENTER>
<B>Supervisor:</B>Ian Hodkinson<BR>
<B>Room No.:</B>426<BR>
<B>E-mail:</B><A HREF="mailto:imh@doc.ic.ac.uk">imh@doc.ic.ac.uk</A><BR>
<HR><BR>To calculate and display suitable flightpaths for a spacecraft travelling from Earth to other planets/moons and back.   <BR>
<HR><BR><b>I am available to discuss this and my other projects at 1pm on Mondays and 12 noon on Fridays.</b><P>

You remember those <a href="http://www.hq.nasa.gov/office/pao/History/SP-350/profile.html"> figure-of-eight pictures </a> of the Apollo flightpath that NASA used to show during the moonshots (maybe you were not around then)?  This project would produce software to calculate and graphically display such paths.  User would enter the destination(s) (e.g., moon and/or other planet(s), comets?), the launch date and perhaps Earth location, whether a return flightplan is required, and the costliest resource (fuel or time).  Program would compute and dynamically display a suitable flightpath that optimises the named resource.  A sophisticated program might recommend better launch dates or propose its own launch windows for "Grand tour"-like voyages visiting several planets in one trip.  As an extension to the project, slingshot effects round the sun and other bodies could be utilised where appropriate.  Obviously it would be necessary to calculate positions of Earth and planets at any time as part of the project.

<P>
Some requirements: 
<P>
1) all numerical approximations must be done by Runga-Kutta method, 
<P>2) the algorithm must be based on Kepler's laws of planetary motion, and not simple simulation of gravitational forces step by step over increments of time.  
<P>You must be willing to work out an algorithm for  yourself (I will help), rather than plough through the technical literature, in which you will surely get bogged down.  Therefore you need to be competent in calculus, vectors, and basic physics, as well as programming.  Ideally you will have done astronomical (e.g., planetary) calculations before, perhaps as a hobby.  This project is most suitable for a JMC student.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Indexing in latex</H2></CENTER>
<B>Supervisor:</B>Ian Hodkinson<BR>
<B>Room No.:</B>426<BR>
<B>E-mail:</B><A HREF="mailto:imh@doc.ic.ac.uk">imh@doc.ic.ac.uk</A><BR>
<HR><BR>To produce software to visualise and edit the index entries in a latex source, and output the results ready for typesetting.<BR>
<HR><BR><b>I am available to discuss this and my other projects at 1pm on Mondays and 12 noon on Fridays.</b><P>

Latex is a typesetting language based on Donald Knuth's TeX, and is widely used to prepare technical papers and books in computing, mathematics, and other scientific subjects.  The <A HREF=http://tex.loria.fr/bibdex/makeindex.pdf>Makeindex</A> package is often used to prepare indexes to latex documents; it utilises special "index" commands which have already added by the writer to the source file.  
<P>The proposed project is to create software that replaces and improves on Makeindex in several ways.  A key aim is that the software should display the compiled index in a form that can be manipulated directly by the writer with consequent changes to the source files, so reducing the need for the writer to hunt through the source files for the embedded index commands.  This is in line with HCI theory, as well as with the professional view of an index as a separate document that requires its own editing.  It would obviate the chief drawback of embedded index entries, which is that the index cannot be manipulated directly.  The visual form of display could perhaps use advanced HCI ideas.
<P>
The software would display non-editable locators (page numbers) as well as the index entries.  It should support specialised sorting (this is not trivial) and manual re-ordering of entries, as well as moving, renaming, deleting, promoting, demoting, and combining of headings, sub-headings, and sub-sub-headings.  It should support "see" and "see also" cross-references, and automatically check these for blind xrefs and loops.  It should allow the user to declare entries as synonymous - such entries should automatically get identical locators.  Spell-checking would be a useful feature.  Several separate indexes (e.g., author, subject, symbol) in the same document should be supported, as should introductory notes. This is not an exhaustive list of functions.  Other novel features are welcome, and limited only by your time and imagination.  
<P>The program will output the edited index to a file as latex source, ready to be typeset, with several style options.  Ideally this stage should allow running headers, which may require rewriting the TeX output routine (this will make you a TeX wizard).
<P> The software should preferably be able to handle documents already indexed with Makeindex.  This will increase its utility.
<P>The program's structure, functionality, and help system should promote good practice in index design, something in which few writers are expert.  (For example, main headings should be nouns or gerunds, not adjectives.  Headings with more than about 7 locators should be broken into subheadings. Cross-references should only be made to a heading with at least three locators or with subheadings.)  Well-written software could find wide application by the myriad Latex users worldwide.
<P>Anyone doing this project should be interested in learning about professional indexing, an art in itself.  I recommend Hans Wellisch's book "Indexing from A to Z" to start you off.  The project does not involve automated indexing (in which index entries are chosen by the software).  <BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>DNA Sequence Analysis</H2></CENTER>
<B>Supervisor:</B>Duncan Gillies<BR>
<B>Room No.:</B>306<BR>
<B>E-mail:</B><A HREF="mailto:dfg@doc.ic.ac.uk">dfg@doc.ic.ac.uk</A><BR>
<HR><BR>To write software for displaying and analysisng data from DNA sequencing.<BR>
<HR><BR>We have a current research project in the Department on modelling the Sanger reaction for determining the base sequence in fragments of DNA. There is a need for support software that will read in sequence data, display the traces, perform some tests on them, and implement some methods for determining the sequence.  Further features could include simulation of sequencing data.

No knowledge of bio-informatics is needed and full support on all aspects of DNA sequencing is available.  The software is probably to be written in C++ under the linux environment.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Runtime optimisation of Java JDBC calls using a Virtual JVM</H2></CENTER>
<B>Supervisor:</B>Paul Kelly<BR>
<B>Room No.:</B>423<BR>
<B>E-mail:</B><A HREF="mailto:phjk@doc.ic.ac.uk">phjk@doc.ic.ac.uk</A><BR>
<HR><BR>Improve performance of Java applications that use the JDBC database interface. 
The idea is you run the application under a special "virtual" JVM layer, which intercepts JDBC calls and optimises it uses classical JDBC performance tricks. <BR>
<HR><BR>JDBC is Java's binding to SQL databases, and is very widely used.  Poor use of JDBC can be the source of many performance problems, and fixing this chews up a lot of development time.  The goal of this project is to develop an automatic optimisation tool which looks at the client's use of JDBC, and automatically rearranges the code to expose optimisation opportunities.
<p> 
To do this we propose to use the "Veneer" Virtual JVM.  This is a prototype tool for implementing "domain-specific" optimisations at runtime in Java.  Veneer is a Java application that executes Java applications, but each time application bytecode is loaded it modifies the bytecode to intercept the flow of control.  We have used this successfully to optimise RMI.  The plan is to do it for JDBC.  The basic idea is to defer JDBC calls as much as possible, then, when forced to execute them, we can look at a whole sequence of calls together.
<p>
Then we can use whatever performance tricks we can find - stored procedures, prepared statements, and perhaps more - to optimise the aggregated call set.
<p>
Your task is to figure out how to get Veneer to do this, select a database and JDBC implementation, and write the code needed to make it work.  The goal is to write a report that shows the potential for these ideas on realistic applications, so a crucial issue is to identify a selection of benchmarks which you can use for testing from an early stage.
<p>
This is a research-level project with enormous potential.  You need fairly deep knowledge of Java, some experience of JDBC and its applications, and, above all, a talent for getting complicated code to work.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Simulating the Container Transport System</H2></CENTER>
<B>Supervisor:</B>Tony Field<BR>
<B>Room No.:</B>376<BR>
<B>E-mail:</B><A HREF="mailto:ajf@doc.ic.ac.uk">ajf@doc.ic.ac.uk</A><BR>
<HR><BR>To build middleware that will enable an existing Java model of the international container shipping system to be turned into a service, with model integration happening on high-performance compute clusters and model configuration, job control and data visualisation happening via a web browser<BR>
<HR><BR>The vast majority of world import and export goods are now shipped by container. It's a multi-billion-pound business involving shippers (e.g. Sainsbury's), ports (e.g. Southampton), shipping lines (e.g. P&O), road and rail hauliers (e.g. Securicor-Omega, Freightliner) and third-party logistics organisations.  <BR><BR>
To help the container business organisations plan for the future, and to help the U.K. Government to explore the implications of transport policies such as road charging, a simulation model of the business is being developed here at Imperial. This is a big research project funded by the DTI through EPSRC.  <BR><BR>
The project described here will focus on the international trade model, which models port-port and door-port container volume based upon historical data and scenarios for future growth. It's in Java and it works!  Currently, however, the model is very cumbersome to use: the user (one of the industrial partners) has to install a raft of software on their desktop machine, follow low-level instructions for driving the model, keep track of various intermediate files generated by the model, apply manual filtering of output data and then invoke a tool such as Excel to produce reports, time series etc.  It's all very 'yucky'<BR><BR>

Ideally, what we would like is a system that enables the user to configure a model, integrate the model (solve it), and analyse its output remotely via a web browser. For computationally complex queries, e.g. draw a graph of ship capacities at Felixstowe as global trade volumes increase from 1 through 20%, it would be nice to exploit a high-performance cluster on the server side, such as those provide by ICPC. <BR><BR> Initially, to get things started, the project could focus on providing visualisation tools for a pre-computed data set. <BR><BR>
This is not an ultra high-risk project, although the cluster-based computing problems (e.g. using ICENI) will present some interesting challenges if you get that far. The project is initially about delivering useful tools that really work.  The project will give you a chance to work alongside research assistants who are developing the various models and industry partners who will be using them.
<BR><BR> You need to be interested in client-server programming, Java, middleware etc. an interest in modelling would be nice, but is not essential.  You should have done some web-based programming before.<BR><BR>

It may be better from our point of view to offer this to an MEng student for the simple reason that we would ideally like some early deliverables (early January).  This will prove more difficult for BEng Computing students, but they will not be excluded from consideration.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Investigations into C-sharp</H2></CENTER>
<B>Supervisor:</B>Sophia Drossopoulou<BR>
<B>Room No.:</B><BR>
<B>E-mail:</B><A HREF="mailto:scd@doc.ic.ac.uk">scd@doc.ic.ac.uk</A><BR>
<HR><BR>The investigate the  novel features of C-sharp, 
with particular interest in linking and separate compilation.<BR>
<HR><BR>C-sharp is a new language developed by Microsoft, to be used
as the high level for the .net platform. It is meant to combine the
experience from java and C++. It has a very powerful type
system, and interesting ideas with regards to linking.
<p>
The project could concentrate on all, or some of the following:
<li>develop a semantcis and type system for a subset
</li><li>
develop a sequrence of test programs which demonstrate language 
features
</li>
<li>
investigate dynamic linking and compare with that in Java
</li>
<p>
A very interesting question in C-sharp is the support of
versioning, more at 
<a href="http://www.doc.ic.ac.uk/~mcs98//SLURP.cgi?PrelimVers"> a discussion wiki</a>. 
<p>
The student would investigate the features by means of studying the
language description, developing a sequence of examples, and then
formalizing the semantics in the style of L2, as in 
<a href="http://www.doc.ic.ac.uk/~scd/Teaching/AdvOO.html"> the
course Advanced Issues in
Object Oriented Languages</a>, or, in a more axiomatic presentation,
by means of equations,
as in the paper <a href=http://www-dse.doc.ic.ac.uk/projects/slurp/pubs.html#lics">
A Fragment Calculus ? towards a model of Separate Compilation, Linking and Binary Compatibility</a>
</a>
<p>
<p>


Students' suggestions welcome. Enthusiasm a prerequisite.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Java Semantics Visualization</H2></CENTER>
<B>Supervisor:</B>Sophia Drossopoulou<BR>
<B>Room No.:</B>559<BR>
<B>E-mail:</B><A HREF="mailto:scd@doc.ic.ac.uk">scd@doc.ic.ac.uk</A><BR>
<HR><BR>A simulator and animator for the Java Operational Semantics,
as described in a formal semantics developed by
Sophia Drossopoulou and Susan Eisenbach.<BR>
<HR><BR>The tool should run on the web, and should highlight execution
of a term, and its effect on the state. Of course, only a
subset of the language Java can be modelled.
</p>

<p align="justify">

Attendance of Operational Semantics course a prerequisite.
</p>

<p align="justify">
The following paper describes the Java operational semantics:
</p>

<p>
<a href="http://www-dse.doc.ic.ac.uk/projects/slurp/pubs.html#tapos">Is the Java Type System Sound?</a>
<br>
by  Sophia Drossopoulou, Susan Eisenbach and Sarfraz Khurshid.
</p><BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Formalization of GJ</H2></CENTER>
<B>Supervisor:</B>Sophia Drossopoulou<BR>
<B>Room No.:</B>559<BR>
<B>E-mail:</B><A HREF="mailto:scd@doc.ic.ac.uk">scd@doc.ic.ac.uk</A><BR>
<HR><BR>To extend the description of the language L2 (from the course Advances Issues in OO Languages), so that it includes a formalization og GJ.<BR>
<HR><BR>GJ is an extension of Java, which supports generic classes, i.e. class parameterization. GJ has been introduced into version 1.5 of Java, c.f. <a href="http://www.research.avayalabs.com/user/wadler/gj/index.html#jan03"> The GJ Description</a>. The language has been formalized for a functional setting in
<a href="http://www.sato.kuis.kyoto-u.ac.jp/~igarashi/papers/fj.html"> Featherweight Java, a minimal core calculus for Java and GJ</a>.
<p>
The aim of this project is to formalize GJ for an imperative setting.
<p>
The project has a high research potential, and requires enthusiasm. <BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Beat the Theorem Prover</H2></CENTER>
<B>Supervisor:</B>Simon Colton<BR>
<B>Room No.:</B>407<BR>
<B>E-mail:</B><A HREF="mailto:sgc@doc.ic.ac.uk">sgc@doc.ic.ac.uk</A><BR>
<HR><BR>To generate theorems which are difficult for automated theorem provers to solve.<BR>
<HR><BR><html>
<title>Beat the Theorem Prover</title>
<body background="../../../images/greenministripe.gif" text="black">
<table width=600 border=0>
<tr>
<td>
<center>
<font face='comic sans MS'>
<h2>Beat the Theorem Prover</h2>
</font>
</center>
<p align=justify>
Automated theorem proving is an important area of Artificial
Intelligence. To show advances in the area it is important to keep
testing theorem provers with new theorems and non-theorems. There is a
competition every year:

<p>
<center>
<a href="http://www.cs.miami.edu/~tptp/CASC/">The CADE ATP System Competition
</a>
</center>

<p align=justify>
in which the leading state of the art first order theorem provers
battle it out to be crowned supreme champion. 
<p align=justify>
The theorems selected for the competition are taken from the:

<p>
<center>
<a href="http://www.cs.miami.edu/~tptp/index.html">
The TPTP Problem Library
</a>
</center>

<p align=justify>
We have previously used our HR program to generate theorems for this
library. HR is a theory formation program which can generate tens of
thousands of theorems given just the axioms of a mathematical domain
such as group theory. However, the generation was done in a
brute-force way, without using any of the (masses of) intelligence in
the program. To show you how bad it is, out of 46,000 theorems in
group theory, only 184 were accepted into the TPTP library.

<p align=justify>
This project will involve using HR to generate theorems more
intelligently in different algebraic domains. Various methods will be
used and appraised and improvements to the system will be made. These
improvements will be implemented into the (Java) program underlying
HR. The aims of this project are to (a) generate lots of theorems at
just the right level of difficulty and (b) determine how (and
implement ways) to get HR to produce more theorems like this.

<tr>
<td align=center>
<p>
<hr>
&copy; Simon Colton 2002
<hr>
<p>
</td>
</tr>
</table>
</body>
</html><BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>An Online Java Interpreter #2</H2></CENTER>
<B>Supervisor:</B>Simon Colton<BR>
<B>Room No.:</B>407<BR>
<B>E-mail:</B><A HREF="mailto:sgc@doc.ic.ac.uk">sgc@doc.ic.ac.uk</A><BR>
<HR><BR>To continue and appraise the development of the open-source RJCE system, which allows a user to modify the code for any Java method for any particular object at run-time.<BR>
<HR><BR><html>
<title>An Online Java Interpreter #2</title>
<body background="../../../images/greenministripe.gif" text="black">
<table width=600 border=0>
<tr>
<td>
<center>
<font face='comic sans MS'>
<h2>An Online Java Interpreter #2</h2>
</font>
</center>
<p align=justify>
Compiled languages such as Java have certain drawbacks. For instance,
if you've ran your program for hours and want to extract information
from its results, but the code you've written to do this isn't up to
scratch (has a bug, doesn't do what you wanted it to do, etc.), then
it's likely you'll have to quit, re-program, re-compile and re-run the
program! Hence, in some situations, it's good to have aspects of an
interpreted language.

<p align=justify>
For his MSc. project, James Bloom has put together the <a
href="http://www.doc.ic.ac.uk/~jdb197/links.html">RJCE</a> system,
which uses the Beanshell Java interpreter to enable the user to change
the code of any method for any particular object at run-time. It
performs pre-processing of the user's Java code to insert
re-directions which can be enabled at run-time. The re-directions take
the program flow through some interpreted code, hence simulating the
change of underlying code at run-time. The system is extremely useful,
and we already have applications in mind in education, debugging and
automatic (e.g., genetic) programming.

<p align=justify>
This project will continue the development of RJCE and perform an
analysis of alternatives. In particular, we want to look at whether an
approach based on <a href="http://eclipse.org/aspectj/">ASPECTS</a>
would be a good idea. Another possibility is to use <a
href="http://koala.ilog.fr/djava/">Dynamic Java</a> as the underlying
interpreter, rather than Beanshell. We also want to look at possible
ways to integrate this with the Veneer virtual JVM developed in the
department. This is an important chance to become an early developer
of an open-source system which may affect the way in which people
program Java in future.

<tr>
<td align=center>
<p>
<hr>
&copy; Simon Colton 2002
<hr>
<p>
</td>
</tr>
</table>
</body>
</html>
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Pun Generation via Conceptual Blending</H2></CENTER>
<B>Supervisor:</B>Simon Colton<BR>
<B>Room No.:</B>407<BR>
<B>E-mail:</B><A HREF="mailto:sgc@doc.ic.ac.uk">sgc@doc.ic.ac.uk</A><BR>
<HR><BR>To generate puns using conceptual blending to take a punchline and generate a joke.<BR>
<HR><BR><html>
<title>Pun Generation via Conceptual Blending</title>
<body background="../../../images/greenministripe.gif" text="black">
<table width=600 border=0>
<tr>
<td>
<center>
<font face='comic sans MS'>
<h2>Pun Generation via Conceptual Blending</h2>
</font>
</center>
<p align=justify>
People are beginning to take humour research seriously, for instance, see: 

<p align=center>
<a href="http://www.ub.utwente.nl/webdocs/ctit/1/0000009e.pdf">
Humour Research: State of the Art
</a>

<p align=justify>
Puns are a particularly poor form of joke, but they can - occasionally
- be funny. Previous work on automatic pun generation has used a
template based approach, for example the JAPE pun generator:

<p align=center>
<a
href="http://citeseer.nj.nec.com/cache/papers/cs/2037/http:zSzzSzwww.sonycsl.co.jpzSzpersonzSzkimbzSzdai_version.pdf/binsted94symbolic.pdf">
A Symbolic Description of Punning Riddles</a>

<p align=justify>

This project will involve using the Divago system written by Francisco
C. Pereira as described in this paper:

<p align=center>
<a href="http://eden.dei.uc.pt/~camara/files/ExperimentsII.pdf">
Experiments with Free Concept Generation in Divago
</a>

<p align=justify>
Divago performs conceptual blending, which takes descriptions of two
concepts and outputs a new concept which has some of the aspects of
both. For instance, the concept of `horse-bird' could be generated by
blending the concepts of horse and bird, but there are many
possibilities for the blend (a horse with wings, a bird with four
legs, etc.). 

A user manual for Divago is here:

<p align=center>
<a href="http://www.doc.ic.ac.uk/~sgc/teaching/projects/pun_generation/Divago.txt">Divago ReadMe.txt</a>

<p align=justify>
Many jokes have at their heart a blended concept. For instance:
<p>
Q. "What do you get if you cross a kangaroo and a sheep?"<br>
A. "A wooly jumper!"
<p align=justify>
Here, the blended concept of a kangaroo-sheep has been used. This
project will involve exploring the possibility of whether the
following (or a similar) routine is able to produce jokes: 

<ol>
<li>Generate a punch line by taking a well known phrase such as
"Jacket Potato".</li>
<p>
<li>Find concepts related to those in the punch line, such as
"clothing" and "vegetable"</li>, and blend them.
<p>
<li>Turn a description of the blended concept into a joke using a
template, for instance: "What kind of vegetable do you wear?"
</ol>

<p align=justify>
We'll start by trying to re-discover jokes such as the Jacket Potato
pun, then see if the system can produce new jokes, starting with
punchlines such as: "floppy disk", "bowler hat", etc. Guaranteed
laughs all round!


<tr>
<td align=center>
<p>
<hr>
&copy; Simon Colton 2002
<hr>
<p>
</td>
</tr>
</table>
</body>
</html>
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Anomaly Detection in Musical Analysis</H2></CENTER>
<B>Supervisor:</B>Simon Colton<BR>
<B>Room No.:</B>407<BR>
<B>E-mail:</B><A HREF="mailto:sgc@doc.ic.ac.uk">sgc@doc.ic.ac.uk</A><BR>
<HR><BR>To perform experiments using machine learning tools to identify anomalies in pieces of music.<BR>
<HR><BR><html>
<title>Anomaly Detection in Musical Analysis</title>
<body background="../../../images/greenministripe.gif" text="black">
<table width=600 border=0>
<tr>
<td>
<center>
<font face='comic sans MS'>
<h2>Anomaly Detection in Musical Analysis</h2>
</font>
</center>
<p align=justify>
Whenever a new manuscript is found (a novel, a piece of music, etc.),
which may have been written by someone like Shakespeare, Beethoven,
etc. then computational techniques can be used to compare the new
piece to those known to be written by the famous person, and they can
be authenticated. Such techniques include simple but effective things
like n-gram analysis. For instance, it may be that the distribution of
triples of letters in a new manuscript is completely different to the
average for a Shakespeare play, so it's unlikely to be written by him.
While such techniques can give high accuracy in determining
authorship, they can be quite unsatisfying. It would be more
interesting, for example, if the analysis pointed out that Beethoven
never used a particular cadence, whereas the new piece has 10 of these
cadences.

<p align=justify>
In his MSc. project, Ben Vine showed that our HR system can be used
for musical analysis. He also showed that, given some Bach chorale
melodies and a carousal melody, HR points out that the carousal is an
anomaly, and gave reasons for this judgement. For instance, HR pointed
out that the carousal was one of only three melodies which had a
quaver followed by a semi-quaver. One possible application of this
kind of analysis might be in education. When composing, harmonising,
etc., music students follow rules, and try to imitate certain styles,
such as harmonising a chorale in the style of Bach. While they may
stay within the rules, a student's piece might be somewhat lacking
musically. An analysis of the type performed by HR could tell them
that they have more (or less) of something than Bach typically has,
and point out other anomalies. It would also be interesting to see
where the great composers bent the rules.

<p align=justify>
This project will involve continuing this study into anomaly detection
in music. It will involve getting hold of music data and carrying out
experiments to test the hypothesis that HR can be used to identify
anomalies in music. As with all projects with HR, there will be much
scope to improve the underlying (Java) program, by analysing where the
program fails and implementing solutions.
<tr>
<td align=center>
<p>
<hr>
&copy; Simon Colton 2002
<hr>
<p>
</td>
</tr>
</table>
</body>
</html>
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Feature Detection for Artistic Purposes</H2></CENTER>
<B>Supervisor:</B>Simon Colton<BR>
<B>Room No.:</B>407<BR>
<B>E-mail:</B><A HREF="mailto:sgc@doc.ic.ac.uk">sgc@doc.ic.ac.uk</A><BR>
<HR><BR>To perform image analysis to identify the location of objects such as trees, people, cars, etc. <BR>
<HR><BR><html>
<title>Feature Detection for Artistic Purposes</title>
<body background="../../../images/greenministripe.gif" text="black">
<table width=600 border=0>
<tr>
<td>
<center>
<font face='comic sans MS'>
<h2>Feature Detection for Artistic Purposes</h2>
</font>
</center>
<p align=justify>
Programs such as Photoshop can produce stunning artistic effects using
sophisticated filters and transformations. However, it is difficult to
project any level of creativity onto these programs. Part of the
reason for this is that such programs cannot recognise the objects in
the image they are transforming. If they could, then they might be
able to apply different filters to different parts of the image, for
example treating a person differently to a tree.

<p align=justify>
This project will be to write and use feature detection algorithms to
suggest image processing methods for particular areas of an input
image. Such algorithms can use colour histograms or edge detection, or
can involve machine learning techniques such as neural network
learning and ontologies. This will form part of the ThreeCreate
initiative, which aims to produce a creative visual arts
program. Hence, many of the algorithms for loading and finding bitmap
information from images are available (in Java).

<tr>
<td align=center>
<p>
<hr>
&copy; Simon Colton 2002
<hr>
<p>
</td>
</tr>
</table>
</body>
</html>
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Bioinformatics for the Web #2</H2></CENTER>
<B>Supervisor:</B>Simon Colton<BR>
<B>Room No.:</B>407<BR>
<B>E-mail:</B><A HREF="mailto:sgc@doc.ic.ac.uk">sgc@doc.ic.ac.uk</A><BR>
<HR><BR>To produce online applets for the demonstration of some bioinformatics sequence matching algorithms (for educational purposes).<BR>
<HR><BR><html>
<title>Bioinformatics for the Web</title>
<body background="../../../images/greenministripe.gif" text="black">
<table width=600 border=0>
<tr>
<td>
<center>
<font face='comic sans MS'>
<h2>Bioinformatics for the Web</h2>
</font>
</center>

<p align=justify>
Many bioinformatics algorithms have been designed to analyse and
compare these sequences. For example, there are <i>sequence matching
and alignment</i> algorithms which test how closely two sequences
match. These are useful for building <i>phylogenetic trees</i> which
describe which genes evolved from which others. There is a nice
example on page 27 of <a
href="http://www.oup.co.uk/isbn/0-19-925196-7"> this book</a> where
they use such tests to see whether the (now extinct) Siberian mammoth
was more closely related to African or Indian elephants.

<p align=justify>
Bioinformatics students are usually taught to write Perl scripts for
analysing these sequences, as this is the perfect tool for playing
around with what are essentially strings of letters. However, for
some of the fairly routine tasks such as sequence matching, it would
be nice to have a Java applet online into which you simply cut and
paste some sequences, click a button and get an answer.

<p align=justify>
The purpose of this project is to write such a program and put
it onto the web. There is potential for such a program to be quite
popular with people wanting to carry out quick tests. Also,
it may be useful as a teaching aid: we could use it to demonstrate the
bioinformatics algorithms at work.

<p align=justify>
The project can be as difficult as you make it: if you offer more
functionality (more bioinformatics algorithms) in your program,
then this will be a more difficult project. I would expect undergraduates
to get the program online with some functionality. I would expect
masters students to include some statistical routines to check 
whether the results the program returned were statistically 
significant. A really good project would connect to online bioinformatics
databases to return information relating to the user's input.

<tr>
<td align=center>
<p>
<hr>
&copy; Simon Colton 2002
<hr>
<p>
</td>
</tr>
</table>
</body>
</html>
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>A Substructure Server #2</H2></CENTER>
<B>Supervisor:</B>Simon Colton<BR>
<B>Room No.:</B>407<BR>
<B>E-mail:</B><A HREF="mailto:sgc@doc.ic.ac.uk">sgc@doc.ic.ac.uk</A><BR>
<HR><BR>To improve upon a bioinformatics server which identifies submolecules within positive and negative examples (for toxicity, etc.)<BR>
<HR><BR><html>
<title>Substructure Server #2</title>
<body background="../../../images/greenministripe.gif" text="black">
<table width=600 border=0>
<tr>
<td>
<center>
<h2><font face='comic sans MS'>
Substructure Server #2
</font></h2>
</center>
<p align=justify>

<p align=justify>
Biotech companies waste many millions of pounds each year developing
drugs (leads) which eventually turn out to be toxic to humans, so have
to be shelved. Hence the field of predictive toxicology was born,
whereby they try and predict whether a drug will be toxic in
advance. Computers play a large part in this effort.

<p align=justify>
Machine learning programs such as the Inductive Logic Programming
system Progol have been used to discover reasons why certain chemicals
are toxic and others are not. In fact, they learn a concept which is
true of the toxic drugs and false for the others (or thereabouts). In
general, the learned concepts have been sub-molecular structures
containing around 5 or 6 atoms, some of which are fixed and some of
which can vary. 

<p align=justify>
We are developing a server which enables a user to provide details of
some positive (active) and some negative (non-active) chemicals to a
web page, that uses a simple machine learning technique to find a
substructure which is true of more positives than negatives. In the
long term, this may turn out to be a structural predictor for
toxicity. 

<p align=justify>
Saravanan Anandathiyagar has put together a server which performs the
basic operations well. We want to upgrade the system so that it offers
more functionality and is faster. There is much room for improvement,
and for this project, you can concentrate on the areas you
prefer. Projects include:

<ul>
<li>Adding in a front-end translation program so that the user can
supply the chemicals in any format they want. <a
href="http://openbabel.sourceforge.net/">Babel</a> is such a
program. </li>
<P>
<li>Adding in a molecule viewing program such as those found 
<a
href="http://dmoz.org/Science/Chemistry/Software/Structural/Visualization/">
here</a>. This will enable the user to view the sub-molecules found by
the system.</li>
<p>
<li>Distribute the learning process over a farm of computers to
improve the speed.</li>
<p>
<li>Improve the underlying learning algorithm, by adding in more
sophistication and/or replacing it with another algorithm, such as an
ILP routine.</li>
</ol>

</ul>

<tr>
<td align=center>
<p>
<hr>
&copy; Simon Colton 2002
<hr>
<p>
</td>
</tr>
</table>
</body>
</html>
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Automatic Generation of Number Theory Exercises</H2></CENTER>
<B>Supervisor:</B>Simon Colton<BR>
<B>Room No.:</B>407<BR>
<B>E-mail:</B><A HREF="mailto:sgc@doc.ic.ac.uk">sgc@doc.ic.ac.uk</A><BR>
<HR><BR>To use the HR system to produce exercises for undergraduate number theory
students.<BR>
<HR><BR><html>
<title>Automatic Generation of Number Theory Exercises</title>
<body background="../../../images/greenministripe.gif" text="black">
<table width=600 border=0>
<tr>
<td>
<center>
<font face='comic sans MS'>

<h2>Automatic Generation of Number Theory Exercises</h2>
</font>
</center>
<p align=justify>
Maths students need exercises in order to test their understanding of
a domain and their skill in applying the results they have
studied. Ordinarily, mathematics lecturers produce exercises without
the help of computers. We aim to help them in the task by providing
them with conjecture making support from the HR program. As described
in this paper:

<p align=center>
<a href="http://www.doc.ic.ac.uk/~sgc/html_papers/colton_radm02.html">
Automated Theory Formation for Tutoring Tasks in Pure Mathematics</a>

<p align=justify>
we have used HR previously as an aid to setting exercises in group
theory. We want to extend this study to number theory. The project
will involve looking through number theory course notes to extract the
functions used in them (such as phi, tau, sigma, etc.), then turning
these into code for the Maple computer algebra system. Following this,
you will use the HOMER system, which uses HR and Maple to form
conjectures about the Maple functions, then you will prove as many of
these theorems and assess whether they could be used as exercises on a
course. As with all projects with HR, there will be plenty of scope
for improving the underlying (Java) program.

<p align=justify>
HOMER is described here:

<p align=center>
<a href="http://www.doc.ic.ac.uk/~sgc/html_papers/colton_cade03.html">
The Homer System</a>


<tr>
<td align=center>
<p>
<hr>
&copy; Simon Colton 2002
<hr>
<p>
</td>
</tr>
</table>
</body>
</html>
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Theorem Proving in Batches</H2></CENTER>
<B>Supervisor:</B>Simon Colton<BR>
<B>Room No.:</B>407<BR>
<B>E-mail:</B><A HREF="mailto:sgc@doc.ic.ac.uk">sgc@doc.ic.ac.uk</A><BR>
<HR><BR>To investigate techniques for improving the performance of theorem provers when they have to solve a batch of theorems in one session.<BR>
<HR><BR><html>
<title>Batch Theorem Proving</title>
<body background="../../../images/greenministripe.gif" text="black">
<table width=600 border=0>
<tr>
<td>
<center>
<font face='comic sans MS'>
<h2>Batch Theorem Proving</h2>
</font>
</center>
<p align=justify>
Automated theorem proving is an important area of Artificial
Intelligence. To show advances in the area it is important to keep
testing theorem provers with new theorems and non-theorems. There is a
competition every year:

<p>
<center>
<a href="http://www.cs.miami.edu/~tptp/CASC/">The CADE ATP System Competition
</a>
</center>

<p align=justify>
in which the leading state of the art first order theorem provers
battle it out to be crowned supreme champion. 

<p align=justify>
The theorems selected for the competition are taken from the:

<p>
<center>
<a href="http://www.cs.miami.edu/~tptp/index.html">
The TPTP Problem Library
</a>
</center>

<p align=justify>
In the next competition, there will be a special category for batch
processing: a set of, say, 50 theorems will be provided, and the
winning system will be the one which proves the most of the set in a
given time. Results from proving previous theorems in the batch can be
used to prove later ones. 

<p align=justify>
This project will involve getting hold of state of the art theorem
provers and trying out some strategies for improving their performance
on batches of theorems. Such strategies will involve intelligent
selection of proved theorems to use as lemmas. We may also try using
our HR system to for theories at the start of the session. Previously,
we found that this slowed down theorem provers for individual
theorems, but there is a chance that it will improve matters for batch
proving. 

<tr>
<td align=center>
<p>
<hr>
&copy; Simon Colton 2002
<hr>
<p>
</td>
</tr>
</table>
</body>
</html>
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Morton order layout for two-dimensional arrays</H2></CENTER>
<B>Supervisor:</B>Paul Kelly<BR>
<B>Room No.:</B>423<BR>
<B>E-mail:</B><A HREF="mailto:phjk@doc.ic.ac.uk">phjk@doc.ic.ac.uk</A><BR>
<HR><BR>Change the way the world stores arrays<BR>
<HR><BR>Everyone knows the way you store a 2d array is as a 1d array of rows (row-major) or a 1d array of columns (column-major).  But this leads to a common pitfall - programmers traverse a row-major array in column-major order.  This leads to a performance hit of 3 to 10 times.
<p>
This is shoddy: quality tools shouldn't have such precipitate pitfalls.
<p>
Preliminary research here at Imperial (<a href="www.doc.ic.ac.uk/~phjk/Publications/ImprovingMorton-LCPC2003.pdf">see here</a>) has shown there is a good alternative - a compromise between row-major and column-major with performance almost as good as either.
<p>
The idea is to use the Morton Z order - one of a family of quadtree-based "space-filling curves".  The address of A[i,j] is calculated as D1[i] + D0[j], where D0 is a lookup table that maps j to a bitwise-dilated representation with a zero between (to the left of) each binary digit.  D1 is same but with the zeroes to the right (D0[jjjj]=0j0j0j0j, D1[i]=i0i0i0i0).
<p>
You need a couple more tricks - careful alignment, and aligned unrolling - to get the performance.
<p>
Your job is to implement this scheme for a realistic programming language such as Fortran or C# (C and Java are no good as they don't have first-class multidimensional arrays).
<p>
One way to do it is using SUIF, the Stanford University Intermediate Form <a href="http://suif.stanford.edu/">see here</a>.  This should work pretty well.
<P>
Another idea might conceivably be to use Rotor or Mono - should work, but there isn't much code to test it out with.
<p>
Once you have got it to work, you need to evaluate it on a number of different CPUs using a variety of different full-scale application examples.
<p>
This is a project for someone who likes compiler technology and wants to change the world.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Multistage programming and domain-specific optimisation by metaprogramming (Java or .Net?)</H2></CENTER>
<B>Supervisor:</B>Paul Kelly<BR>
<B>Room No.:</B>423<BR>
<B>E-mail:</B><A HREF="mailto:phjk@doc.ic.ac.uk">phjk@doc.ic.ac.uk</A><BR>
<HR><BR>Build a tool, preferably a library rather than a compiler, which supports multistage programming - programs which generate code at runtime.
<BR>
<HR><BR>Multistage languages support runtime code generation as a first-class functionality.  This can be useful for performance optimisation - you can specialise code for particular runtime values.  It also makes it easy to build domain-specific languages.  Finally, it offers the potential for an extreme form of reflection - replacing or augmenting your (or another) application's code on the fly.
<p>
Your job is to implement it.  With some specific objectives:
<ul><li>as a library (not as a new compiler or preprocessor) (This is tough but we've done in a C++ prototype, the TaskGraph Library)
<li>with really good-quality generated code.  This is easy if you're not in a hurry - for the TaskGraph library we generate C source then fork gcc
<li>really fast - using gcc takes about 100ms.  It should be possible to generate good-quality code much faster than that, but good tools are rare.  One idea might be to use .Net's support for runtime code generation - see eg  http://www.dina.dk/~sestoft/rtcg/
<li>With type safety - so a correctly-typed program can't generate a program with a type error.
<li>The long-term plan for this work is to support metaprogramming - once you have constructed a piece of code (eg as an AST), we want to be able to manipulate it - unroll/interchange loops, inline, etc.
</ul>
For background have a look at our work on the TaskGraph library, google "multi-stage programming" (with hyphen).  See also Don Batory's "Jak".
<p>
We have a prototype implemented in C++ which lacks type safety and uses gcc.  A bytecode-based implementation exists for OCaml.  We can discuss what language to base it on but both C# and Java look promising.  See Kawa and ikvm.  You could perhaps consider modifying the IBM Research JVM to get more explicit control over code generation/optimisation.
<p>
It is essential that the project plan include evaluation and demonstration.  
<p>
This is a challenging project and you need a talent for getting complicated code to work.  The payoff is that if it works it should be very cute!<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Project on Music Analysis and Recognition</H2></CENTER>
<B>Supervisor:</B>Duncan Gillies<BR>
<B>Room No.:</B>306<BR>
<B>E-mail:</B><A HREF="mailto:dfg@doc.ic.ac.uk">dfg@doc.ic.ac.uk</A><BR>
<HR><BR>To analyse and recognise music in digital form.<BR>
<HR><BR>The objective of this project is to process music files (probably in the WAV format, but maybe also MP3) to extract a unique signature from which the music can be identified. This will involve beat detection in the first instance, followed by extraction of frequency features.  Once the best way of extracting a signature has been found the project can continue by setting up a data base of music tracks, and investigating how accurate recognition is under different conditions, such as the level of compression.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Code annotation for collaborative code review</H2></CENTER>
<B>Supervisor:</B>Jeff Magee and Robert Chatley<BR>
<B>Room No.:</B>572a<BR>
<B>E-mail:</B><A HREF="mailto:jnm@doc.ic.ac.uk">jnm@doc.ic.ac.uk</A><BR>
<HR><BR>Design a system to manage collaborative review, to work with a
version control system and your favourite editor.<BR>
<HR><BR>When developing software collaboratively in a team, it would be useful
for a senior developer to be able to mark a section of code as "you
should revise this", "are you sure this is correct", "take a look at
Class XYZ, that might help you here". The relevant developer should be
alerted when such comments are made. Degrees of urgency should be
specifiable.

From the reverse point of view, developers should be able to suggest
different possible ways of writing a bit of code, and request for them
to be approved or rejected by another developer.


Design a system to manage this collaborative review, to work with a
version control system and your favourite editor.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Refactoring tool for Message Sequence Chart specifications</H2></CENTER>
<B>Supervisor:</B>Jeff Magee and Robert Chatley<BR>
<B>Room No.:</B>572a<BR>
<B>E-mail:</B><A HREF="mailto:jnm@doc.ic.ac.uk">jnm@doc.ic.ac.uk</A><BR>
<HR><BR>The aim of this project is to develop tool support (probably extending
an existing tool) to aid the designer in performing such refactorings,
and identifying where such refactorings might be possible.

<BR>
<HR><BR>Using sets of Message Sequence Charts as a specification technique is
becoming more popular in the design of software systems. There are
several tools available that allow MSCs to be drawn (including an
extension for LTSA).


As MSC specs tend to be developed incrementally, it is often the case
that they need to be refactored to express things in a more concise or
general way. For example, two alternative scenarios might be drawn which
have a common prefix, e.g. login, search, place order and login, search,
cancel order. These can be refactored into three smaller scenarios with
no repetition login, search and place order and cancel order which can
be sequenced to achieve the same behaviour.

<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>LTSA Plugins (up to 3 projects)</H2></CENTER>
<B>Supervisor:</B>Jeff Magee and Robert Chatley<BR>
<B>Room No.:</B>572a<BR>
<B>E-mail:</B><A HREF="mailto:jnm@doc.ic.ac.uk">jnm@doc.ic.ac.uk</A><BR>
<HR><BR>Develop a Plugin for the LTSA tool to add new functionality (th ethree areas are 1) Darwin Architecural Description Language graphical display and input,
2) ACME - architectural description lanaguage input, 3) SCR requirements model translator to FSP<BR>
<HR><BR>1) Currently, there is a textual Darwing plugin for LTSA. The project would implement a graphical display and input system. It is possible some of the required finctionality can be recovered from a previous EPSRC funded project - the System Architects Assistant

2) ACME is a software architectural description language intended as an interchange format between different toolsets. The idea is to dvelop a plugin for teh LTSA tool that can translate ACME +FSP into an FSP descripotion.

3) SCR is a requirements specification language which captures state machines in a tabular format. This project would develop an SCR specification capture tool together with a translator to FSP.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Mapping UML/OCL Models into Object Z Specifications</H2></CENTER>
<B>Supervisor:</B>Alessandra Russo & Krysia Broda<BR>
<B>Room No.:</B>564<BR>
<B>E-mail:</B><A HREF="mailto:{ar3, kb}@doc.ic.ac.uk">{ar3, kb}@doc.ic.ac.uk</A><BR>
<HR><BR>The aim of this project is to develop a tool that allows the generation of (graphical representation of) ObjectZ specifications from an UML/OCL model given in input. <BR>
<HR><BR>UML is a very popular modelling language for software systems, and it encompasses different modelling techniques, such as class diagrams. OCL is instead a formal language that allows the specification of constraints over class diagrams. These constraints relay upon the data declarations given in the class diagrams.  ObjectZ, on the other hand, is a formal specification language that enables both data declarations and specification to be
represented within the same structure of a class schema. There is a clear correspondence between UML/OCL constructs and class schema constructs of an ObjectZ specification. But a formal mapping between these two representation languages has never been finalised. 

<P> This project is composed of two parts. The first part consists of defining a mapping between UML/OCL language and ObjectZ specification language. The second part will then build upon this result and develop a tool that automates this mapping. The tool should allow a user to input UML/OCL models and automatically generate ObjectZ specifications. The latter can be in the form of either an XML file, or a graphical representation of class schemas. 

<P> The definition of such mapping and tools will enable other existing tools, which reason about Object-Z specifications, to interface with user input different from the ObjectZ language. This will hopefully increase the possibility of deploying formal methods during the development process of software systems. 

<P> The project is suitable to both undergraduate and postgraduate students. It does require, however, a basic understanding of logic.


<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>A Graphical User Interface for Logic Programming</H2></CENTER>
<B>Supervisor:</B>Alessandra Russo<BR>
<B>Room No.:</B>560<BR>
<B>E-mail:</B><A HREF="mailto:ar3@doc.ic.ac.uk">ar3@doc.ic.ac.uk</A><BR>
<HR><BR>The project aims to develop a user-friendly environment that interfaces with two classes of existing formal specification tools for, respectively, reasoning and analysing specifications.<BR>
<HR><BR>While representing specification in logic provides powerful means for analysing these specifications, many users find logic-based development environments difficult to use. There is, therefore, a need for user-friendly development environments that act as interfaces with existing formal specification tools. <P>
Specifically, two classes of formal specifications tools can be taken into consideration. The first one is based on deduction. It allows reasoning about a given formal specification, in terms of verifying if a specification satisfies certain properties and reasoning about the behavior of the underlying system by querying its formal specification.  The second class of formal specifications tools is instead based on AI abductive reasoning techniques and it facilitates analysis of formal specifications in terms of diagnosis of system failures. 
<P>
This project aims to develop a user-friendly environment which interfaces with both these two types of formal specifications tools.

This environment should in particular, facilitate 
<P>
1)ways for allowing "easy" input of formal specifications; 
<P>
2)a user-friendly query-based interface with a prolog engine for reasoning about a given formal specification, e.g. using graphics and/or color to highlight problems such as inconsistencies;
<P>
3)an user-friendly interface for existing abductive (prolog-based) tools, which facilitates the input the (negation of) system properties, the use of graphical representation of (reasoning) navigations through the specifications, and graphical techniques for highlighting errors in the specifications.
<P>
The environment will be tested by considering some case studies.
<P>
Target students are MEng students with some interest or experience in interface design. 

<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Domain-specific runtime optimisation components for C++</H2></CENTER>
<B>Supervisor:</B>Paul Kelly<BR>
<B>Room No.:</B>423<BR>
<B>E-mail:</B><A HREF="mailto:phjk@doc.ic.ac.uk">phjk@doc.ic.ac.uk</A><BR>
<HR><BR>Build a tool for run-time code generation, and add support for application-specific optimisation extensions<BR>
<HR><BR>We have built a prototype C++ library called TGL (TaskGraph Library)
which let's you do things like this:
<pre>
void main(int argc, char **argv;) {
  int d1, d2;
  sscanf(argv[1], "%d", &d1);
  sscanf(argv[2], "%d", &d2);
  unsigned A_size[] = { 1000, 1000 };
  double X[1000][1000];

  TaskGraph T;
  taskgraph (T) {
    tParameter(tArray(float, A, 2, A_size));
    tFor (i, 1, 1000) {
      tFor (j, 1, 1000) {
        A[i][j] = 0.25*(A[i-d1][j] + A[i+d1][j] + A[i][j-d2] + A[i][j+d2])
      } endloop;
    } 
  } 
  T.optimise();
  T.compile();
  T.execute(X);
}
</pre>
This code builds the abstract syntax tree for a loop nest,
specialising it using available constants such as d1 and d2.  It then
compiles it (by printing it as C to a file, calling gcc or icc, and linking
the resulting binary file back into the running program).
<p>
The focus of this project is the "T.optimise()" line.  The idea is
that the programmer builds a program fragment, then applies specific
optimisation functions.  For example, the loop above is a "stencil
loop", and there is a family of tiling/blocking transformations which
can improve performance substantially.
<p>
So we want to support the development of a wide variety of specialist
program analyses and transformations.
<p>
To do it, the TaskGraph library uses SUIF, the
Stanford University Intermediate Form.  This gives easy
access to the wide variety of analyses, optimisations and loop
restructuring transformations which have been developed for SUIF.
<p>
The job:
<ul>
<li> Design and implement an API for accessing the SUIF data structure
  at run-time, and using the SUIF analysis and optimisation passes.
<li> Demonstrate the results by building one or two sample optimiser
  components, eg to handle stencil loops as above, and loop fusion.
<li> Evaluate the effectiveness of your work, showing the resulting
  performance using selected application examples.
</ul>
This a challenging and exciting research-level project.  You need a
talent for getting complex C++ code to work.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Aspect-oriented instrumentation and bottleneck analysis for Java by runtime binary patching</H2></CENTER>
<B>Supervisor:</B>Paul Kelly<BR>
<B>Room No.:</B>423<BR>
<B>E-mail:</B><A HREF="mailto:phjk@doc.ic.ac.uk">phjk@doc.ic.ac.uk</A><BR>
<HR><BR>Use a dynamic instrumentation (= dynamic aspect weaving) tool for Java to construct a powerful general-purpose tool for debugging and performance analysis.
Use it to search automatically for performance "anti-patterns".<BR>
<HR><BR>We have built a prototype Java utility for dynamic instrumentation.  This allows you to connect to a running Java application,
browse its classes and methods, and insert instrumentation code at
essentially any chosen point - on the fly.
<p>
The goal of this project is to turn this into a powerful
general-purpose tool for debugging and performance analysis.
<p>
In particular, we'd like:
<ul>
<li>To have a general-purpose plug-in architecture for adding new
    instrument types to the system.  An instrument is essentially
    the combination of one or more instrumentation code fragments,
    a strategy for applying them, a database schema for the
    data generated by the instrument, and a data analysis tool for
    visualising the output and combining it with data from other
    instruments.
<li>To have a general-purpose instrumentation database.  We want
    to design an extensible framework for storing the results from
    performance instrumentation.  We need a flexible way of querying
    this database.  The idea is that you can construct queries
    which allow you to identify and prioritise patterns of
    behaviour which are characteristic of a fixable performance
    problem, or, for that matter, a bug.
<li>To experiment with programmatic application of instruments.
    You can think of this as dynamic aspect weaving (ie applying
    aspect-oriented programming ideas at run-time).  Another
    point of reference is the automatic bottleneck search
    used in the Performance Consultant component of the Paradyn
    tool.
</ul>
Performance analysis commonly involves studying whole program
behaviour, in terms of the main APIs on which the application is
built.  Instrumentation plug-ins can be specialised to search for
performance issues ("anti-patterns") special to the particular APIs being used.
<p>
This is a challenging project with potential both to create a really
useful tool, and to contribute to research.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Debugging with retrospect with the GNU debugger</H2></CENTER>
<B>Supervisor:</B>Paul Kelly<BR>
<B>Room No.:</B>423<BR>
<B>E-mail:</B><A HREF="mailto:phjk@doc.ic.ac.uk">phjk@doc.ic.ac.uk</A><BR>
<HR><BR>Extend the GNU debugger gdb with the ability to move backwards and forwards through a trace of an application's history.<BR>
<HR><BR>A debugger like gdb lets you stop an application and explore its data.  Usually, you stop the application at a point where a bug has been diagnosed - for example an assertion failure.  So the next task is to figure out how you got here.  You want to single-step backwards.
<p>
In fact, you want to be able to move freely backwards and forwards through the application's history, monitoring variables as you go.<p>
Your job is to extend gdb to support this.
<p>
A summer 2003 project made considerable progress: Jonathan Cooper modified valgrind (http://developer.kde.org/~sewardj) to log memory and register writes.  He then extended gdb (through gdb's "target vector" mechanism) to operate on the resulting log files instead of on a running process.<p>
Your job is to build on this work by adding tools for navigating the trace.  There are lots of possibilities, ranging from simple ideas like breakpoints and watch variables, through to using aspect-oriented programming and debug-by-query ideas, and perhaps also graphical visualisation.
<p>
The plan is to release the modified gdb to the open source community sometime in the spring.  Then you can spend the summer collecting cool usage examples for your report, and exploring extensions.
<p>
This is a challenging project suitable for students with a talent for getting complex software to work, and with some experience of open-source development.  The payoff is to put your name to a tool a lot of people will want to use.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Image Retrieval by Texture</H2></CENTER>
<B>Supervisor:</B>Stefan Rueger<BR>
<B>Room No.:</B>379<BR>
<B>E-mail:</B><A HREF="mailto:srueger@doc.ic.ac.uk">srueger@doc.ic.ac.uk</A><BR>
<HR><BR>The objective of this project is to research ans implement some or all of the surveyed texture features for use in an existing image search engine, and to compare their effectiveness in content-based image retrievale in an evaluation study.

<BR>
<HR><BR><TABLE BORDER=0>
<tr>
<td> <a href="http://km.doc.ic.ac.uk/akmt-2001/Brodatz/D3.gif"><img border=0 width=80 height=80 alt="D3" src="http://km.doc.ic.ac.uk/akmt-2001/Brodatz/D3_icon.jpg"></a>
<td> <a href="http://km.doc.ic.ac.uk/akmt-2001/Brodatz/D4.gif"><img border=0 width=80 height=80 alt="D4" src="http://km.doc.ic.ac.uk/akmt-2001/Brodatz/D4_icon.jpg"></a>
<td> <a href="http://km.doc.ic.ac.uk/akmt-2001/Brodatz/D11.gif"><img border=0 width=80 height=80 alt="D11" src="http://km.doc.ic.ac.uk/akmt-2001/Brodatz/D11_icon.jpg"></a>
<td> <a href="http://km.doc.ic.ac.uk/akmt-2001/Brodatz/D27.gif"><img border=0 width=80 height=80 alt="D27" src="http://km.doc.ic.ac.uk/akmt-2001/Brodatz/D27_icon.jpg"></a>
<td> <a href="http://km.doc.ic.ac.uk/akmt-2001/Brodatz/D43.gif"><img border=0 width=80 height=80 alt="D43" src="http://km.doc.ic.ac.uk/akmt-2001/Brodatz/D43_icon.jpg"></a>
<td> <a href="http://km.doc.ic.ac.uk/akmt-2001/Brodatz/D49.gif"><img border=0 width=80 height=80 alt="D49" src="http://km.doc.ic.ac.uk/akmt-2001/Brodatz/D49_icon.jpg"></a>
<td> <a href="http://km.doc.ic.ac.uk/akmt-2001/Brodatz/D95.gif"><img border=0 width=80 height=80 alt="D95" src="http://km.doc.ic.ac.uk/akmt-2001/Brodatz/D95_icon.jpg"></a>
</tr>
</TABLE>

<P>Texture is a general feature of surface areas that usually describes
the repetitive structure of it apart from its colour. In contrast to
colour, which is a point feature, texture is a region feature. It relates
mostly to a specific, spatially repetitive structure of surfaces formed by
one or more  primary elements. Generally, the repetition may involve local
variations of scale, orientation, or other geometric and optical features
of the elements. 

<P>Texture, together with colour and shape, is one the major low-level
features that can be used for "Query by example", ie, finding similar
images given one or two example images.

<P>In this individual study option, you are expected to review the
starte-of-the-art in image retrieval using texture of images. This
includes surveying texture features such as (but not limited to)
Co-occurrence Matrices, Tamura features (coarseness, contrast,
directionality, linelikeness, regularity, roughness - based on
psychological studies), Markov Random Field Texture Models, Wold
Decomposition Based and Gabor Texture Features and MPEG-7 Texture
Descriptors.

<P> You will implement some or all of the surveyed texture features (so
they can be used with an existing image search enging) and compare their
effectiveness for content-based image retrieval in a carefully designed
evaluation study.

<P>REFERENCES

<p>Albert del Bimbo (1999): <em>Visual Information Retrieval</em>. Morgan
Kaufmann.

<P>V Castelli and L D Bergman (Eds) (2002): <em>Image Databases: Search and
Retrieval of Digital Imagery</em>. Wiley.

<P>G L Gimel'farb and A K Jain (1996): On retrieving textured images from
an image data base. <em>Pattern Recognition</em>, vol 29, no 9, pp 1441 -
1483.

<P>A Hanjalic, G C Langelaar, P M B van Roosmalen, J Biemond, and R
Lagendijk (2000): <em>Image and Video Data Bases: Restoration,
Watermarking and Retrieval</em>. Elsevier Science.

<p>Michael S Lew (Ed) (2001): <em>Principles of Visual Information
Retrieval</em>. Springer. 

<P>F Liu and R W Picard (1996): Periodicity, directionality, and
randomness: Wold features for image modeling and retrieval. <em>IEEE
Transactions on Pattern Analysis and Machine Intelligence</em>, vol 18,
no 7, 1996, 722 - 733.

<P>S M Rahman (Ed) (2002): <em>Interactive Multimedia Systems</em>. IRM
Press, Hershey.

<P>T K Shih (2002): <em>Distributed Multimedia Databases: Techniques &
Applications</em>. Idea Group Publishing, Hershey

<P>A W M Smeulders and R Jain (Eds) (1997): Image Databases and Multimedia
Search. World Scientific, Singapore.

<p> H Tamura, S Mori, and T Yamawaki (1978): Texture features
corresponding to visual perception. <em>IEEE Transactions on Systems,
Man, and Cybernetics</em>, vol SMC-8, no 6, pp 460 - 473. 



<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Scalable Multimedia Database Indexing</H2></CENTER>
<B>Supervisor:</B>Stefan Rueger<BR>
<B>Room No.:</B>379<BR>
<B>E-mail:</B><A HREF="mailto:srueger@doc.ic.ac.uk">srueger@doc.ic.ac.uk</A><BR>
<HR><BR>The objective of this project is to research and implement
multidimensional indexing structure which are suitable for large scale
multimedia databases.
<BR>
<HR><BR>Most Image or Video Search engines operate by extracting and storing
feature vectors from the multimedia objects. These feature vectors may,
for example, consist of colour or texture histograms and can vary
considerably in size, say from a few ten numbers to 50,000 numbers. When
an image database is queried with a particular example image ("show me  
simular images"), the corresponding feature vector is computed and the
most similar feature vectors from the database are searched to display the
most similar images in the database.
   
<P>The last process is linear in the number of database entries - the more
images are stored the more similarity comparisons between the query  
feature vector and the database. Multidimensional indexing structures  are
supposed to cut this process short and quickly return the most similar
entries without looking through the entire database. We have several pure
image collections of up to 70,000 images and corresponding Gigabytes of
feature vectors (in varying type and size) available. There also exists a
backend image search engine which can be used for this project.

<P>REFERENCES

<P>Christian B&ouml;hm, Stefan Berchtold and Daniel Keim (2001): Searching in
High-Dimensional SpacesIndex Structures for Improving the Performance of
Multimedia Databases, ACM Computing Surveys, Vol. 33, No. 3, pp 322-373.

<a href="http://portal.acm.org/ft_gateway.cfm?id=502809&amp;type=pdf&amp;coll=GUIDE&amp;dl=GUIDE&amp;CFID=12930895&amp;CFTOKEN=17685718">Show PDF (from within College)</a>

<P>
Stefan Berchtold, Daniel A. Keim, Hans-Peter Kriegel (1996): The X-tree:
An Index Structure for High-Dimensional Data, Proceedings of the 22nd
International Conference on Very Large Databases. 

<a href="http://citeseer.nj.nec.com/cache/papers/cs/1211/ftp:zSzzSzftp.informatik.uni-trier.dezSzpubzSzuserszSzLeyzSzvldbzSzBerchtoldKK96zSzArticle.pdf/berchtold96xtree.pdf">Show PDF</a>
<P>
J K Lawder, P J H King (2000): Using Space-filling Curves for
Multi-dimensional Indexing, Lecture Notes in Computer Science 1832,
Springer.

<a href="http://citeseer.nj.nec.com/cache/papers/cs/16349/http:zSzzSzwww.dcs.bbk.ac.ukzSzTriStarpzSzpubszSzbncod17.pdf/lawder00using.pdf">Show PDF</a>




<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Distributed Query Processing</H2></CENTER>
<B>Supervisor:</B>Peter McBrien<BR>
<B>Room No.:</B>555<BR>
<B>E-mail:</B><A HREF="mailto:pjm@doc.ic.ac.uk">pjm@doc.ic.ac.uk</A><BR>
<HR><BR>This project seeks to implement a distributed query processor (DQP)
for the IQL language (an extension of the RA), when the IQL is held in transformations
used to specify the data integration of a set of databases. The DQP
should select appropriate mechanisms to answer each query, building upon already
implemented or developed techniques.<BR>
<HR><BR>For details, see <a
href="http://www.doc.ic.ac.uk/~pjm/teaching.html">Peter McBrien's
teaching page</a><BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Op-Art Generator and Animator</H2></CENTER>
<B>Supervisor:</B>Peter J McBrien<BR>
<B>Room No.:</B>555<BR>
<B>E-mail:</B><A HREF="mailto:pjm@doc.ic.ac.uk">pjm@doc.ic.ac.uk</A><BR>
<HR><BR>To provide a computer generator for the Op Art work of Bridget
Riley, where the generator will allow a user to adjust parameters used
in generating the Op Art, and also generate sequences of images to
form an animation.<BR>
<HR><BR>For details, see <a
href="http://www.doc.ic.ac.uk/~pjm/teaching.html">Peter McBrien's
teaching page</a><BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Perfect Developer (2)</H2></CENTER>
<B>Supervisor:</B>Krysia Broda and Gabrielle Sinnadurai<BR>
<B>Room No.:</B>378/540<BR>
<B>E-mail:</B><A HREF="mailto:{kb,apgs}@doc.ic.ac.uk">{kb,apgs}@doc.ic.ac.uk</A><BR>
<HR><BR>To apply Perfect Developer to a case study (the Cold Stream RailRoad)<BR>
<HR><BR>Perfect Developer is a product of Escher technology and is a tool for producing correct programs. It is based around the ideas introduced in program reasoning and has a hybrid language incorporating both logic and imperative structures. It supports classes.

It is possible to specify a system and to derive a Java program from it using Perfect. In this project, the particular system is a specification of the control system for the Cold Stream RailRoad (part of a rail system in Canada). Using this case study Perfect will be evaluated for a reasonably large scale application.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Perfect Developer Projects(1)</H2></CENTER>
<B>Supervisor:</B>Krysia Broda and Gabrielle Sinnadurai<BR>
<B>Room No.:</B>378/540<BR>
<B>E-mail:</B><A HREF="mailto:{kb,apgs}@doc.ic.ac.uk">{kb,apgs}@doc.ic.ac.uk</A><BR>
<HR><BR>To build a Perfect Developer Tutorial<BR>
<HR><BR>Perfect Developer is not difficult, but, being a formal language there may be resistance in the software engineering community to learn and use it. Therefore, a tutorial, that gives examples, definitions and hints and guides someone not fully conversant with the idea of program reasoning (i.e. that hasn't been on our first year course!) would be very useful.
<p>
That's what this project is to build. Of course it will entail learning Perfect and testing out many examples. In addition, there should be a larger case study, to illustrate its capabilities. 


An interest in reasoning about programs is necessary.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Object-Z to Perfect Developer </H2></CENTER>
<B>Supervisor:</B>Krysia Broda and Alessandra Russo<BR>
<B>Room No.:</B>378/564<BR>
<B>E-mail:</B><A HREF="mailto:{kb,ar3}@doc.ic.ac.uk">{kb,ar3}@doc.ic.ac.uk</A><BR>
<HR><BR>To develop a translator from Object-Z (eg XML notation) to Perfect Developer, a specification tool that proves programs correct (or not).<BR>
<HR><BR>Object-Z is a formal specification language/notation, which is an extension
of Z to incorporate object-oriented notions. Perfect Developer is a new
formal reasoning system in which one can write specifications and
implementations and have them checked by the system. That is, the system
proves correctness (just as in the "reasoning about programs" course ). 
The system produces a Java or C++ program or a program outline for correct
specifications.
<p>
The project is to take an object-Z specification and convert it into a
perfect specification. Perfect would then be used to check its correctness.
<p>
This project is probably most suitable for an MEng student or MSc student. However, the main criterion is that you should feel comfortable with writing formal specifications. 
<p>
Perfect Developer is developed by Escher Technologies. Their webpage is www.eschertech.com. Take a look at it!

<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>A Workbench for the Ambient Calculus</H2></CENTER>
<B>Supervisor:</B>Iain Phillips<BR>
<B>Room No.:</B>427<BR>
<B>E-mail:</B><A HREF="mailto:iccp@doc.ic.ac.uk">iccp@doc.ic.ac.uk</A><BR>
<HR><BR>To provide tools for investigating particular
processes written in the Ambient Calculus and variant calculi.<BR>
<HR><BR>The Ambient Calculus of Cardelli and Gordon is a successful model of process
mobility and the interaction of computational domains.

The aim of this project is to provide tools for investigating particular
processes written in AC and variant calculi.  This would include simulating the
operational semantics, so that possible behaviour can be traced, and also
providing graphical representations.

As an application, the system could be used to check that certain processes
form "symmetric electoral systems".  Symmetric electoral systems are
distributed systems which are guaranteed to elect a leader process.  This is
related to current research by the proposer and Maria Grazia Vigliotti.

Would particularly suit fourth-year students taking 481 Models of Concurrency.

Reference:
http://research.microsoft.com/Users/luca/Papers/MobileAmbients.A4.pdf<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Translating between XML and Relational Databases</H2></CENTER>
<B>Supervisor:</B>Peter McBrien         <BR>
<B>Room No.:</B>555<BR>
<B>E-mail:</B><A HREF="mailto:pjm@doc.ic.ac.uk">pjm@doc.ic.ac.uk</A><BR>
<HR><BR>To develop techniques, and implement tools to support those
techniques, for the conversion of data and schemas between XML files
and Relational Databases.<BR>
<HR><BR>Details found at <a href="http://www.doc.ic.ac.uk/~pjm/teaching.html">
Peter McBrien's teaching page</a>
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Temporal Database System</H2></CENTER>
<B>Supervisor:</B>Peter McBrien<BR>
<B>Room No.:</B>555<BR>
<B>E-mail:</B><A HREF="mailto:pjm@doc.ic.ac.uk">pjm@doc.ic.ac.uk</A><BR>
<HR><BR>This project would involve building a database system which would
provide improved support for the storage and querying of temporal data
than is found in current relational databases. The database temporal
query language would be based on US Logic, which provides a simple
extension of the relational calculus to support temporal data.</p>
<BR>
<HR><BR>For details, see <a href="http://www.doc.ic.ac.uk/~pjm/teaching.html">Peter McBrien's teaching page</a>
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Database Integration Tool</H2></CENTER>
<B>Supervisor:</B>Peter McBrien<BR>
<B>Room No.:</B>555<BR>
<B>E-mail:</B><A HREF="mailto:pjm@doc.ic.ac.uk">pjm@doc.ic.ac.uk</A><BR>
<HR><BR>This project would involve implementing a data integration tool
around the 
<a href="http://www.doc.ic.ac.uk/automed/" target="_top">AutoMed API</a>,
allowing a user to view schemas of databases, view the content of the
database, and perform a guided process of data integration to build
a set of mappings between data sources which allow for the migration
and transformation of data and queries between databases.<BR>
<HR><BR>For details, see <a href="http://www.doc.ic.ac.uk/~pjm/teaching.html">Peter McBrien's teaching page</a>
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Behavioural Equivalences for Xdpi</H2></CENTER>
<B>Supervisor:</B>Philippa Gardner<BR>
<B>Room No.:</B>452<BR>
<B>E-mail:</B><A HREF="mailto:pg@doc.ic.ac.uk">pg@doc.ic.ac.uk</A><BR>
<HR><BR>To study behavioural equivalences for Xdpi, a peer-to-peer model of
dynamic XML. 
<BR>
<HR><BR>Gardner and her PhD student Sergio Maffeis have recently introduced
Xdpi, a peer-to-peer model for describing the dynamic behaviour of XML. It is
based on an idealised model of XML, and an extension of the
pi-calculus (taught in the `Models of Concurrent Computation' course)
to model the underlying distribution layer. This model is used to
describe and analyse behaviour found in, for example, dynamic web page
programming, applet interaction, and service orchestration.  We have a
candidate operational equivalence associated with Xdpi.  The aim of
this theoretical project is to assess whether this equivalence is any
good: one approach is to translate this model into a higher-order
pi-calculus and compare equivalences; another approach is to study
examples; another approach is to look for other equivalences and study
their relationship with the initial one.  This is a challenging
theoretical project and is only suitable for somone with a good
instinct for theory.  It will be supervised by Gardner and Maffeis.
Details can be found in the introductory paper called `Dynamic
behaviour of Web Data' at http://www.doc.ic.ac.uk/~maffeis/

<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Security for Xdpi</H2></CENTER>
<B>Supervisor:</B>Philippa Gardner<BR>
<B>Room No.:</B>452<BR>
<B>E-mail:</B><A HREF="mailto:pg@doc.ic.ac.uk">pg@doc.ic.ac.uk</A><BR>
<HR><BR>To extend Xdpi, a peer-to-peer model for describing dynamicXML, with 
security types for analysing properties such as resource access 
control and data integrety<BR>
<HR><BR>Gardner and her PhD student Sergio Maffeis have recently introduced
Xdpi, a peer-to-peer model of the dynamic behaviour of XML. It is
based on an idealised model of XML, and an extension of the
pi-calculus (taught in the `Models of Concurrent Computation' course)
to model the underlying distribution layer. This model is used to
describe and analyse behaviour found in, for example, dynamic web page
programming, applet interaction, and service orchestration. 

The aim of this project is to extend  Xdpi with typing information to 
analyse security properties such as resource  access control
and data integrity, and to implement the resulting language.  This is
a challenging project suitable for somone interested in both theory
and practice.  It will be supervised by Gardner with Maffeis and
Ahern.  Ahern is a first-year PhD student who did an MEng project to
implement Xdpi.  Details for Xdpi can be found in the introductory paper 
called `Dynamic behaviour of Web Data' at http://www.doc.ic.ac.uk/~maffeis/

<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Extended Active XML: A Language for Integrating  Web Data</H2></CENTER>
<B>Supervisor:</B>Philippa Gardner<BR>
<B>Room No.:</B>452<BR>
<B>E-mail:</B><A HREF="mailto:pg@doc.ic.ac.uk">pg@doc.ic.ac.uk</A><BR>
<HR><BR>To extend Active XML  (a novel language for data integration based on exisitng XML standards) with mechamisms for process orchestration. <BR>
<HR><BR>
Active XML (AXML) is a declarative framework that harnesses web
services for data integration, and is put to work in a peer-to-peer
architecture. It is centered around AXML documents which are XML
documents that may contain calls to web services. The language allows
both the specification of such documents and the definition of new web
services based on them. While documents with embedded calls have
already been proposed, AXML is first to actually turn calls to web
services embedded in XML into a powerful tool for web-scale data
integration. Active XML is currently being developed by an industrial
research laboratory in Paris.

Active XML is similar to the Xdpi model of Gardner and her PhD student
Maffeis. Xdpi is based on XML and pi-processes  for describing the underlying
distribution layer (taught in the `Models of Concurrent Computation'
course), and unlike Active XML allows direct process interaction.
 The goals  of this project are to (1) extend Active XML to capture
much of the additional expressivity of Xdpi, whilst still retaining
the Active XML  spirit, and (2) to adapt the Active XML implementation to
this extension.  It would appeal to someone interested in using
existing XML standards in a novel way. Details can be found in two
introductory papers: the Active XML paper at
http://www-rocq.inria.fr/~abitebou/PRESENTATION/AXML-EDBT02.pdf and
the Xdpi paper, called `Dynamic behaviour of Web Data',  at
http://www.doc.ic.ac.uk/~maffeis/






<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Tools for Modelling Managed Systems</H2></CENTER>
<B>Supervisor:</B>Arosha Bandara and Emil Lupu<BR>
<B>Room No.:</B>553<BR>
<B>E-mail:</B><A HREF="mailto:bandara@doc.ic.ac.uk">bandara@doc.ic.ac.uk</A><BR>
<HR><BR>To develop/adapt a UML state chart editor that can be integrated into a formal approach for analysing systems management policies.<BR>
<HR><BR>Policy based management is a very flexible approach to managing distributed systems that allows the rules governing the behaviour of the system to be separated from the underlying functionality provided by the system.  Types of policies that could be specified include positive authorisations (permitted operations), negative authorisations (denied operations), obligations (operations that should be performed) and refrains (operations that should not be performed).  There is an existing language, Ponder, which supports specification of such policies.  For more information about Ponder and policy-based systems management see <a href="http://www-dse.doc.ic.ac.uk/policies/"> http://www-dse.doc.ic.ac.uk/policies/</a>.
<br><br>
Managing real-world systems will involve writing a large number of policies and it is critical that the policy specifications are free from conflicts and inconsistencies.  Conflicts could arise in a policy specification when two policies are specified using the same operations but have opposite modality (e.g. one policy permits a user to change a firewall rules table whilst another policy prohibits the same user from doing the same thing).  Ongoing research in the department has identified a formal approach for detecting conflicts in policy specifications that is based on Event Calculus.  This approach requires that, in addition to having a model of the policies themselves, it is necessary to model the behaviour of the system being managed.  However, the formal notation is quite verbose and not really suitable for users to interact with directly.
<br><br>
Therefore, it would be very useful to be able to define the behaviour of the managed system using UML state charts and then translate these state charts into the Event Calculus notation automatically.  The primary objective of this project is to develop a tool that will support this process.  Students may investigate existing UML modelling tools (e.g. ArgoUML) and adapt on of these to meet the requirements.  The final tool should integrate with the Prolog-based policy analysis system that has already been developed.
<br><br>
This project would be suitable for MEng/BEng (ISE/Comp) students who are interested in developing interactive graphical applications using Java.
<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Smart Web Browsing Tools</H2></CENTER>
<B>Supervisor:</B>Chris Hogger<BR>
<B>Room No.:</B>432<BR>
<B>E-mail:</B><A HREF="mailto:cjh@doc.ic.ac.uk">cjh@doc.ic.ac.uk</A><BR>
<HR><BR>To build tools that can help users to browse the websites that they commonly visit in a more effective fashion. Such a tool is to be constructed automatically from analysis of the user observed browsing activities.<BR>
<HR><BR>This project involves a combination of web technologies, AI techniques (mining and/or inference) and interface design. This project offers both practical and intellectual challenges.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Tool Support for Policy Analysis</H2></CENTER>
<B>Supervisor:</B>Emil Lupu and Arosha Bandara<BR>
<B>Room No.:</B>564H / 553H<BR>
<B>E-mail:</B><A HREF="mailto:ecl1@doc; bandara@doc">ecl1@doc; bandara@doc</A><BR>
<HR><BR>To develop an interactive tool that will support the partial automation of policy analysis together with a means of visualising the complex output of the analysis process.<BR>
<HR><BR>Policy based management is a very flexible approach to managing distributed systems that allows the rules governing the behaviour of the system to be separated from the underlying functionality provided by the system.  Types of policies that could be specified include positive authorisations (permitted operations), negative authorisations (denied operations), obligations (operations that should be performed) and refrains (operations that should not be performed).  There is an existing language, Ponder, which supports specification of such policies.  For more information about Ponder and policy-based systems management see <A href="http://www-dse.doc.ic.ac.uk/policies/"> http://www-dse.doc.ic.ac.uk/policies/</a>.
<br><br>
Managing real-world systems will involve writing a large number of policies and it is critical that the policy specifications are free from conflicts and inconsistencies.  Conflicts could arise in a policy specification when two policies are specified using the same operations but have opposite modality (e.g. one policy permits a user to change a firewall rules table whilst another policy prohibits the same user from doing the same thing).  Alternatively, policy specification could be considered inconsistent if there are policies that specify operations that cannot be performed (e.g. one policy obliges a firewall to log all changes to the rules but there is no mechanism for maintaining a log file).  At present, it is the responsibility of the administrators who specify the policies to ensure that conflicts and inconsistencies do not arise.   However, in large, distributed systems this can quickly become an onerous, if not impossible, task.  Therefore, there is a critical need for analysis techniques that can, at least partially, automate the task of detecting conflicts and inconsistencies in policy specifications. 
<br><br>
The overall objective of this project is to develop an interactive tool that will support the partial automation of policy analysis.  The tool will need to provide a means of visualising the complex output that will be generated by the analysis process – may involve using animation to illustrate the time varying nature of the output.  There is scope for students to develop new analysis techniques for detecting conflicts and inconsistencies in policy specifications; but it also possible make use of techniques already being developed as part of ongoing research.  It is expected that the tool will be integrated into the existing Ponder Policy Management Toolkit, which was developed using Java.  Some of the challenges of this project include designing an intuitive UI that supports specification of the system behaviour and the display of the analysis results, generating Prolog code from Ponder and interfacing to a commercial Prolog engine (Sicstus-3.9).
<br><br>
This project would be suitable for MEng (ISE/Comp) students who are interested in developing interactive graphical applications using Java.

<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>A Language for Updating XML</H2></CENTER>
<B>Supervisor:</B>Philippa Gardner<BR>
<B>Room No.:</B>452<BR>
<B>E-mail:</B><A HREF="mailto:pg@doc.ic.ac.uk">pg@doc.ic.ac.uk</A><BR>
<HR><BR>To  implement  a language for dynamically updating distributed
trees data (such as XML). <BR>
<HR><BR>Gardner and her PhD student Sergio Maffeis have recently introduced
Xdpi, a peer-to-peer model of the dynamic behaviour of XML. It is
based on an idealised model of XML, and an extension of the
pi-calculus (taught in the `Models of Concurrent Computation' course)
to model the underlying distribution layer. This model is used to
describe and analyse behaviour found in, for example, dynamic web page
programming, applet interaction, and service orchestration.

There is much experience with implementing languages based on the
pi-calculus, including very recent research by Gardner, Laneve and
Wischik (Bologne) and Meridith (Microsoft Redmond). The aim of this
project is to combine ideas from this new implementation work with
existing tools for querying and manipulating XML, to provide a
programming language for updating dynamic XML. This work follows
two implementation projects on this work, one by Ahern who has just 
started  a PhD at Imperial supervised by Gardner. The programming language
developed for this project will have a very different emphasis due to
the new implementation techniques associated with the pi-calculus.

Gardner, Maffeis and Ahern  will supervise this project.  This
project is suitable for someone with a good instinct for mathematics
and programming, and is fairly challenging. 
Details can be found in the introductory paper called `Dynamic behaviour
of Web Data' at http://www.doc.ic.ac.uk/~maffeis/
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Bibtex bibliographic database handling system</H2></CENTER>
<B>Supervisor:</B>Istvan Maros<BR>
<B>Room No.:</B>377, Huxley<BR>
<B>E-mail:</B><A HREF="mailto:im@doc.ic.ac.uk">im@doc.ic.ac.uk</A><BR>
<HR><BR>To design and implement a multi-functional front-end for creating, maintaining and querying Bibtex databases for Latex documents.<BR>
<HR><BR>Most scientific papers and also an increasing number of books are written using the Latex typesetting system. One of its most powerful features is its capability of including references from bibliographcal databases by its Bibtex system. Unfortunately, the creation and maintenance of such databases are not supported. Users have to create their own `databases' in the form of text files. The aim of the project is to design and implement a powerful front-end that supports the above in a user-friendly way including many advanced functionalities.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Bounds-checking for arrays and pointers in C++</H2></CENTER>
<B>Supervisor:</B>Paul Kelly<BR>
<B>Room No.:</B>423<BR>
<B>E-mail:</B><A HREF="mailto:phjk@doc.ic.ac.uk">phjk@doc.ic.ac.uk</A><BR>
<HR><BR>Extend the GNU C++ compiler so it generates code which catches array and pointer bounds errors at run-time.<BR>
<HR><BR>C++ applications are unnecessarily unreliable.  C++ programmers lives are unnecessarily short.  The reason is that C++ doesn't have bounds checking - if you accidentally increment a pointer too far, you can cause complete chaos.  
<p>
This is also an issue for security - buffer overrun attacks would be prevented if we could stop pointers being abused.
<p>
The trouble is that bounds checking is harder in C and C++ than in most languages.  The reason is that a pointer can be separated from the object into which it is supposed to point.  Thus with "A[i]" it's clear we should check i against A's bounds.  With "p = A; ... *p+100", it's not so easy - we need to know what storage object p is supposed to be pointing into.
<p>
I have a solution to this problem, which we have implemented for C; see 
<pre>
/homes/phjk/gcc-2.95.2-bounds-checking
</pre>
Your job is to do this for C++.  The plan is to patch the compiler's language-independent intermediate representation.
This is attractive as it should work with all source languages supported by gcc.  
The tricky bit is to avoid having to pad each allocated region, as this breaks the C++ ABI (it doesn't in C).  We have a plan, but it requires us to know the type with which each pointer is being used.
<p>
The goal would be to release a prototype to the open-source community during the spring, so your report can show some examples of major applications which have run with the system, and so you can report some bugs in famous open-source projects.
<p>
This is an ambitious project for a talented programmer with experience of open-source projects.  The payoff is building a tool that thousands of people will use.
<p>
For background see
<ul><li>Andrew Suffield, "Bounds Checking for C and C++".  Distinguished Dissertation - see <a href="http://www.doc.ic.ac.uk/~ajf/Teaching/Projects/DistProjects.html">http://www.doc.ic.ac.uk/~ajf/Teaching/Projects/DistProjects.html</a>
<li>Bounds checking for C - 1995 project by Richard Jones - see <a href="http://www.doc.ic.ac.uk/~phjk/BoundsChecking.html">http://www.doc.ic.ac.uk/~phjk/BoundsChecking.html</a>, now maintained at <a href="http://web.inter.nl.net/hcc/Haj.Ten.Brugge/">http://web.inter.nl.net/hcc/Haj.Ten.Brugge/</a>
<li>Play with Richard Jones's compiler at ~phjk/gcc-2.95.2-bounds-checking
<li>Play with Andrew Suffield's at ~phjk/bin/gcc-bc and ~phjk/bin/g++-bc
</ul>
For further background you should know about Greg McGary's work, and CCured, and material cited in Richard and Andrew's reports.




<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Communicating Agents(X)  <generic title, X can be your own id></H2></CENTER>
<B>Supervisor:</B>Jim Cunningham<BR>
<B>Room No.:</B>313 WP<BR>
<B>E-mail:</B><A HREF="mailto:rjc@doc.ic.ac.uk">rjc@doc.ic.ac.uk</A><BR>
<HR><BR>Identify a more specific topic by discussion with me<BR>
<HR><BR>The communicating agent group (http://comma.doc.ic.ac.uk) has had several EU and EPSRC projects in applications of distributed artificial intelligence in middleware and in futuristic communications interfaces for the evolving global infrastructure, including such things as automated negotiation in electronic commerce, virtual enterprises and the intelligent home.

We are also interested in more foundational work in the automation of rationality, learning and communication in multi-agent systems, including intelligent robotics, speech and natural language communication.

We draw on a wide range of technologies, from basic courses in AI, HCI, S/w Engineering and Graphics, as well as more specialised courses in Multi-Agent Systems, Natural Language Processing, Modal and Temporal Logics, Automated Reasoning and Vision. For instance, emerging Industrial Standards in Agent Communication have drawn on work in Knowledge Interchange and the Philosophy of Language. New systems for the representation of dynamic knowledge in multi-agent systems can use automated reasoning for modal and temporal logics in order to be be closer to human language. Emerging systems for dealing with complexity of the visual field probably need hybrid reasoning and the ability to learn.  Robotic systems can also benefit from integration with ideas on intelligent agents.

The group uses April and Qu-Prolog to provide multi-threaded agent technology. Email to speak with me if you have an interest in any of these areas.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Communicating Robot Agents</H2></CENTER>
<B>Supervisor:</B>Jim Cunningham<BR>
<B>Room No.:</B>421<BR>
<B>E-mail:</B><A HREF="mailto:rjc@doc.ic.ac.uk">rjc@doc.ic.ac.uk</A><BR>
<HR><BR>Develop a demonstration of co-operative communication using the multi-threaded April-level robots described under group projects. <BR>
<HR><BR>See the group project description http://www.doc.ic.ac.uk/~ih/gp/proposals/rjc-dja.html and be prepared to read in advance work related to dialogue on the Natural Language Processing course and to Communication and Planning in the Multi-Agent systems course. A possible demonstration would be cooperation to push a puck along a line. Requires a broad range of skills.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Multi-Threaded Natural Language Processing (X)</H2></CENTER>
<B>Supervisor:</B>Jim Cunningham<BR>
<B>Room No.:</B>421<BR>
<B>E-mail:</B><A HREF="mailto:rjc@doc.ic.ac.uk">rjc@doc.ic.ac.uk</A><BR>
<HR><BR>Use multi-threaded agent technology to help develop an architecture for interacting multi-layered, processing of language.  <BR>
<HR><BR>This is a research oriented project and really depends on the NLP course 485 to provide background on the many levels at which NLP takes place, and the MultiAgent Systems course 474. Agent technology is based on the integration of many sorts of processing, including reaction, planning and deliberation to give artificial intelligence in real time. Other background includes Pallotta's 2002 EPFL thesis on Cognitive Language Engineering, Alan Bond's Caltech Brain modelling, and our local work on temporal and sub-atomic semantics. A suitable case study for demonstration purposes will need to to be identified.

The (X) in the title is an indication that variants can be devised. For instance, one variant could emphasise speech processing.
 <BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>An Automated Environment for Analysing Requirements Specifications</H2></CENTER>
<B>Supervisor:</B>Alessandra Russo<BR>
<B>Room No.:</B>560<BR>
<B>E-mail:</B><A HREF="mailto:ar3@doc.ic.ac.uk">ar3@doc.ic.ac.uk</A><BR>
<HR><BR>This project involves implementing a tool that supports the development and analysis of event-driven requirements specifications. <BR>
<HR><BR>Event-driven requirements specifications can be seen as descriptions of how a system is supposed to react to the occurrence of events both within the system itself and in the environment. During the requirements engineering process, it is vital to be able to automatically check the consistency of such descriptions (even if only partially defined) with a given class of system properties (e.g. safety properties). A formal framework for supporting this task has been developed at Imperial, which uses abductive reasoning to provide diagnostic analysis of event-driven requirements specifications. 
<P>
This project involves building a tool that facilitates (a) the input of event-driven requirement specifications and system properties, and (b) the analysis of such specifications with respect to the given properties, by using the above-mentioned formal framework. In particular, the second task requires:
<P>
1)Mapping specifications and properties into a logic program of a particular form.
<P> 
2)Perform an abductive reasoning test on the logic program generated in (1) , so to collect information about parts of the specifications that are inconsistent with respect to the system properties. 
<P>
3)Map the result of the analysis back into the original representation of the specifications.
<P>
This is a challenging project, which requires a good understanding of classical logic. It is probably best suited for MEng students and Advanced Master students.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>An environment for integrating UML models and OCL specifications</H2></CENTER>
<B>Supervisor:</B>Alessandra Russo<BR>
<B>Room No.:</B>560<BR>
<B>E-mail:</B><A HREF="mailto:ar3@doc.ic.ac.uk">ar3@doc.ic.ac.uk</A><BR>
<HR><BR>This project aims to develop a tool that integrates UML models, based on class diagrams, with OCL specifications. <BR>
<HR><BR>UML is a very popular modelling language for software systems, and it encompasses different modelling techniques. Class diagrams are examples of one of these techniques. OCL is instead a formal language that allows the specification of constraints over class diagrams. Whereas various tools are already available for supporting the development of UML specifications, little has been done on the integration of UML with OCL constraints. 
<P>
This project involves the development of a tool that allows a user to 
<P>
(i)	define class diagrams and check for their correctness.
<P>
(ii)	specify grammatically correct OCL constraints, and 
<P>
(iii)	perform syntactic and type checking across the two specifications.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>ontology reasoner</H2></CENTER>
<B>Supervisor:</B>Keith Clark<BR>
<B>Room No.:</B>554<BR>
<B>E-mail:</B><A HREF="mailto:klc@doc.ic.ac.uk">klc@doc.ic.ac.uk</A><BR>
<HR><BR>To write a translater from XML repeesentations of ontologies in the OIL or OWL ontology language to Prolog so that the ontology can be  queried.<BR>
<HR><BR>Will need to learn about DCG Prolog based grammars, ontology languages and be happy with use of Prolog.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Hierarchical Image and Video Browser over the Web</H2></CENTER>
<B>Supervisor:</B>Stefan Rueger<BR>
<B>Room No.:</B>379<BR>
<B>E-mail:</B><A HREF="mailto:srueger@doc.ic.ac.uk">srueger@doc.ic.ac.uk</A><BR>
<HR><BR>The objective of this project is to build a "photo album" or "image gallery"
viewable over the web. It should be screen-aware, bandwidth-aware, dynamic and context aware.<BR>
<HR><BR>Although it is relatively easy to generate a simple
static browser of an image database, this project is more challenging.

<P>The Image Browser is expected to be screen-aware (ie utilise the full
physical screen of the user), band-width aware (ie, decrease resolution
for slow connections and pre-load/cache the images which are likely to be
viewed next), dynamic (so that results from  an image search engine can be
viewed), context-aware (so that annotations, if any, can be displayed
along with the images).

We have several pure image collections of up to 32,000 images which are
partially annotated. There exist backend image search engines which can be
integrated into the browsing process.

<P>Video Browsing should initially be the same as image browsing, ie, one can
expect that a video has been dissected into "shots" each of which is
represented by a key-frame image. When one clicks on a key-frame, the clip
should be played in this window.

We have some 100 hours of videos dissected into shots and key-frames with
annotations from speech recognition or teletext subtitles for these
collections.

<P>You should have good programming skills and know graphic libraries, preferably in Java, perl/cgi or similar.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Visualisation of simulated fluid flow - checkpointing, caching, cross-component optimisation</H2></CENTER>
<B>Supervisor:</B>Paul Kelly<BR>
<B>Room No.:</B>423<BR>
<B>E-mail:</B><A HREF="mailto:phjk@doc.ic.ac.uk">phjk@doc.ic.ac.uk</A><BR>
<HR><BR>Build a responsive, interactive tool which uses idle CPU cycles on local PCs to simulate fluid flow (eg milk mixing in tea), and allow a user to browse the
three-dimensional time-varying simulation results and explore flow properties.<BR>
<HR><BR>This project is about helping scientists understand complex fluid behaviour(such as our collaborators in Earth Sciences - see their great pictures at <a href="http://amcg.th.ic.ac.uk/research/ocean/top.html">http://amcg.th.ic.ac.uk/research/ocean/top.html</a>).  It's also about producing wonderful pictures.
<p>
Suppose we have a CFD (computational fluid dynamics) simulation, which takes a world description as input and produces snapshots of the 3d fluid state as output - perhaps 1GB per timestep.  We want to run this in parallel.  We want to plug it into visualisation tools (eg isosurfaces).  We need to interpose a selective subsampling component to keep the data size under control.  We need to cache intermediate results in order to move smoothly backwards and forwards in time.  We need to manage these caches to keep the space utilisation within bounds.
<p>
The project has been prototyped extensively in three earlier group projects, and we plan to build on a recent UROP project which uses the Python-based MayaVi visualisation framework.  Your job is to structure it in component form, and to construct component metadata so that the component composition layer can figure out 
<ul>
<li>how each (parallel) component should be distributed across the available machines, and 
<li>where caches should be introduced in order to allow the computation to be rolled back seamlessly.
</ul>
The caching element is used both to allow the user to re-examine earlier data in different ways, and to allow the computation to run on a set of idle PCs, and to recover when machines are removed.
<p>
To embark on this project you will need to know C and C++, and to learn Python.  You'll need to learn  a little about CFD, and a bit more about visualisation using vtk.  You must also be unafraid of getting to grips with other people's code.
<p>
This is a research project, and the main purpose is to explore cross-component optimisation in scientific applications - so it's vital to apply a principled approach based on your knowledge of the research literature, and it's essential to evaluate what you do experimentally.   
<p>
Tools: <a href="http://public.kitware.com/VTK/">VTK</a>, <a href="http://mayavi.sourceforge.net/">MayaVi</a><BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Peer-to-Peer Network Analysis</H2></CENTER>
<B>Supervisor:</B>Theodore Hong<BR>
<B>Room No.:</B>355<BR>
<B>E-mail:</B><A HREF="mailto:twh1@doc.ic.ac.uk">twh1@doc.ic.ac.uk</A><BR>
<HR><BR>To carry out simulations and performance analysis on the Freenet peer-to-peer file storage network, and suggest possible improvements in its design.<BR>
<HR><BR><p>Peer-to-peer networks have been much in the news as a medium for copying music or movies, but the peer-to-peer paradigm has far broader implications as a powerful generic platform for distributed computing.  For example, we could make overloaded webservers a thing of the past by automatically replicating files around the world in response to demand.  Other applications include efficient multicast, location-independent hyperlinking, and censorship resistance.
</p>

<p>
Freenet is one of the most widely deployed general-purpose peer-to-peer networks, but is very much under active development.  The aim of the project would be to investigate the performance of its routing and storage algorithms, examine the evolution of its network structure over time, and design and evaluate possible improvements.  This would be carried out through a combination of simulation and experiments on the live network.  If successful, you would be making a significant contribution towards advancing a current hot research topic.
</p><BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Automated Negotiation in the Game of Diplomacy</H2></CENTER>
<B>Supervisor:</B>Theodore Hong<BR>
<B>Room No.:</B>355<BR>
<B>E-mail:</B><A HREF="mailto:twh1@doc.ic.ac.uk">twh1@doc.ic.ac.uk</A><BR>
<HR><BR>To build a computer player for the strategic negotiation game Diplomacy.<BR>
<HR><BR><p>Many programs have been written to play two-player games, but few  
for multiplayer games, in which negotiation and communication become important.  Diplomacy(tm) is a popular board game in which  
seven players each take the part of one of the Great Powers of Europe  
just prior to the First World War.  Players command a number of armies  
and fleets which they use to fight for control of the various  
provinces of Europe.  In each round, the players' moves are sealed in  
secret and then simultaneously revealed.  A set of simple deterministic rules settles the outcome.  Like chess, Diplomacy is a completely strategic game with no dice or  hidden information.  Unlike chess, the key to success is not  
calculating the right moves, but negotiating with other players to  
form alliances, and (critically) stabbing them in the back when the  
time is right.  
</p>  
  
<p>  
The aim of the project is to build a computer Diplomacy player.    
Unrestricted negotiation is obviously far too complex, so to make the  
problem doable, you should develop a language (possibly logic-based)  
for expressing deals.  Negotiation can then be expressed   
as a sequence of exchanges of proposed deals, such as "Your army in  
Rumania supports my army in Warsaw attacking Galicia, in exchange for  
my fleet in the Black Sea withdrawing to Sevastopol."  There are  
several different modules that need to be built, including a move  
generator for coming up with possible move combinations, a  
negotiator for proposing and evaluating deals based on these  
combinations, and of course a graphic interface and move execution engine for actually playing  
the game.  Not much research has been done in this area before, so  
this could be quite a challenging but hopefully fun project!  
</p><BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Spam Filtering Using Machine Learning</H2></CENTER>
<B>Supervisor:</B>Theodore Hong<BR>
<B>Room No.:</B>355<BR>
<B>E-mail:</B><A HREF="mailto:twh1@doc.ic.ac.uk">twh1@doc.ic.ac.uk</A><BR>
<HR><BR>To build a more effective spam email filter using machine learning techniques.<BR>
<HR><BR><p>Spam email has become a serious problem, by some estimates accounting for more than half of all emails sent.  DoC has recently installed SpamAssassin, which attempts to distinguish spam from non-spam by assigning scores to various features found in incoming emails and seeing if the total score exceeds some assigned spam threshold.  The problem with this approach is that the features (and to some extent the scores) are created in an unprincipled, ad hoc way, and inevitably get out of date as spammers try to get around them.  In addition, the scores are black boxes that cannot be easily tuned or understood by the user.</p>

<p>A better way is to use machine learning to discover features automatically and build an explicit representation such as decision trees or inductive logic programs.  Such representations can show the user exactly why a particular email was classified as spam/not spam, and can be easily adjusted to fix mistakes.  The aim of this project is to build such a learner and to integrate it into a mail client such that the user can simply click a spam/not spam button to provide more training examples, and perhaps report spam to a blacklist service like Razor.</p><BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Projects in Artificial Intelligence</H2></CENTER>
<B>Supervisor:</B>Theodore Hong<BR>
<B>Room No.:</B>355<BR>
<B>E-mail:</B><A HREF="mailto:twh1@doc.ic.ac.uk">twh1@doc.ic.ac.uk</A><BR>
<HR><BR>If you have your own suggestions for projects based around AI topics, I would be happy to discuss them with you.<BR>
<HR><BR><BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Algorithm Animation</H2></CENTER>
<B>Supervisor:</B> Ian Moor<BR>
<B>Room No.:</B>355<BR>
<B>E-mail:</B><A HREF="mailto:iwm@doc.ic.ac.uk">iwm@doc.ic.ac.uk</A><BR>
<HR><BR>To construct a tool to display the state of programs in a graphical for.<BR>
<HR><BR>Many complex algorithms using structures are best explained visually, textbooks and lecturers often give a sequence of diagrams, a
step at a time. It would be much better to provide an animation of the program in action. 

To design and implement a tool to provide an animated view of the working of programs by displaying the program state in
a graphic form. A viewer should have control  over the speed and amount of detail visible and the format of the display. <BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Digital circuit schematic entry and simulation in an object-oriented language</H2></CENTER>
<B>Supervisor:</B>Ian Moor<BR>
<B>Room No.:</B>355<BR>
<B>E-mail:</B><A HREF="mailto:iwm@doc.ic.ac.uk">iwm@doc.ic.ac.uk</A><BR>
<HR><BR>To implement a easily-used and portable circuit simulator. <BR>
<HR><BR>
The project would consist of developing an object-oriented scheme for describing circuit components and their
interconnection and implementing a  schematic editor and circuit simulator in an objected-oriented language such as Java, C++.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>An Annotation Assistant for  the Static Checker for C Splint </H2></CENTER>
<B>Supervisor:</B>Ian Moor<BR>
<B>Room No.:</B>355<BR>
<B>E-mail:</B><A HREF="mailto:iwm@doc.ic.ac.uk">iwm@doc.ic.ac.uk</A><BR>
<HR><BR>To make Splint more user friendly by particularly by generating the annotations 
for   programs to be checked by splint. <BR>
<HR><BR><p>
Splint is a static C source checker, producing warnings for possible  use of null pointers, undefined variables and array bound errors. Annotations are often needed to override Splint's default assumptions and ambiguous properies in C .
For example using a pointer referencing an undefined location as an  argument to  a function is reported 
as an error, but it might  an output argument  of the function
<p>
 Annotations are written  as  specially formatted comments recognised by splint
to add information for the checking, for example  in a function argument declaration:
<pre>
  void   question(/*@out@*/ char * result) {
     ..
     *result = '?';
     ..
  } 
</pre>
  /*@out@*/  indicates that the argument is an output argument and a warning is only generated
 if *result is used before it is given a value.
<p>  
Manually adding annotations is difficult unless the user understands Splint  and 
what the program  is meant to do, but without annotations many of the warnings 
from Splint are useless.
<p>
 ESC/Java is a similar static checker for Java also using annotations. To reduce the time and effort of writing
annotations for ESC/Java the program 'Houdini'  an annotation assistant can be used to infer suitable annotations
for  Java programs.
Houdini  generates a  set of candidate annotations for a program and  uses ESC/Java as a subroutine to verify or refute 
the  annotations, removing invalid annotations. ESC/Java is finally run with the valid annotations and the result
is shown to the user.  
<p>
An program with the same purpose as Houdini should be constructed foe Splint.
<p>
<a href="http://www.splint.org"> Splint home page </a>    <br>    
<a href="http://research.compaq.com/SRC/esc/">ESC/Java  home page: </a> <br>
<a   href="http://gatekeeper.research.compaq.com/pub/DEC/SRC/technical-notes/abstracts/src-tn-2000-003.html">
Houdini report:</a>


<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Agent based simulation</H2></CENTER>
<B>Supervisor:</B>Keith Clark<BR>
<B>Room No.:</B>554<BR>
<B>E-mail:</B><A HREF="mailto:klc@doc.ic.ac.uk">klc@doc.ic.ac.uk</A><BR>
<HR><BR>To use a distrubuted LP language  for economic or social simulation<BR>
<HR><BR>See proposer<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Agents as logical objects</H2></CENTER>
<B>Supervisor:</B>Keith Clark<BR>
<B>Room No.:</B>554<BR>
<B>E-mail:</B><A HREF="mailto:klc@doc.ic.ac.uk">klc@doc.ic.ac.uk</A><BR>
<HR><BR>To implement an agent application using an OO extension of a multi-threaded Prolog system<BR>
<HR><BR>Suitable only for someone happy with programming in Prolog and familiar with OO programming. Ideally someone who has also done at least the introductory AI course.  Will involve using and further devloping an OO extension of a multi-threaded version of Prolog to implement the agents and the co-ordination strategies.  <BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Upgrading Java Programs (or .NET Programs) safely</H2></CENTER>
<B>Supervisor:</B>Susan Eisenbach<BR>
<B>Room No.:</B>569<BR>
<B>E-mail:</B><A HREF="mailto:sue@doc.ic.ac.uk">sue@doc.ic.ac.uk</A><BR>
<HR><BR>To enable a programmer to make changes to components and to ensure that the code will still do what the client of the components wanted it to do.<BR>
<HR><BR>Java code can be changed and the new code if it will link will be executed. Other than checking whether code will link (which has been done successfully in another project) how do you check that the code actually does what you wish it to do?

This is a currently active area of research and there are also implementation possibilities for a limited number of tests. The work focusses on invariant and pre/post condition checking.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Mobile Agents API</H2></CENTER>
<B>Supervisor:</B>Susan Eisenbach<BR>
<B>Room No.:</B>569<BR>
<B>E-mail:</B><A HREF="mailto:sue@doc.ic.ac.uk">sue@doc.ic.ac.uk</A><BR>
<HR><BR>Implement an API for Java or C# that gives a process algebra model (CSP, CCS, Pi, other) to Java. <BR>
<HR><BR><p>In the 1970s theoreticians came up with threads as a formal model for concurrency. In 1995 Java was released with threads as part of the programming language.</p>

<p>In the 1980s (and onwards until now) theoreticians came up with a variety of process algebras for modelling concurrency. So far no programming language has taken this model for its concurrency constructs. In this project you would implement an api for at least one of the process algebra models.</p>

<p>Build a system that uses the api. If you would like make it graphical.</p>

There is plenty of work to extend this to deal with mobility or to compare with other concurrent models.

Should be taking Models of Concurrency course. For a background paper there has been plenty of work on process algebras for dealing with mobility and distribution.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>A Typed Pattern-matching Language for Manipulating  XML </H2></CENTER>
<B>Supervisor:</B>Philippa Gardner<BR>
<B>Room No.:</B>452<BR>
<B>E-mail:</B><A HREF="mailto:pg@doc.ic.ac.uk">pg@doc.ic.ac.uk</A><BR>
<HR><BR>To design, implement  and validate a typed pattern-matching  language  for 
manipulating tree data such as XML<BR>
<HR><BR>XML and semi-structured data are prompting the development of a new
generation of programming languages, based on type systems that can
flexibly handle such self-describing and irregular data.  The goal of
this project is to implement a typed pattern-matching language for analysing
and manipulating trees, based on work by Gardner and Calcagno (Imperial),
Cardelli (Microsoft Research) and Ghelli (Pisa). The tree types are unusual,
since they are formulae in a new logic for reasoning about
trees. Tree data is manipulated via pattern-matching constructs that
perform `run-time type checks'.  Since trees types are formulae, we
have the full power of the logic to express the pattern-matching
conditions. The focus of the project is to design such a programming language
for manipulating tree data, provide an implementation of the language and 
study examples to  validate the design decisions. 

This project will be supervised by Calcagno and Gardner, and is challenging.
It is suitable for someone with  a strong interest in mathematics and 
programming.

<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>A Static Checker for XML</H2></CENTER>
<B>Supervisor:</B>Philippa Gardner<BR>
<B>Room No.:</B>421<BR>
<B>E-mail:</B><A HREF="mailto:pg@doc.ic.ac.uk">pg@doc.ic.ac.uk</A><BR>
<HR><BR>To develop the theoretical foundations and implementation of a tool for checking properties of  XML data at compile time.<BR>
<HR><BR>Commercial implementations of programming languages and tools for querying and manipulating XML guarantee little about the structure and properties of 
data. Spatial logics have been recently introduced for reasoning about
semi-structured data (such as XML), in order to provide the basis  for new 
type systems  and programming languages. One of the main challenges in the 
area is to  devise and implement decision procedures for these logics, to be used in static checkers such as type checkers and model checkers.  Last year Calcagno and Gardner supervised an MEng  project which set out to  validate the decision procedure
developed by  Calcagno (Imperial) and  Cardelli and Gordon (Microsoft Research). 
Although conceptually interesting, it turned out that a direct implementation would not scale to the size of realistic examples. This  project will focus on the application of  promising new theoretical results (announced in the last 6 months)  to (1) develop a different kind of  decision procedure,  (2) provide 
an  implementation of this procedure,  and (3) validate the implementation on  
realistic examples. 

This project will be supervised by Calcagno and Gardner and is challenging.
It  would appeal to someone with a strong interest both in  mathematics and programming (in particular efficient algorithms and data  structures), and 
has the potential to lead to publishable software or a reserach publication.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Theorem Provers for non-classical logics, for example Modal Logic or Linear Logic, using Translation</H2></CENTER>
<B>Supervisor:</B>Krysia Broda<BR>
<B>Room No.:</B>378<BR>
<B>E-mail:</B><A HREF="mailto:kb@doc.ic.ac.uk">kb@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>Given a logical problem it is possible to "compile" it into a set of simpler clauses that represent the problem. This has been fully worked out for  various  logics including modal logics and substructural logics. The latter are logics in which the structure of the data matters, in particular in the treatment of data as resources. However, other applications are possible - indeed for many different kinds of logic, such as a logic of granting permissions (used perhaps by a system for allowing access to servers).
<p>
There are several projects available, which would investigate one or more different families of logics. In particular, modal logics and substructural logics provide a rich variety. But there are others, for example a logic of obligations (deontic logic) or many-valued logics. The aim of the project is to build theorem provers for sets of sentences that result from the translations. Because these are of a simplified form, the theorem prover can often be specialised.
<p>
It is likely that Prolog would be the language of choice, but not necessarily!

<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Calculation Style Proofs</H2></CENTER>
<B>Supervisor:</B>Krysia Broda<BR>
<B>Room No.:</B>378<BR>
<B>E-mail:</B><A HREF="mailto:kb@doc.ic.ac.uk">kb@doc.ic.ac.uk</A><BR>
<HR><BR>To investigate the use of the OTTER theorem prover to do calculation style proofs.<BR>
<HR><BR>The book "A Logical Approach to Discrete Math" by D. Gries and F. Schneider
contains an interesting approach to reasoning. The authors present numerous rules of equivalences and implications between various logical statements and use these in a "calculator style" to prove theorems.
<p>
A simple propositional example is to show p or true equiv true.
p or true = p or (p equiv p) = (p or p) equiv (p or p) = true
This uses the rules true = p equiv p and distributivity of or over equiv.
<p>
The OTTER theorem prover is well known automated reasoning program that has been used to give several new proofs of famous problems. (See books by WOS.)
<p>
The aim of this project is to investigate how the proofs in Gries could be automated using OTTER. Although OTTER has  a very rudimentary (and perhaps slightly old fashioned) user interface, it can be used interactively.
<p>
The application of this project could be of use in tools for verification, in which many simple theorems need to be proved using various theories. Although OTTER doesn't enforce keeping theories separate, it would not be difficult to provide an interface which did so, making the organisaton of proofs easier to control.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Performance Engineering of Java Programs using State Models</H2></CENTER>
<B>Supervisor:</B>Tony Field and Jeff Magee<BR>
<B>Room No.:</B>376<BR>
<B>E-mail:</B><A HREF="mailto:ajf@doc.ic.ac.uk">ajf@doc.ic.ac.uk</A><BR>
<HR><BR>To extend a stochastic version of the Kramer/Magee LTSA system to generate and solve analytical performance models.<BR>
<HR><BR>Correctness and performance are two of the most important engineering issues in the development of complex software. The huge increase in the number of distributed applications, brought about by the presence of the internet, has served to highlight these issues. Ensuring that a program does what it is supposed to do and that it performs acceptably in terms of response time, scalability etc. have historically been treated as two separate issues.  Typically software engineers have tackled the former and independent performance analysts the latter.  This project is about unifying these activities through process algebra, with particular emphasis on the development of tools for predicting the performance of a distributed program.
<BR><BR>
An exciting way to tackle issue of correctness is to build a *model* of the software which describes in some abstract way the behaviour of the code in terms of allowable transitions in a state transition system.  Many tools have been developed to build and analyse such transition systems - the one many of you may have encountered is the LTSA system from the second-year distributed systems course, and the subject of Jeff Kramer and Jeff Magee's book 'State Models and Java Programs'.  A recent extension of the system (a Distinguished Project from 2002 - see http://www.doc.ic.ac.uk/~ajf/Teaching/Projects/DistProjects.html) allows the programmer to annotate an FSP program with both probabilities (e.g. on average the program will go this way 20% of the time and that way 80% of the time) and time delays (e.g. on average this action takes 20ms in the chosen platform).  From these annotations we now have a tool that will construct a discrete-event simulation model of the system, which is essentially a program that explicitly traverses the state space using random sampling.  The role of the simulation is to estimate performance properties of the application such as the mean response time or the average occupancy of a request buffer.  <BR><BR>
The simulation tool is very general, but can be slow for some systems as it involves walking over potentially very large state spaces until the performance estimates are within specified confidence intervals. The next stage in the LTSA development is to generate*analytical* models from the transition system when the appropriate conditions hold.  This project is about building and solving Markov Chains (themselves state transition systems), specifically in cases where the state holding times are all exponentially distributed.  Various methods exist for encoding probabilistic choice in Markov Chains and they can be solved to yield the equilibrium state probabilities using established algorithms.  All this can be explored, but possibly the best way to proceed is to interface LTSA with the DNAMICA system developed by William Knottenbelt which, give or take, holds the world record for the largest Markov Chain every solved!  DNAMICA takes a text input file describing a state transition system and the required performance measures etc. It then uses parallel processing to both build and solve the Markov Chain.  Evaluation of the tool with respect to a realistic case study will also add value to the project - there is considerable scope for publication of the proposed work.
<BR><BR>
Ideally you will have taken the second-year Concurrent Programming course.  It will also be beneficial if you have taken, or intend to take the third year course in Simulation and Modelling and/or Performance Analysis.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Theorem Proving using NAND expressions</H2></CENTER>
<B>Supervisor:</B>Krysia Broda<BR>
<B>Room No.:</B>378<BR>
<B>E-mail:</B><A HREF="mailto:kb@doc.ic.ac.uk">kb@doc.ic.ac.uk</A><BR>
<HR><BR>Build a flexible theorem prover for first order logic NAND expressions.<BR>
<HR><BR>Recently, Tor Sandquist, a PhD student from Finland, suggested automating deductions using formulas 
that use only the NAND operator. A first attempt at a theorem prover using this notation has been carried out (by Lin Yang MSC student 2003) and the aim of  this project is to improve and extend the method to include simplification and reduction steps. 
<p>
The system can also be used for model checking and can simulate other well known methods such as Davis Putnam procedure or model generation. Part of the project is to investigate these claims and to evaluate how useful the approach is as compared with other clausal provers.
<p>
Examples of expressions written in this language are
<br>[a b c] meaning not(a and b and c)
<br>[[a]b] meaning not(not a and b) (i.e. b -> a)
<br>[[a b]] meaning a and b
<br>[[a b] p [q [r p]]] meaning  - an exercise!<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>A Theorem Prover for Equality using Lemmas</H2></CENTER>
<B>Supervisor:</B>Krysia Broda<BR>
<B>Room No.:</B>378<BR>
<B>E-mail:</B><A HREF="mailto:kb@doc.ic.ac.uk">kb@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>A surprisingly good theorem prover is that based on a simple extension to Horn clause programming, called the method of Intermediate Lemmas. In this approach, derived clauses consist of positive literals only, which are used to derive more such clauses. These are called lemmas. This was implemented as a project last year.
<p>
The aim of the project is to investigate how equality reasoning can be incorporated into the method. Equalities are not easily dealt with in linear theorem provers based on the tableau method, but this method looks promising if it is incorporated with another idea, that of deriving equations which will enable two literals to match. The main theorem prover would be in two parts: part (i) using the usual Lemma method, and part (ii) using it also,  but for equality literals only.
<p>
A second aim is to try to include some compilation techniques into the prover, so that some of the overhead of interpretation is reclaimed.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Theorem Proving in the Logic of Only Knowing</H2></CENTER>
<B>Supervisor:</B>Krysia Broda<BR>
<B>Room No.:</B>378<BR>
<B>E-mail:</B><A HREF="mailto:kb@doc.ic.ac.uk">kb@doc.ic.ac.uk</A><BR>
<HR><BR>Investigation of the logic of Only Knowing in Otter and via a bespoke theorem prover.<BR>
<HR><BR>The logic of Only Knowing (OL) is a modal logic that can be used to express non-monotonic deduction.  A modal logic has operators such as "box", written as [], and []a can be read as a is believed, or a is necessary. It means that in all "worlds" I might consider that are related (in some sense) to the world I am in a is true. The logic of Only Knowing has three such operators, approximately, believe, don't believe, and exactly believe.
<p>
An outline for a theorem prover for this logic has been developed using a simple approach known as Labelled deductive systems. The first part of the project is to implement this prover (eg as a logic program) and also to try and implement a prover using an existing resolution theorem prover such as Otter. A comparison can be made of the two approaches.
<p>
The second part is to compare this approach with two others in the literature, also to be implemented using Prolog. 
<p>
Finally, an extension to first order logic can be attempted.
<p>
This project is probably most suitable for MEng and MAC students, but enthusiastic students with an interest in logic could also do it.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Learning Teleo-reactive Programs</H2></CENTER>
<B>Supervisor:</B>Krysia Broda<BR>
<B>Room No.:</B>378<BR>
<B>E-mail:</B><A HREF="mailto:kb@doc.ic.ac.uk">kb@doc.ic.ac.uk</A><BR>
<HR><BR>To use Inductive Logic Programming to learn TR programs<BR>
<HR><BR>Teleo-reactive (TR for short) programs are a set of simple condition - action rules. The conditions are propositions that become true according to an agent's perceptions of the world. For example, in a block world, these might be things like "seeing a tower of height 5" or holding a block. In a maze-world, a perception might be "way blocked". The rules form a program that has as its aim some goal, although that goal is not usually expressed explicitly within the rules. An "agent" or "robot"  carries out the rules in a program by continuously monitoring its perceptions and choosing the action of the first rule that is enabled. That is, the first rule for which all the conditions are true. Typical actions might be simple - switch on motors, move forward,  stop - or complex, eg pick up block, wander around, etc. It is supposed that under normal conditions an agent following a TR-program will reach its goal. There can, of course, be several agents all followgn the same program (clones) or different ones.
<p>
Writing TR-programs is not as simple as it seems at first sight. This is because, for a simple set of perceptions a robot might have the same perception for two different states, and, furthermore, ideally be required to carry out diffeernt actions in these two states to make good progress. Since it can only have one action for each perception some compromise is necessary.

<p>This project's aim is to see whether such programs can be learned. 
The idea is to write some simple programs and then to generalise them, possibly using inductive logic programming (ILP). For example, it is not too hard to write reasonable programs for block-world robots to build towers of small heights by fully analysing the relevant states and perceptions. For big towers this may be impossible. Two ways to deal with the more complex cases are to use ILP and produce programs with first order conditions (as opposed to propositions), or to generalise the idea of a perception, again using first order perceptions, but to apply the methods already pursued for the propositional case.

<p>The project is suitable for all students, but you should   have an interest in logic and logic programming.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Simulation Experiment Environment for TR-Robots</H2></CENTER>
<B>Supervisor:</B>Krysia Broda and Chris Hogger<BR>
<B>Room No.:</B>378<BR>
<B>E-mail:</B><A HREF="mailto:kb@doc.ic.ac.uk">kb@doc.ic.ac.uk</A><BR>
<HR><BR>To build a simulation environment for Teleo-reactive robots. <BR>
<HR><BR>Teleo-reactive robots (TRs for short) are robots designed to carry out simple tasks in their (limited) environment. Such robots have a finite (and small) action set and can perceive various features of the environment. For example, such perceptions might include holding something, seeing something of a particuar size or colour or being next to a wall. A program for such a robot is a list of rules of the form
<p>
	if "conjunction of perceptions"  then  action
<p>
which are continuously evaluated and the action corresponding to the first true conjunction in the list is the current action. Although the robot is not cognisant of any goal, the program is designed to achieve some task under "normal conditions". An example is the following simple program designed to build  towers of 3 blocks assuming a collection of blocks lying around, possibly in towers of other sizes. The robot can "pick-up-a-block", "place-a-block" or "wander", represented by K,L,W, respectively. The robot can sense if it is holding (h) or not-holding (nh) a block, and whether it is seeing a tower of size n (written as sn). A tower of size 0 means the robot is looking at the floor.

The actions are specified as:
<p>
K - before the action the robot must not be holding anything and be seeing a tower of size >=1; after it the robot is holding a block and seeing a tower of size 1 less than before.
<p>
L - before the action the robot must be holding a block and after it is seeing a tower of size 1 more than before.
<p>
W - the robot moves to a different position.

<p>
and the program is
<p>
if s3 then W  			(the robot can wander when it sees a 3-tower)
<br>if s2,h then L 				(build another 3-tower)
<br>if s2,nh then W 				(look for another block)
<br>if s1,h then L 				(start a tower)
<br>if sx, not (x=2), not (x=3),  nh  then K 	( here's a block)

<p>A feature of such programs is that if the environment changes as a result of external factors, the robot will simply adapt itself to the new situation. If, in the above environment the robot manages to build lots of 2-towers, and then there is a fierce wind which knocks them down, the robot simply recovers by building more towers!

<p>This is not the only program (or policy) for such a robot and we are interested in evaluating policies to find good ones.
<p>
The project is to build a simulation package for such robots. The particular robot environment could be one in which the robot carries out tasks such as laying tiles in some pre-arranged pattern on a floor, although other environments are possible and not excluded. The floor is a finite rectangular array of cells and at any time  each cell either contains a tile or it doesn't. A robot can occupy a cell whether that cell contains a tile or not and it can see the N, S, E, W immediate neighbours of the cell it occupies. It can wander directly only to one of those neighbours and can pick/place only from/upon one of those neighbours. (So, it can't place a tile under its own feet!).

<p>In this environment a state actually consists of a function 
<p>
	tile:cell position maps to {tiled, untiled} 
<p>(most simply represented by a set of the tiled positions), together with a number indicating how many  tiles are being held  by robots. So for example, if the world is a 5 x 5 square consisting of 25 cells numbered (0,0), (0,1),..,(0,4),(1,0),...,(4,4)  the following is a state (only tiled positions indicated, others assumed untiled):
<p>
	"tiled ={(1,1), (1,2), (2,3), (3,4),(4,0),(4,1)}, 1"

<p>
The simulation package will consist of the following parts:
<p>
1) An initialisation module that allows for various initial situations to be set up (including possibly more than one robot).
<p>
2) A simulation module that continuously monitors the state of the system and activates each robot accordingly. Note that there will be no need for concurrent execution. Each simulation will consist of a finite sequence of actions of the robot(s), which could have occurred.
<p>
3) A policy calculator that finds suitable policies and evaluates them to find those that are possibly good for simulation. eg a policy that has no chance of achieving the goal might be abandoned.
<p>
4) A graphics module to view simple simulations (useful for testing).
<p>
5) A data module to collect results and render them suitable for viewing.


<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Simulation of the Ocean Plankton Ecosystem</H2></CENTER>
<B>Supervisor:</B>Tony Field and John Woods<BR>
<B>Room No.:</B>376<BR>
<B>E-mail:</B><A HREF="mailto:ajf@doc.ic.ac.uk">ajf@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>Phytoplankton are unicellular plants which, the hours of daylight, absorb carbon dioxide and release oxygen through photosynthesis.  About 70% of the world's carbon dioxide is converted by them.  As well as being essential organisms in this respect they also have an interesting life cycle.  Becase they cannot swim their movement is dictated entirely by sea currents. Their depth in the ocean is determined by turbulence which in turn depends on local phenomena such as air temperature and wind speed and their lateral motion by ocean currents.  If the conditions are right, in terms of nutrient and energy, the phytoplankton can reproduce, increasing the population. At the same time they are grazed by small marine animals (zooplankton) with the opposite effect. They themselves are prey to species higher up the food chain such as fish larvae. 
<BR><BR>
Plankton populations are very hard to observe in the oceans and the only way that the population dynamics can be studied is by computer simulation.  This has already been done for a 1D model which you can think of as representing a water column which drifts around a given ocean circuit trajectory.  Inside the column are millions of particles each representing a sub-population of plankton of specifoed type.  These interact with their local environment and among themselves as the column drifts and as turbulence mixes them within the column. <BR><BR>
 Previous work by Computing students in this department has improved the basic model in a number of ways, for example: parallellisation of the code, support for phytoplankton size variability and epidemiological modelling tools. This work is already enabling exciting new science in biological oceanography with the promise of a great deal more to come.
<BR><BR>
There are numerous projects that I can offer in this area. Here is a taster; if the subject interests you but none of these appeals, come and talk to me...
<BR> <BR>
PROJECT 1:  Particle Management<BR>
As plankton populations increase (e.g. the spring phytoplankton 'bloom') the subpopulations grow rapidly in size and there is a significant increase in the sub-population variance over all particles.  This introduces biases, where big particles dominate small particles in the overall statistics. To reduce the variance we would like to split, and later re-combine, particles.  However splitting introduces more particles and therefore more computation.  Re-combining is fiddly because it is hard to know how to combine two dissimilar groups of individuals.  What we really need is a flexible particle management tool that will allow particle sizes to grow or shrink within user-specified bounds.  We also need to evaluate various strategies for recombination, in particular assessing the effect they have in comparison with the non-combining (but more expensive) approach.  It's all about trading off computation time for demographic noise (population variance measured over many runs).  This project will build on earlier work by an MSc student and will implement, refine and evaluate the particle management rules proposed specifically with a view to measuring the time/noise tradeoff. 
<BR><BR>
PROJECT 2:  Biodiversity and Stability<BR>
If you model a number of phytoplankton size groups at a fixed location you find that the climate at that location suits some 'bugs' better than others.  One size class is favoured abover the rest and the outliers are very gradually driven to extinction. Now the fun: in reality the water is constantly in motion, driven by large-scale currents (e.g. Atlantic Drift etc.)  So in reality the bugs are subjected to a constantly changing climate.  We would therefore reasonably expect that as the climate changes so the 'optimal' size class changes - perhaps colder water favours small bugs and warmer water big bugs, or vice versa.  So imagine an extreme case of motion - one where the water moves barotropically (upright) in a *closed* circuit and where the circuit spans a wide range of climatic conditions. It seems plausible that instead of some size classes being driven to extinction, the fluctuating conditions may instead move them into and out of 'favour', in other words leading to a system which is completely stable across all size classes around the circuit by virtue of changing geography and associated climate. Curiously the extinction rate in the fixed model is of the order of 100 years; the circulation time is typically of the order of 10 years - the stability story might be true! The aim of this project is to enhance the existing code to simulate biodiversity in a 'Geographically Lagrangian' system, i.e. a system with a moving water column, and investigate the population dynamics and stability of the drifting population.  There is a strong computing component to this project coupled with genuine scope for new and exciting scientific results in biological oceanography. 
<BR><BR>
PROJECT 3: Interfacing the model with the Grid via ICENI. The computational complexity of the simulation is arbitrarily large!  In practice there are far more plankton in the oceans than we could possibly imagine simulating as individuals.  We therefore work with sub-populations which helps, but the more particles (subpopulations) we have the better the results in terms of statistical noise. One way to do more in the same time is to exploit several processors.  There are two things we can do:  1. run identical experiments but with different random numbers on separate computers; 2. parallelise the code and distribute a single run over several different computers.  We could even combine the two. The latter involves parallelising a Java program.  How is this best done?  There may be a separate project here!
<BR><BR>
Interests:  You need to be interested in the idea of environmental modelling, although no prior expertise in either is required. An interest in 'using computers to do interesting science' is a definite plus.  The projects are not easy, however, so are best suited to students looking for more adventurous topics. The new version of the model and supporting system is in Java - you *must* be a proficient Java programmer!<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Virtual 3D Environments for Simulated Clay Pigeon Shooting </H2></CENTER>
<B>Supervisor:</B>Tony Field<BR>
<B>Room No.:</B>376<BR>
<B>E-mail:</B><A HREF="mailto:ajf@doc.ic.ac.uk">ajf@doc.ic.ac.uk</A><BR>
<HR><BR>To build and evaluate a 3D virtual reality shooting environment using the department's 3D visualisation facility<BR>
<HR><BR>Clay pigeon shooting is a form of moving target shooting which involves the hitting and 'breaking' of a circular clay target with small pellets discharged from a shotgun. The clay is typically around 4 inches in diameter and is projected through the air at varying heights and speeds with a trajectory similar to that of a discus. The shooter has several parameters which can be varied before deciding how to swing the gun. Static parameters include the size and number of pellets, the initial pellet velocity and the diamater of the barrel opening (choke). 

In order to hit a moving target the usual technique is to swing the gun so as to follow the target with the point of aim. The trigger is preferably pulled whilst the gun is in motion, allowing sufficient lead (aiming ahead of the target) to compensate for the delay between the trigger pull and the pellet cloud reaching the clay. 

In the field if a shooter misses it is often impossible to determine exactly where.  An experienced instructor can improve a shooter's consistency but they cannot visually track the pellet cloud.  Also, they cannot monitor exactly important factors such as barrel speed, point of aim, lead and so on.

The aim of this project is to build a 3D shooting environment to enable all of these factors to be measured as part of the interaction between a real shooter and a computer simulation of the environment and pellet cloud.  Part of the problem has already been implemented - see the prize-winning project by Asa Denton from 2003.  This constructs a virtual 3D environment, implements a complete model of the pellet cloud ballistics, and also provides a comprehensive front-end in the form of a computer game.  

What we want to do now is twofold and I am therefore proposing TWO coupled projects:  The first is about taking the current 2D visualisation (i.e. a conventional screen) and building instead a 3D visualisation using stereo projection.  It would be paarticularly nice to be able to replace the current virtual landscape with (a stereo photo of) a real one and maybe to integrate both real and virtual worlds. The second is concerned with the problem of tracking a real shotgun in the hands of the user and using the tracking system to replace the mouse in the current 'game'.  The tracking system problem was partly solved in a distinguished project by Simon Coulson in 2003 using a dual camera system trained on IR LEDs mounted on the barrel.  We learnt a lot from this project and I am particularly keen to re-run it using improved technology.  I have purchased a de-activated shotgun specifically for this project(!) and we have amassed a considerable amount of hardware for high-resolution frame capture.  With the system fully integrated there is scope for research into how users interact with a virtual environment with fast-moving targets.  How much better is 3D visualisation?  Is 2D good enough in some cases?

The tracking system is possibly well suited to an ISE student (not a requirement though). It's a nice combination of harwdare and software. Performance is crucial. You also need a trigger sensor mounted on the gun, but this is straightforward.

Interests: Prior knowledge of clay pigeon shooting is not required. You should, however, have a reasonable interest in computer modelling, virtual reality and computer graphics, depending on which of the two projects interests you. The core of the project is completely well specified but beyond that is open-ended. There is also considerable opportunity for commercial exploitation.  I would like to deliver a working and fully tested prototype by the end of the project.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Optimisation of Multi-threaded Java Programs</H2></CENTER>
<B>Supervisor:</B>Tony Field<BR>
<B>Room No.:</B>376<BR>
<B>E-mail:</B><A HREF="mailto:ajf@doc.ic.ac.uk">ajf@doc.ic.ac.uk</A><BR>
<HR><BR>To transform Java co-routines into a single-threaded program as a vehicle for reducing program execution time<BR>
<HR><BR>Co-routines are processes (or threads) with explicit methods to sleep the process for a given (or even unbounded) length of time, and to activate other processes. However, the rule is that only one process can be running at any time, even though several may be in the 'active' (or runnable) state.  Implicitly, therefore, there is a sequential flow of control among the co-routines since control flow is, in some sense, explicit.  

The objective of this project is to perform automatic transformation of multi-threaded Java byte code programs to produce a semantically equivalent program with a single thread.  The idea is to use continuations - the program is fragmented around yield points and the code that needs to be executed on return to a yield point is packaged as a method (the continuation).  The trick is to ensure that the correct methods are called with the correct environments.  This optimisation can yield speed-ups of around an order of magnitude in some process-oriented simulations, which make heavy use of Java's thread library.  There are, however, many other classes of application which can benefit.

Ideally, you should have done, or be doing, the Simulation and Modelling course which introduces co-routines in the context of discrete-event simulation and the Java class library which will be the target of the transformation tool.

There are some papers which point at the same idea but they're ad-hoc. Here we want to cast the optimisation in a continuation/fragmentation framework and possibly deliver more generic fragmentation tools as a result.  A successful implementation would produce at least publishable software and possibly also an accompanying research paper, suitable for a performance engineering tools conference or journal.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Predicting the Performance of Java Programs</H2></CENTER>
<B>Supervisor:</B>Tony Field<BR>
<B>Room No.:</B>376<BR>
<B>E-mail:</B><A HREF="mailto:ajf@doc.ic.ac.uk">ajf@doc.ic.ac.uk</A><BR>
<HR><BR>To build a tool that will compute an estimate of the execution time of a Java program<BR>
<HR><BR>Predicting the execution time of a program is crucial in any resource-sharing system when we want to compute for example an optimal schedule of jobs on a collection of resources.  The emerging computational grid is a good example - we need to schedule jobs taking account of many factors, e.g. completion time, resource requirements, cost etc. 

Imperial College is at the forefront of grid middleware technology and the integration of that technology with component-based scientific software. Currently the performance of a program is estimated by composing performance models of the individual components.  These models are currently entirely empirical - they are essentially look-up tables mapping problem size (parameters) to execution times on specific platforms based on execution time measurement. The approach is costly (pilot run time) and is infeasible for more than one or two parameters because of the size of the parameter space.  We'd like to be able to build simple mathematical models which, properly parameterised, will give a reasonable estimate of execution time, scalability etc.

The objective of this project is to build performance models of Java programs *automatically*  based on both compile-time analysis of the byte code and instrumentation of the running program.  The project will initially focus on the former, using the SOOT tools (http://www.sable.mcgill.ca/soot/) to walk the byte code.

This is a hard problem and it certainly won't work for all programs.  JIT compilers may also complicate the analysis. The objective is to see how far we can get using initially simple ideas.  More complexity can be added later.

This project is fairly high risk in the sense that the accuracy and applicability of generated models is very hard to predict ahead of time.  This is *not* a "safe implementation project!" but it *is* doable.  You need to be a competant software engineer and be comfortable working with other people's tools (SOOT in particular).  It is a good opportunity to learn more about the factors affecting Java program performance.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Parallel hypergraph partitioner</H2></CENTER>
<B>Supervisor:</B>William Knottenbelt<BR>
<B>Room No.:</B>371<BR>
<B>E-mail:</B><A HREF="mailto:wjk@doc.ic.ac.uk">wjk@doc.ic.ac.uk</A><BR>
<HR><BR>To create a hypergraph partitioner.<BR>
<HR><BR>Hypergraphs are extensions of graph data structures that can be used to perform efficient and accurate data partitioning for distributed sparse matrix vector multiplication (amongst many other applications including VLSI circuit partitioning). Your task would be to create your own distributed/parallel hypergraph partitioner and compare its performance against 2 benchmark tools. 
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Fluid Stochastic Petri net Analyser</H2></CENTER>
<B>Supervisor:</B>William Knottenbelt<BR>
<B>Room No.:</B>371<BR>
<B>E-mail:</B><A HREF="mailto:wjk@doc.ic.ac.uk">wjk@doc.ic.ac.uk</A><BR>
<HR><BR>To develop an analyser for Fluid Stochastic Petri nets<BR>
<HR><BR>Fluid Stochastic Petri nets are Petri net models that incorporate fluid flows, as well as the usual flow of discrete tokens. They can be used for modelling phenomena such as the accumulation of errors in software, as well as various biological homeostatic processes. Your job would be to create an editor/simulator/analyser for fluid stochastic Petri nets that could produce performance statistics from a high level model.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Deterministic and Stochastic Petri nets analyser</H2></CENTER>
<B>Supervisor:</B>William Knottenbelt<BR>
<B>Room No.:</B>371<BR>
<B>E-mail:</B><A HREF="mailto:wjk@doc.ic.ac.uk">wjk@doc.ic.ac.uk</A><BR>
<HR><BR>To develop an analytical tool for solving for performance measures of a Deterministic and Stochastic Petri net.<BR>
<HR><BR>Deterministic and Stochastic Petri nets are Petri nets models that include exponential, immediate and deterministic delays. They are useful for modelling many concurrent systems e.g. communication protocols with deterministic timeouts. Your job is to devise an analytical engine which can solve for the steady state (and hence performance measures) of such a system. You can make any simplifying assumptions you need (e.g. only one deterministic transition is enabled in any marking). You will need to be good at maths and have the ability to work largely independently (there are a wealth of good papers on this topic).<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Response time distributions in concurrent systems</H2></CENTER>
<B>Supervisor:</B>William Knottenbelt     <BR>
<B>Room No.:</B>371, Huxley <BR>
<B>E-mail:</B><A HREF="mailto:wjk@doc.ic.ac.uk">wjk@doc.ic.ac.uk</A><BR>
<HR><BR>The aim of this project is to devise an analysis tool that can automatically calculate response time distributions from a stochastic specification of a concurrent system<BR>
<HR><BR>Conventional steady state analysis of concurrent systems (whereby we
compute the long-term average time the system spends in each state) is inadequate for calculating more advanced performance measures such as (a) response time quantiles and distributions in client-server systems (e.g. can we guarantee that 95% of transactions will complete within 5 seconds)
(b) passage times in protocols (e.g. what is the distribution of the time it takes for a packet to be successfully transmitted from the sender to a receiver) 
and (c) cycle times in queueing networks. 

The idea of this project is to produce a tool that takes a specification of system, a description of the source and target states (between which the response time is required) and a range of time values over which the distribution should be plotted. The project will involve programming in C++
(possibly in parallel), some maths, Markov chains, Petri nets and Queueing networks.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Semi-Markov Chain analyser</H2></CENTER>
<B>Supervisor:</B>William Knottenbelt<BR>
<B>Room No.:</B>371<BR>
<B>E-mail:</B><A HREF="mailto:wjk@doc.ic.ac.uk">wjk@doc.ic.ac.uk</A><BR>
<HR><BR>To develop an automatic analyser for the specification and steady-state solution of semi-Markov chains.<BR>
<HR><BR>Markov chains are widely used as a low-level system representation in the performance modelling of systems. Queueing networks, stochastic Petri nets and process algebras can all be mapped onto Markov chains. Unfortunately Markov chains are somewhat restricted in their assumptions (e.g. all delays in the system must be exponentially distributed). Semi-Markov chains are extensions of Markov chains that do away with some of the restrictions without making the analysis intractable. Your task would be to develop a (possibly distributed) analyser that allows for the high-level specification and solution of semi-Markov chains.
<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Hypergraph visualiser</H2></CENTER>
<B>Supervisor:</B>William Knottenbelt<BR>
<B>Room No.:</B>371<BR>
<B>E-mail:</B><A HREF="mailto:wjk@doc.ic.ac.uk">wjk@doc.ic.ac.uk</A><BR>
<HR><BR>To create a hypergraph visualiser that can be used to produce a guided hypergraph partition.<BR>
<HR><BR>Hypergraphs are recent data structures that can be applied to produce efficient data partitionings for parallel-sparse matrix vector multiplication (a key operation in many numerical computations). Your task is to produce a hypergraph visualiser which shows a visual representation of a hypergraph and then allows users to move the vertices and partitions around until they have obtained a good partition.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Parallel chess computer</H2></CENTER>
<B>Supervisor:</B>William Knottenbelt<BR>
<B>Room No.:</B>371<BR>
<B>E-mail:</B><A HREF="mailto:wjk@doc.ic.ac.uk">wjk@doc.ic.ac.uk</A><BR>
<HR><BR>The aim of this project is to build a chess computer that runs in parallel over a network of workstations, and to compare its performance against human and other computer players.<BR>
<HR><BR>In our computer labs we have banks of 2GHz PCs each with 1GB RAM that sit idle for most of the day. Using a parallel programming interface (such as PVM or MPI) and C++ can you harness their joint processing power to build a good chess computer? 

You will be able to see how your chess computer compares to other human and computer players by attaching it to one of the several free chess networks (see e.g. http://www.freechess.org).
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Team Strategies for Blackjack</H2></CENTER>
<B>Supervisor:</B>William Knottenbelt<BR>
<B>Room No.:</B>371<BR>
<B>E-mail:</B><A HREF="mailto:wjk@doc.ic.ac.uk">wjk@doc.ic.ac.uk</A><BR>
<HR><BR>To assess the money-making potential of team playing strategies for Blackjack.<BR>
<HR><BR>Blackjack (Twenty-one) is unique amongst casino games in that is not memoryless - i.e. the cards that have appeared so far affect the likelihood of the cards that will appear in the future. The book "Bringing Down the House: The Inside Story of Six MIT Students Who Took Vegas for Millions" by Ben Mezrich describes a team playing blackjack scheme which is designed to exploit this fact. Your job would be to devise a simulation (pref. a large scale parallel one) or an analytical technique to evaluate the money-making potential of the scheme. Does the scheme really make money? How much money do you need to invest to make a given profit? What is the variance on the return? Can you design a better scheme?<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>A news-based automatic stockmarket trading system</H2></CENTER>
<B>Supervisor:</B>William Knottenbelt     <BR>
<B>Room No.:</B>371, Huxley <BR>
<B>E-mail:</B><A HREF="mailto:wjk@doc.ic.ac.uk">wjk@doc.ic.ac.uk</A><BR>
<HR><BR>To develop a stockmarket trading system that rapidly analyses stockmarket news reports and makes buy/sell decisions automatically.<BR>
<HR><BR>Hundreds of companies announcements (final results, director share holdings, profit warnings etc.) are made every day. These announcements can have
a profound effect on share prices. It seems reasonable that being able to instantly and automatically analyse and react to these news reports might 
give traders an advantage over others who take longer to obtain and interpret the news. The challenge is to build a trading system that outperforms the market by analysing and trading in reaction to real-time stock market announcements.

You will be expected to:
(a) write tools for obtaining real-time news data off financial web sites.
(b) devise a theoretically sound mechanism for rating articles according to   buy/sell signals.
(c) demonstrate and quantify how the performance of your system compares to a     buy/hold or other strategy.
(d) develop a real time tool that draws attention to significant news articles as they are released. <BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>A Compiled Labelled Deductive System (CLDS) for process algebra</H2></CENTER>
<B>Supervisor:</B>Alessandra Russo & Krysia Broda<BR>
<B>Room No.:</B>564<BR>
<B>E-mail:</B><A HREF="mailto:{ar3,kb}@doc.ic.ac.uk">{ar3,kb}@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>This project aims to develop a CLDS for process algebra building upon existing results on logics for process algebra such as mu-calculus. 
<P>
The CLDS framework facilitates the development of a labelled natural deduction system for a logic that is (a) suitable for application and (b) more amenable to automation. This is achieved by combining the underlying logic with a specialised first-order theory that allows reasoning on the semantic properties of the logic. 
<p>
A particular logic has been already developed for an extended pi-calculus that has been shown to be sound with respect to the calculus. Such algebra has also been shown to be particularly suitable for formalising and reasoning about concurrency. However no full completeness proof has been so far developed. 
The CLDS framework gives an alternative way of formalising such algebra and 
possibly proving a completeness result.
<P>
The project will consist of two parts. Part I is to formalise the algebra as a CLDS in terms of either a labelled tableau or labelled nantural deduction system. Part II will give a choice between the following two options. One is to  prove formal results such as soundness and comleteness of the CLDS with respect to the algebra, and the second option is to develop a theorem prover using CLDS.
<P>
This project is particularly suitable for fourth year MEng or advanced MSc students.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Formalising Hybrid Logic as a Compiled Labelled deductive System (CLDS)</H2></CENTER>
<B>Supervisor:</B>Alessandra Russo & Krysia Broda<BR>
<B>Room No.:</B>564<BR>
<B>E-mail:</B><A HREF="mailto:ar3@doc.ic.ac.uk">ar3@doc.ic.ac.uk</A><BR>
<HR><BR> <BR>
<HR><BR>This project aims to develop a CLDS for hybrid logic, a particular non-classical modal logic. The CLDS framework facilitates the development of a labelled natural deduction system for a logic that is (a) for suitable for application and (b) more amenable to automation. This is achieved by combining the underlying logic with a specialised first-order theory that allows reasoning on the semantic properties of the logic. 
<p>
Hybrid logic is a particular modal logic that uses the concept of "label" to name possible worlds, as in CLDS. However such labels are considered to be part of the logical language, whereas in CDS they are orthogonal to the logic. This kind of logioc has been used to model temporal systems. 
<P>
The project will consist of two parts. Part I is to formalise Hybrid logic as a CLDS in terms of either a labelled tableau or labelled lantural deduction system. Part II will give a choice between the following two options. One is to  prove soundness and comleteness results and the correspondence between the CLDS formalisation and the original hybrid logic, and the second option is to develop a theorem prover using CLDS.
<P>
This project is particularly suitable for fourth year MEng or advanced MSc students.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Genetic algorithm for university timetabling</H2></CENTER>
<B>Supervisor:</B>Istvan Maros<BR>
<B>Room No.:</B>377<BR>
<B>E-mail:</B><A HREF="mailto:im@doc.ic.ac.uk">im@doc.ic.ac.uk</A><BR>
<HR><BR>To design and implement a genetic algorithm that is capable of creating university timetables.<BR>
<HR><BR>Creating university timetables is a very complex task. There are many constraints (hard and `soft') that have to be satisfied along with some quality criteria regarding the `goodness' of the timetable. The situation is just complicated by the fact that several courses are offered to different groups of students. Ideally, a clash-free timetable should be created. There is a huge number of possible allocations many of which are simply infeasible (do not satisfy hard constraints). For the (approximate) solution of this combinatorial problem a genetic algorithm has to be designed, implemented and tested on real departmental data.

<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Journal Assistant</H2></CENTER>
<B>Supervisor:</B>Istvan Maros<BR>
<B>Room No.:</B>377, Huxley<BR>
<B>E-mail:</B><A HREF="mailto:im@doc.ic.ac.uk">im@doc.ic.ac.uk</A><BR>
<HR><BR>To provide an interactive tool for assisting the work of the Editor
of a scientific journal.<BR>
<HR><BR>The process of editing a scientific journal involves
(a) handling the submitted papers,
(b) keeping track of the refereeing process
(c) preparing regular and special issues and volumes,
(d) maintaining a database of the editorial board, referees and authors,
(e) general archiving.

The project should create a database with a graphical user interface (GUI) to
assist the editor. Ideally, the project would cover all aspects.
However, "Refereeing Assistant" for handling the submitted papers is a
minimum requirement.

Working knowledge of a database management system and familiarity with
GUI are needed.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Communicating distributed agents</H2></CENTER>
<B>Supervisor:</B>Fariba Sadri<BR>
<B>Room No.:</B>447<BR>
<B>E-mail:</B><A HREF="mailto:fs@doc.ic.ac.uk">fs@doc.ic.ac.uk</A><BR>
<HR><BR>To program a collection of logic based agents that can plan and react to their environment and that can communicate with the
environment and each other for co-operative tasks.
<BR>
<HR><BR>We have a Prolog implementation of the reasoning model of single agents. The project involves an integration of such a model within a distributed system to build a community of communicating agents that negotiate about resources and activities.  Anyone taking on this project is required to attend or have attended a logic programming course (e.g computatational logic or automated reasoning) and the multi-agent systems course.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Adaptive webserver for serving dynamic resources</H2></CENTER>
<B>Supervisor:</B>Julie A. McCann<BR>
<B>Room No.:</B>557<BR>
<B>E-mail:</B><A HREF="mailto:jamm@doc.ic.ac.uk">jamm@doc.ic.ac.uk</A><BR>
<HR><BR>To build and experiement with an adaptive webserver.<BR>
<HR><BR>Adaptive and self-adaptive systems are becoming more prevalent methods of building computing systems today. This project requires the student to build an adaptive system for serving dynamic webpages. In this project, the dynamic resources will be servlets and JSP served by the open source Java based Apache Tomcat. The student will have to build an adaptation engine, which will be driven by rules defined using XML. The Patia project uses similar rules expressed in BNF and the student can port the latter to XML. The student is expected to eventually run experiments to investigate the performance of the XML based adaptation engine. For this purpose, a testbed made up of 8 PCs running Linux is available in a 100 Mbps switched Ethernet. In order to carry out this project, the student is expected to be proficient in Java. Knowledge of the following will be picked up in the course of the project:

[a] Understanding of how Apache Tomcat works in order to write the adaptation engine to interface with it.
[b] Servlet and JSP specifications
[c] XML
[d] Linux (a basic understanding of Linux will be helpful in setting up the testbed)

All the documentation and resources required for this project are open source and readily available.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Web server request redirector</H2></CENTER>
<B>Supervisor:</B>Julie A .McCann<BR>
<B>Room No.:</B>557<BR>
<B>E-mail:</B><A HREF="mailto:jamm@doc.ic.ac.uk">jamm@doc.ic.ac.uk</A><BR>
<HR><BR>To build a redirector that takes HTTP requests and redirects them to another server.<BR>
<HR><BR>In this project, the student will build a redirector that "sits" in front of a pool of dynamic web servers and redirects HTTP requests from clients (web browsers) to one of the web servers. This redirection has to be transparent to the clients. The redirector will have to be configurable such that a number of criteria can be used to decide the redirection such as load balancing, requested resource requirements. The redirector will also have to cater for the fact that servers may join and leave the pool at any time. The development platform will be Linux and modification of TCP implementation at kernel level will be required. Hence the student must be proficient in C and comfortable with such tinkering of the Linux kernel.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Modelling Biological Interaction by Concurrent Atoms of Mobile Processes </H2></CENTER>
<B>Supervisor:</B>Nobuko Yoshida<BR>
<B>Room No.:</B>556<BR>
<B>E-mail:</B><A HREF="mailto:yoshida@doc.ic.ac.uk">yoshida@doc.ic.ac.uk</A><BR>
<HR><BR>See http://www.doc.ic.ac.uk/~yoshida/project.html
<BR>
<HR><BR><BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Liveness and Safety Guarantee by Type Checking of Mobile Processes </H2></CENTER>
<B>Supervisor:</B>Nobuko Yoshida<BR>
<B>Room No.:</B>556<BR>
<B>E-mail:</B><A HREF="mailto:yoshida@doc.ic.ac.uk">yoshida@doc.ic.ac.uk</A><BR>
<HR><BR>See http://www.doc.ic.ac.uk/~yoshida/project.html
<BR>
<HR><BR><BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Security Guarantee in Mobile Agents </H2></CENTER>
<B>Supervisor:</B>Nobuko Yoshida<BR>
<B>Room No.:</B>556<BR>
<B>E-mail:</B><A HREF="mailto:yoshida@doc.ic.ac.uk">yoshida@doc.ic.ac.uk</A><BR>
<HR><BR>See http://www.doc.ic.ac.uk/~yoshida/project.html
<BR>
<HR><BR><BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Programming Language-Based Security by Type-Checking </H2></CENTER>
<B>Supervisor:</B>Nobuko Yoshida<BR>
<B>Room No.:</B>556<BR>
<B>E-mail:</B><A HREF="mailto:yoshida@doc.ic.ac.uk">yoshida@doc.ic.ac.uk</A><BR>
<HR><BR>See http://www.doc.ic.ac.uk/~yoshida/project.html
<BR>
<HR><BR><BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>UbiShop an intelligent supermarket (ubiquitous computing)</H2></CENTER>
<B>Supervisor:</B>Julie A McCann<BR>
<B>Room No.:</B>557<BR>
<B>E-mail:</B><A HREF="mailto:jamm@doc.ic.ac.uk">jamm@doc.ic.ac.uk</A><BR>
<HR><BR>To build a system that emulates an intelligent shop by taking sensor information from food products and carries out stock control and purchasing.<BR>
<HR><BR>The UbiShop is a normal shop with a wireless network and where RF-Tags, which comprise of small labels, replace traditional barcodes on the products. The RF tags uniquely identify each product and are constantly transmitting the “presence” of the product to RF-receivers effectively positioned on a shopping trolley. When the consumer enters the supermarket he/she joins the UbiShop system. The system identifies the user and displays their shopping list (missing products) to the shopping trolley display screen. While shopping at the supermarket, the consumer selects products from the shelves as usual. The readers on the shopping trolley can understand when the products are placed in and also retrieve their price and other information, updating the consumer’s shopping list from the retailers’ servers. The shopping trolley may also display in-store promotions that are based on previous consumer buying behaviour or cross-selling product associations. At the checkout counter, there is no need to scan the products again. Instead, the “smart” shopping trolley notifies the cashier, sends the shopping-list data to the checkout system and the payment receipt is issued, while the store inventories can be updated. The customer’s shopping list information is maintained in the system as point of sales data to be used for future promotional activities.

Meanwhile back at home the smart fridge and cupboards see these new products and update their databases accordingly. They effectively create the original shopping list for the customer.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Happy Hal (ubiquitous computing/HCI/multimedia)</H2></CENTER>
<B>Supervisor:</B>Julie A, McCann<BR>
<B>Room No.:</B>557<BR>
<B>E-mail:</B><A HREF="mailto:jamm@doc.ic.ac.uk">jamm@doc.ic.ac.uk</A><BR>
<HR><BR>to build a friendly interface to a ubiquitous compuing system manager<BR>
<HR><BR>We are seeing a move toward the 3rd wave in computing – Ubiquitous Computing. This is where many computers are made available throughout the physical environment, while effectively being invisible to the user. One such environment would be the home. An application of Ubicomp in the home is that of Medical care. Here the patient is being monitored in terms of temperature, movement, heart rate, food consumption etc The aim of the Ubicomp environment is to make sure the patient is healthy and safe. I am about to start a project that will look after a Ubicomp environment in the home. My project aims to build middleware (namely ANS: Autonomic Networked System) to allow the data from all the differing sensors to be collected and that the system knows what to do when something goes wrong either with the patient or with the system itself. 

This project will look at the user interface for the patient. That is, the ANS system gets a friendly face. This system should have a history/personality and also be able to not only alert the patient when something goes wrong but chat to the patient when they are lonely. This is a fun project with lots of potential. It involves the student getting to know Ubicomp, HCI, graphics, multimedia, perhaps even voice recognition etc with a medical/social application. 

Enthusiastic students only need apply :-)
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Java for Beginners IV </H2></CENTER>
<B>Supervisor:</B>Susan Eisenbach         <BR>
<B>Room No.:</B>569, Huxley <BR>
<B>E-mail:</B><A HREF="mailto:sue@doc.ic.ac.uk">sue@doc.ic.ac.uk</A><BR>
<HR><BR>take the first year programming IDE and make it better (add reasoning capabilities into it) note successful projects will be used by at least 150 students in the following year<BR>
<HR><BR><p>Introductory imperative programming is aimed at teaching beginners how to solve small (e.g. 100 lines) problems using appropriate control and data structures. Although Java is a language that everyone wants to know it lacks simplicity, so it isn't an ideal language to teach basic imperative constructs. Students however would like to learn Java as early as possible. The aim of this project is to reconcile this conflict.</p>
 
<p>
The HelloWorld program in Java is</p>
class HelloWorld{</p>
  public static void main(String[] args){</p>
  System.out.println("Hello World");</p>
  }</p>
}</p>

whereas in Turing it is</p>
put "Hello World"</p>
<p>
Input in Java makes output look straightforward.</p>
<p>
This is the fourth year this project is running. The first year this project produced an IDE and language called Kenya that we used in first year teaching. The next year's project produced an interpreter for the language so students could single step through their Kenya programs, set breakpoints, look at variables, etc. Last year's project wass to improve the debugger (e.g. put single step backwards).
</p>
<p>This year's project is to extend the intepreter with support for Program Reasoning such as support for pre and post conditions and loop invariants.
system.</p>
<p>This is an area of active research. Your work will also be of use to others if you are successful.</p>
<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Compiler Tools for C#</H2></CENTER>
<B>Supervisor:</B>Susan Eisenbach<BR>
<B>Room No.:</B>569<BR>
<B>E-mail:</B><A HREF="mailto:sue@doc.ic.ac.uk">sue@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR><h4>Motivation</h4>

I have run projects written in C# for a few years. Java programmers seem to really like C# because they can write Java-like code but get the advantages of a faster development/run-time system. They also like that the graphics provided compared with Swing. C++ programmers prefer it to Java, saying it is much less restrictive.
<p> 
There are many compiler tools (and APIs for walking over Abstract Syntax trees) available for Java but these don't seem to be available for C#. The lack of these tools restricts the development of of a certain class of projects
</p>

<h4>Objective</h4>
C# programs, when compiled produce an AST like structure called CodeDom. The aim of this project is to make the information held in CodeDom available in a useful way.

<h4>What you might do</h4>
<ol>
<li>Investigate the world of compiler tools.</li>
<li>Choose what you are going to implement.</li>
<li>Design and implement what you would like.</li>
<li>Design a small application that uses your API to see how it works.</li>
<li>Improve your API in the light of what you learnt when you used your it.</li>
</ol>
<h4>Person Specification</h4>
This project requires an confident programmer who likes compiler technology and would like to work in C#. The courses Advanced Issues in Object Oriented Programming and Program Analysis should be taken. Depending on what is implemented this could be a research/implementation project or a straight implementation project.
<p>
If you would like to do something similar to this but not what I have described, I would be happy to discuss your ideas for a project.
</p> <BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Code Comprehension Tools (for Eclipse)</H2></CENTER>
<B>Supervisor:</B>Susan Eisenbach<BR>
<B>Room No.:</B>569<BR>
<B>E-mail:</B><A HREF="mailto:sue@doc.ic.ac.uk">sue@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR><h4>Motivation</h4>

In 2003 a former Imperial student (MEng + Ph.D.) Diomidis Spinellis published a book called <i>Code Reading: The Open Source Perspective</i>. Diomidis when at Imperial showed himself to be an outstanding programmer. One of his skills was the ability to read and understand other people's code. Given the amount of time most people spend in trying to understanding other people's code (and for some people their own code) any help is welcome.
</p>
<p>
Last year there was a distinguished project on Code Comprehension. The student, Russ Wood built a framework for code comprehension tools and populated it with a variety of tools. There were many advantages to his approach, but in the length of time of an individual project useful tools for a large language could not possibly be written. 
</p>

<h4>Objective</h4>
For Java programmers an IDE of choice seems to be IBM's Eclipse system. Eclipse has a plugin architecture. Open source developers can write tools that can be used within the Eclipse environment. Eclipse has many tools already that make the programming (and probably the understanding process) easier. So it seems useful to try to provide a code comprehension plugin for Java programmers who use Eclipse.

<h4>What you might do</h4>
<ol>
<li>Read what other people have done.</li>
<li>Learn how Eclipse works.</li>
<li>Decide what capabilities you would like to have in your plugin. Many of these may come from ideas based in the Program Analysis course.</li>
<li>Design and implement your plugin.</li>
<li>Design a small maintenance problem to test your system.</li>
<li>Evaluate your plugin by running an experiment where some people make the changes using Eclipse without your plugin and some people make the same changes using your plugin.</li>
</ol>
<h4>Person Specification</h4>
This project requires a confident Java programmer who likes compiler technology. The courses Advanced Issues in Object Oriented Programming and Program Analysis should be taken. Depending on what is implemented this could be a research/implementation project or a straight implementation project.
<p>
If you would like to do something similar to this but not what I have described, I would be happy to discuss your ideas for a project.
</p><BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Linked - A systems project</H2></CENTER>
<B>Supervisor:</B>Susan Eisenbach<BR>
<B>Room No.:</B>569<BR>
<B>E-mail:</B><A HREF="mailto:sue@doc.ic.ac.uk">sue@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR><h4>Motivation</h4>

In 2003 a very readable, popular science book was published called <i>Linked</i> by Albert-László Barabási. The subtitle is
<blockquote>
How Everything Is Connected to Everything Else and What It Means for Business, Science, and Everyday Life
</blockquote></dd> 

<p>
Different kinds of networks have very different structures (network topologies) and this book describes current research into network topologies. Several different networks are covered and the book contains discussions about the repercussions of using each different topology. In particular, different types of networks evolve and deal with failure in very different ways. One of the main examples of a network is the internet and the book is filled with interesting stories about the growth of the internet. 
</p>
<h4>Objective</h4>
A program can be thought of  as a network of components linked by method calls. Some of these components will come from system maintained libraries. This project is about looking at the structure of system library calls to see what kind of network they form. The properties of the network network type should influence the design and maintenance strategy of such system libraries.

<h4>What you might do</h4>
<ol>
<li>Read the book.</li>
<li>Choose an operating system (e.g. Linux, Windows 2000).</li>
<li>Decide what information you wish to collect. For example, you might decide to go through applications and find all system calls (static information), you might decide to monitor running systems (dynamic information) or you might decide to collect both kinds of information.</li>
<li>Write tools to collect this information. Before doing this you will need to see what tools there are around so that you don't duplicate work.</li>
<li>Decide which different systems you are going to run your tools on and then collect the information.</li>
<li>Using your data decide which kind of network the library calls form. Before being able to do this you will have to learn in greater detail about the network type indicated by your data.</li>
<li>Draw conclusions on how library code should evolve to minimize failure.
</ol>
<h4>Person Specification</h4>
This project requires a reasonable understanding of system software in order to be able to extract useful information. As the results are unknown, the person was does this project will be doing research.
<p>
If you would like to do something similar to this but not what I have described, I would be happy to discuss your ideas for a project.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Influence Diagrams</H2></CENTER>
<B>Supervisor:</B>Frank Kriwaczek<BR>
<B>Room No.:</B>431<BR>
<B>E-mail:</B><A HREF="mailto:frk@doc.ic.ac.uk">frk@doc.ic.ac.uk</A><BR>
<HR><BR>To build a tool for entering and solving decision problems, expressed as influence diagrams.<BR>
<HR><BR>Influence diagrams are an alternative to decision trees for expressing sequential problems of decision making under risk.

There are several commercial programs, such as Netica (http://www.norsys.com/download.html), but none of these are ideal for teaching purposes. I'd like a tool that explicitly shows the steps that the system takes in solving the decision problem.

The system could be implemented in Java or C, for the ambitious, or Visual Basic (perhaps in Excel) for the fainthearted.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>A web service environment for image analysis</H2></CENTER>
<B>Supervisor:</B>Daniel Rueckert<BR>
<B>Room No.:</B>306c<BR>
<B>E-mail:</B><A HREF="mailto:dr@doc.ic.ac.uk">dr@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>For more details look at http://www.doc.ic.ac.uk/~dr/teaching/projects.html<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>3D Geometry for Schools</H2></CENTER>
<B>Supervisor:</B>Frank Kriwaczek<BR>
<B>Room No.:</B>431<BR>
<B>E-mail:</B><A HREF="mailto:frk@doc.ic.ac.uk">frk@doc.ic.ac.uk</A><BR>
<HR><BR>To produce a computer-based applicationto help teachers demonstrate and to allow pupils to discover elementary ideas in 3D Geometry.<BR>
<HR><BR>The Royal Society recently published a report (http://www.royalsoc.ac.uk/files/statfiles/document-154.pdf) bemoaning the fact that geometry was not given sufficient prominence in Maths teaching in schools and emphasising the importance of some understanding of 3D geometry in a wide range of areas, including physics and biology.

Although there is some excellent software for discovery in plane geometry, there is little available in the 3D area. 

This project would aim to produce a tool, perhaps in Java - although not necessarily an applet, that would encourage experimentation and discovery of some of the important ideas in elementary 3D geometry. The software would not be just an ad hoc collection of tools, but would be an application created in a principle fashion, cognaisant of previous work in the area.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2><B><FONT COLOR="#BF0901">Computer Engineering: Applications and Tools</FONT></B></H2></CENTER>
<B>Supervisor:</B>Wayne Luk<BR>
<B>Room No.:</B>Huxley 434<BR>
<B>E-mail:</B><A HREF="mailto:wl@doc.ic.ac.uk">wl@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>Have a look at my
<a href="http://www.doc.ic.ac.uk/~wl/icprojects/">
project proposals</a>.

<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Distributed Access Control in Ubiquitous systems</H2></CENTER>
<B>Supervisor:</B>Emil C. Lupu<BR>
<B>Room No.:</B>564<BR>
<B>E-mail:</B><A HREF="mailto:ecl1@doc.ic.ac.uk">ecl1@doc.ic.ac.uk</A><BR>
<HR><BR>To develop a prototype for realising Distributed Access control in Ubiquitous environments.<BR>
<HR><BR>Ubiquitous computing environments comprise large amounts of small computational devices embedded in appliances, buildings, clothes etc. These devices interact with each other through wireless links and provide services to each other. However, such environments have stringent access control requirements. Ubiquitous devices must protect themselves from unauthorised access originating from both fixed networks and other devices within their communication range. Conversely fixed network infrastructures will need to host roaming devices and provide services to them while protecting themselves from unauthorised access. The project aims to develop a Distributed Access control framework based on trust relationships, Role-Based Access Control and devolution of access control functions. <br>
Suitable for MEng students, Distributed systems and network security required.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>A symbolic debugger for UML</H2></CENTER>
<B>Supervisor:</B>Emil C. Lupu<BR>
<B>Room No.:</B>564<BR>
<B>E-mail:</B><A HREF="mailto:ecl1@doc.ic.ac.uk">ecl1@doc.ic.ac.uk</A><BR>
<HR><BR>To investigate and implement a "symbolic debugger" for UML-based development. <BR>
<HR><BR>Many academic, industrial and standards organisations advocate the use of Model Driven Architectures (MDAs) in software development (e.g. www.omg.org). This aims to significantly increase the use of UML in systems development. However, there are numerous problems in current UML-based CASE tools when attempting to use UML for generating a significant proportion of the code. In particular there is a need to distinguish code elements that are directly linked to the model from those that have been edited "by hand" and to be able to provide a "debugger" function at the model level. This project will seek to address some of these problems.

Requirements: MEng, good programming skills, knowledge of UML<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Computational Steering via Delayed Evaluation, Self-Optimising Scientific Software Components</H2></CENTER>
<B>Supervisor:</B>Paul Kelly<BR>
<B>Room No.:</B>423<BR>
<B>E-mail:</B><A HREF="mailto:phjk@doc.ic.ac.uk">phjk@doc.ic.ac.uk</A><BR>
<HR><BR>Extend our parallel C++ library with hooks to turn the user's program into an interactive parallel service that we can access and control from a front-end application.<BR>
<HR><BR>  <html>
    <head>
      <title>Computational Steering via Delayed Evaluation,
	Self-Optimising Scientific Software Components</title>
    </head>
    
    <body>
      <center>
	<h2> Computational Steering via Delayed Evaluation,
	  Self-Optimising Scientific Software Components</h2>
	<img src="http://www.doc.ic.ac.uk/~ob3/ProjectIdeas/blurulr6.gif" alt="-------------------------">
      </center>
      <h3>Introduction - The DESO Library</h3> 

      <p> This project is part of the EPSRC-funded OSCAR (Optimising
	Scientific Codes at Runtime) project in the <a
						       href="http:www.doc.ic.ac.uk/~phjk/SoftwarePerformanceOptimisation/iSPELHomePage.html">Software
	  Performance Optimisation Research Group</a>. One of the products
	we are developing is the DESO (Delayed Evaluation,
	Self-Optimising) library of parallel scientific software
	components.  The special characteristic of this library is that
	rather than library routines being executed immediately,
	execution is delayed and a handle for the result (a
	&quot;recipe&quot;) is returned instead. This is used to
	construct a DAG (directed acyclic graph) representing the data
	flow of the computation to be performed. The following figure
	shows an example for such a DAG (in this case the first
	iteration of the Conjugate Gradient methods for solving the
	equation <cite>Ax = b</cite>:

	<center>
	  <a
	     href="http://www.doc.ic.ac.uk/~ob3/ProjectIdeas/first_iteration_c.jpg"><img
											 alt="First Iteration DAG for Conjuage Gradient" height=500
											 src="http://www.doc.ic.ac.uk/~ob3/ProjectIdeas/first_iteration_c.jpg"></img></a>
	</center>
      </p>


      <p>Once we have built such a delayed data flow graph, we then
	have the opportunity to perform cross-component
	optimisations. Our <a
			      href="http://www.doc.ic.ac.uk/~ob3/Publications/Liniker:2002:Delayed.pdf">EuroPar
	  2002 paper</a> gives an introduction to the theory behind this
	library and its use, whilst the <a
					   href="http://www.doc.ic.ac.uk/~ob3/Publications/Kelly:2001:Themis.pdf">&quot;THEMIS
	  paper&quot; (2001)</a> gives are more big-picture overview of
	the aims of the OSCAR research project.
      </p>

      <h3>The aim of this project: Computational Steering</h3> 

      <p>A scientific library like the DESO library could be used to
	build very long-running complex scientific simulation
	programs. The typical mode of operation of such programs is
	<em>off-line</em>: a user starts a simulation run on a large
	data set overnight (or over a few days), with the program at the
	end writing out a large result-file which is then analysed. The
	idea behind <em>Computational Steering</em> is that we would
	really like something much more interactive:
	<ul>
	  <li>We would like to be able to inspect some of the data
	    while the computation is running. This is an important tool
	    for making sure that we do not waste valuable time on
	    simulations that have gone wrong.</li>
	  
	  <li>We want to be able to insert such inspection points at
	    different points in the program's control flow graph
	    (i.e. for example along the edges in the above sample graph)
	    and then remove them afterwards.</li>

	  <li>We may want to adjust certain simulation parameters. For
	    example, some linear system solvers converge more quickly or
	    more slowly based on certain scalar parameters. We want to
	    be able to adjust these interactively at runtime and watch
	    the effect. </li>

	  <li>We may even want to insert additional computational
	    components into the data flow graph.</li>

	  <li>We may want to insert 3D or 2D visualisation components
	    into the data flow in order to be able to watch the progress
	    of a simulation rather than just inspect the final
	    state.</li>

	</ul>
	Another way of explaining this is that we want to take a
	library of scientific subroutines (albeit special ones) and
	turn it into an interactive parallel service that we can
	access and control from a front-end application (probably a
	GUI, but a scripting language might be a good first
	start).</p>
      
      <h3>Key Challenges</h3>
      <ul>
	<li>Understand how our DESO Library works. Understand how
	  existing Steering frameworks are engineered.</li>

	<li>Decide on the appropriate control mechanism for driving
	  the underlying numerical software components.</li>

	<li>Data placement: We want to minimise the amount of data
	  that has to be transferred between the front-end workstation
	  and distributed (parallel) server processors. This is
	  particularly challenging if the set of server processors we use
	  changes over time. </li>

	<li>Our library currently uses MPI, which imposes several
	  restrictions on the way in which we can run parallel
	  programs. Find ways of overcoming these restrictions.</li>

	<li>Design of an appropriate user interface that does not
	  constrain the computational scientist in the kind of
	  computations that can be performed.</li>
      </ul>

      <h3>Is this project for you?</h3>
      
      <p>This is a research-level project. To do this project, you
	must not be scared to pick up and work with an existing large
	software system. You should enjoy the challenge of getting
	software to work and do what you want. If you would like to
	discuss this project, please feel free to talk to either <a
								    href="http://www.doc.ic.ac.uk/~phjk">Paul Kelly</a> or <a
															      href="http://www.doc.ic.ac.uk/~ob3">Olav Beckmann</a>. 

	<p align="center"> <img
				src="http://www.doc.ic.ac.uk/~ob3/ProjectIdeas/blurulr6.gif"
				alt="-----------------------------"> </p>
	<p align="right">
	  <a href="http://www.doc.ic.ac.uk/~ob3">Olav Beckmann</a> <br>
<!-- hhmts start -->
Last modified: Fri Oct 11 17:08:55 BST 2002
<!-- hhmts end -->
	</p>
	<br>

    </body> 

  </html>

<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Optimal Code Selection in Component-based Scientific Programs </H2></CENTER>
<B>Supervisor:</B>Paul Kelly<BR>
<B>Room No.:</B>423<BR>
<B>E-mail:</B><A HREF="mailto:phjk@doc.ic.ac.uk">phjk@doc.ic.ac.uk</A><BR>
<HR><BR>Given a C++ program which uses a numerical class library, figure out, given the particular sequence of calls in the application, which versions of the functions to use.  Better still, figure out how to pack the operations the programmer requested so you can use the CPU manufacturer's manually-optimised libraries to best effect.<BR>
<HR><BR><html>
  <head>
    <title> Optimal Code Selection in Component-based Scientific
    Programs </title>
  </head>
      
  <body>
    <center>
    <h2> Optimal Code Selection in Component-based Scientific Programs
    </h2>
      <img src="http://www.doc.ic.ac.uk/~ob3/ProjectIdeas/blurulr6.gif" alt="-------------------------">
    </center>

    <h3>Motivation</h3> 

    <p> This project is part of the EPSRC-funded OSCAR (Optimising
    Scientific Codes at Runtime) project in the <a
    href="http:www.doc.ic.ac.uk/~phjk/SoftwarePerformanceOptimisation/iSPELHomePage.html">Software
    Performance Optimisation Research Group</a>. One of the products
    we are developing is the DESO (Delayed Evaluation,
    Self-Optimising) library of parallel scientific software
    components.  This library comes with both C and C++ bindings. An
    example of the C++ interface is the following simple numerical
    algorithm:
<PRE>
<FONT color=#0000ff>/*</FONT><FONT color=#0000ff> </FONT>
<FONT color=#0000ff> * A is an N-by-N matrix</FONT>
<FONT color=#0000ff> * r, z, p, q, x are N-element vectors</FONT>
<FONT color=#0000ff> * rho, rho_o, beta, alpha and err are scalars </FONT>
<FONT color=#0000ff> * </FONT>
<FONT color=#0000ff> * Uses the Conjugate Gradient algorithm to solve</FONT>
<FONT color=#0000ff> * the equation Ax = b for x. </FONT>
<FONT color=#0000ff> */</FONT>
<B><FONT color=#a52a2a>for</FONT></B> ( i = <FONT color=#ff00ff>1</FONT>; i &lt;= max_iter; i++ ) {
  <FONT color=#0000ff>/*</FONT><FONT color=#0000ff> ... */</FONT>
  rho = r * z;
  <B><FONT color=#a52a2a>if</FONT></B> (i == <FONT color=#ff00ff>1</FONT>) { 
    p = z;
  } <B><FONT color=#a52a2a>else</FONT></B> { 
    z = z + (rho / rho_o) * p;
    p = z;
  }

  q = A * p;
  alpha = rho / (p * q);
  x = x + alpha * p;
  r = r - alpha * q;

  err = nrm2(r); <FONT color=#0000ff>/*</FONT><FONT color=#0000ff> Check convergence */</FONT> 
  <FONT color=#0000ff>/*</FONT><FONT color=#0000ff> ... */</FONT> 
}

</PRE>
    </p>


    <p>See our recent <a
    href="http://www.doc.ic.ac.uk/~ob3/Publications/Liniker:2002:Delayed.pdf">EuroPar
    2002 paper</a> for an illustration for how a simple high-level
    piece of code like the above can become a working parallel
    program.
    </p>

    <p><b>The Challenge of Cross-component Optimisation.</b> It is
    sadly not true that the composition of optimised software
    components is optimal. For example: Suppose we have two large
    optimised numerical functions <code>f</code> and <code>g</code>,
    then <code>f(); g()</code> is not necessarily optimal, in
    particular if these are parallel functions. One possible solution
    is of course to make sure that we recompile <code>f</code> and
    <code>g</code> each time we want to call them and then use a
    compiler with powerful interprocedural optimisations. However, in
    the case of libraries, we have no information available at
    compile-time about how library functions will be used: we lose all
    context information. In our library of parallel scientific
    components, we overcome this problem of lost context information
    by using <em>delayed evaluation</em> to capture the data-flow
    graph of library operations before they are executed at program
    runtime. We then have the opportunity to perform runtime
    cross-component optimisations.
    </p>

    <p> <b>Code (Component) Selection.</b> For a vector update
    statement such as <code>x = x + alpha * p</code>, the data-flow
    graph nodes created are as follows:
<PRE>
       +------------------+
       | temp = alpha * p |
       +------------------+
              /
             /
            |
           |/
            |
    +--------------+
    | x = x + temp |
    +--------------+
</PRE>
    The reason why two nodes are created is the manner in which DESO's
    C++ interface "parses" the statement <code>x = x + alpha *
    p</code>. <em>This approach is clearly sub-optimal, because</em>
    <ol>

      <li> <p>We should fuse the two loops <code>temp = alpha * p</code>
	and <code>x = x + temp</code>. </p>

      <li> <p>On many platforms, the hardware vendor will have
      supplied an optimised implementation of the operation <code>y
      &lt;- alpha &times; x + y</code>. In our current implementation,
      we lose the opportunity to use that optimised
      implementation. The problem of selecting the optimal set of
      vendor-supplied functions for a particular computation is a
      <em>code selection problem</em>.</p>

    </ol>
      </p>
      
      <p>For a larger illustration of this problem, consider the
	following data flow graph, which is the actual DAG generated
	when running the first iteration of the above sample
	program.</p>
      
      <p>
	<center>
	  <a href="http://www.doc.ic.ac.uk/~ob3/ProjectIdeas/first_iteration_cpp.jpg">
	    <img align=centre height=400
		 src="http://www.doc.ic.ac.uk/~ob3/ProjectIdeas/first_iteration_cpp.jpg"
		 alt="Picture of First Iteration DAG"></img></a>
	</center>
      </p>

    <p><strong>The aim of this project is to use runtime techniques to
    optimise these kind of DAGs.</strong> It would be a real bonus if
    we could also know whether our optimisation has just resulted in
    an improvement or found the actual optimal code selection for this
    DAG. </p>

      <p>Similar problems have to be solved by optimising compilers
      for sequential code, and several published algorithms are
      available for that context.</p>

    <p>There are ways in which both the code selection problem and the
    loop fusion problem could be addressed by using compile-time
    methods, specifically C++ Template Metaprogramming, see for
    example Blitz++ (<a href="http://www.oonumerics.org/blitz/">
    http://www.oonumerics.org/blitz/</a>).  There should be
    interesting trade-offs between the runtime and compile-time
    approaches.</p>

    <h3>The Task</h3>
    
    <p> <strong>Extend our existing parallel linear algebra library to
    perform runtime code selection, exploiting available optimised
    library routines. Evaluate by comparing with loop fusion and
    compile-time approaches.</strong></p>
      
    <ul>
      
      <li> <p>Install and use the DESO library, understand how the C++
      interface and the delayed evaluation system work and how
      data-flow of parallel operations is stored internally. </p>
	
      <li><p>Research existing algorithms in the compiler literature
      for solving this problem (we will point you towards the key
      papers).</p>
      
      <li><p>Implement a suitable algorithm in the existing library,
      together with the required model of what optimised operations
      are available.</p>

      <li><p>Evaluate your work using various benchmarks and compare
      with other solutions (e.g. loop fusion and compile-time
      solutions).</p>

    </ul>
	  
    <h3>Is this project for you?</h3>
      
      <p>This is a research-level project. To do this project, you
      must not be scared to pick up and work with an existing large
      software system. You should enjoy the challenge of getting
      software to work and do what you want. If you would like to
      discuss this project, please feel free to talk to either <a
      href="http://www.doc.ic.ac.uk/~phjk">Paul Kelly</a> or <a
      href="http://www.doc.ic.ac.uk/~ob3">Olav Beckmann</a>. Our <a
      href="http://www.doc.ic.ac.uk/~ob3/Publications/Liniker:2002:Delayed.pdf">EuroPar
      2002 paper</a> gives an overview of the software framework which
      you would be working with, whilst the <a
      href="http://www.doc.ic.ac.uk/~ob3/Publications/Kelly:2001:Themis.pdf">THEMIS
      paper (2001)</a> gives are more big-picture overview of the aims
      of our research project.

<p align="center"> <img
src="http://www.doc.ic.ac.uk/~ob3/ProjectIdeas/blurulr6.gif"
alt="-----------------------------"> </p>
<p align="right">
<a href="http://www.doc.ic.ac.uk/~ob3">Olav Beckmann</a> <br>
<!-- hhmts start -->
Last modified: Wed Oct  9 18:47:22 BST 2002
<!-- hhmts end -->
</p>
<br>

</body> 

</html>





<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>C# for Beginners</H2></CENTER>
<B>Supervisor:</B>Susan Eisenbach<BR>
<B>Room No.:</B>569<BR>
<B>E-mail:</B><A HREF="mailto:sue@doc.ic.ac.uk">sue@doc.ic.ac.uk</A><BR>
<HR><BR>to take the the introductory programming IDE and make it suitable for C# rather than Java<BR>
<HR><BR><p>Introductory imperative programming is aimed at teaching beginners how to solve small (e.g. 100 lines) problems using appropriate control and data structures. Although C# is a language that students want to know it lacks simplicity, so it isn't an ideal language to teach basic imperative constructs. Students however would like to learn it as early as possible. The aim of this project is to reconcile this conflict.</p>
 
<p>
The HelloWorld program in C# is</p>
public class HelloWorld{</p>
  public static void main(string[] args){</p>
  Console.output.WriteLine("Hello World");</p>
  }</p>
}</p>

whereas in Turing it is</p>
put "Hello World"</p>
<p>
Input in C# makes output look straightforward.</p>
<p>
<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2> Typed JavaScript  Compiler</H2></CENTER>
<B>Supervisor:</B>Chrostopher Anderson and Sophia Drossopoulou<BR>
<B>Room No.:</B>559<BR>
<B>E-mail:</B><A HREF="mailto:cla97@doc.ic.ac.uk">cla97@doc.ic.ac.uk</A><BR>
<HR><BR>Implement a compiler for a new object based language, BabyJ,
which is a typed version of a subset of JavaScript.<BR>
<HR><BR>We have recently created a new language, BabyJ, similar to JavaScript with the novel feature in that programs can be incrementally typed. This means the programmer can prototype ideas then gradually add type annotations until the program is fully typed.
<p>
At <a href="http://www.doc.ic.ac.uk/~cla97/BabyJ.ps">BabyJ description<a> you can find our more. 
<p>
We would like to develop a compiler that given a fully typed BabyJ program converts it to a  corresponding Java program. We have a translation schema, but naturally if you think you can do it better then go ahead!
<p> 
A project with a similar theme, for a different language can be found <a href="http://www.doc.ic.ac.uk/~ajf/Teaching/Projects/DistProjects.html">here</a>
<p> 
 
A knowledge of compiler construction will be required and ideally we would like the compiler written in Java.
 
 
 <BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Typed Javascipt Development Environment</H2></CENTER>
<B>Supervisor:</B>Christopher Anderson and Sophia Drossopoulou<BR>
<B>Room No.:</B>558c<BR>
<B>E-mail:</B><A HREF="mailto:cla97@doc.ic.ac.uk">cla97@doc.ic.ac.uk</A><BR>
<HR><BR>To develop a graphical environment for the incremental typing
of a typed version of a subset of JavaScipt. <BR>
<HR><BR>We have recently created a new language, BabyJ, similar to JavaScript with the novel feature in that programs can be incrementally typed. This means the programmer can prototype ideas then gradually add type annotations until the program is fully typed.
 <p>
At <a href="http://www.doc.ic.ac.uk/~cla97/BabyJ.ps">BabyJ description<a> you can find our more.
<p>
We would like to develop a graphical environment for the incremental typing. We imagine
a code browser that allows the programmer to annotate selected parts of the program. Typing errors could be  highlighted. 
<p>
This project has a lot of scope, in particular,  the environment could try to infer types for the program  via some type inference algorithm.
<p>
A basic knowledge of type systems will be needed (as eg taught in the Semantics, the Type System course, or the Advanced Issues in Object Orieted Languages course). We would prefer the tool written in Java.  <BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Compositional Elaboration of Design Models for Distributed Programs</H2></CENTER>
<B>Supervisor:</B>Jeff Kramer<BR>
<B>Room No.:</B>568<BR>
<B>E-mail:</B><A HREF="mailto:jk@doc.ic.ac.uk">jk@doc.ic.ac.uk</A><BR>
<HR><BR>To investigate the utility of local reasoning and environment assumptions in the compositional elaboration of design models for distributed systems. <BR>
<HR><BR>Distributed systems are conveniently described, constructed and managed in terms of their software structure or architecture. However few current approaches exploit the architectural view. The project is to utilise existing
compositional behaviour analysis techniques which complement the architectural methodology. Component behaviour is specified in LTS - Labelled Transition Systems, combined using the architectural description and analysed using a model checker, LTSA, for analysing and checking various properties. In particular this poriject aims to investigate whether designs can be elaborated component by component based on local behaviour and properties to be preserved. Assumptions about the environment could be provided and/or generated to help to elaborate towards system behaviour.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Requirements Elaboration: Scenarios to state machine models and back</H2></CENTER>
<B>Supervisor:</B>Jeff Kramer<BR>
<B>Room No.:</B>568, Huxley<BR>
<B>E-mail:</B><A HREF="mailto:jk@doc.ic.ac.uk">jk@doc.ic.ac.uk</A><BR>
<HR><BR>To investigate the use of message sequence charts (scenarios) as a means of developing and elaborating state machines in the form of labelled transition systems (LTS). <BR>
<HR><BR>A number of current software design techniques use combinations of models to specify and analyse requirements specifications or object-oriented designs. For instance, in UML sequence diagrams are used to describe various scenarios and object interactions. Statecharts can be used to describe the behaviour of each object. Systems can then be analysed as the composition of the interacting objects. Scenarios and state models are complementary forms of specification.

Our current research interest is in using scenarios to help generate state machine (LTS) models and in turn to use these models as a means for elaborating the scenarios themselves. This project aims to investigate current approaches and to experiment with the approach currently proposed. In particular, it will aim to use a case study to experiment with and evaluate the current scenario and LTSA toolset, which has been extended to support the approach. It is expected that the evaluation will indicate areas for further work to extend the approach and toolset.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>A Programmer's Apprentice</H2></CENTER>
<B>Supervisor:</B>Ian Moor<BR>
<B>Room No.:</B>326<BR>
<B>E-mail:</B><A HREF="mailto:iwm@doc.ic.ac.uk">iwm@doc.ic.ac.uk</A><BR>
<HR><BR>To design and implement a programmer's appentice supporting a 
language such as Java.<BR>
<HR><BR>A programmer's apprentice understands a users's program well enough
to cooperate in the design, implementation, and maintenance of the program.
(This definition is taken from a paper printed in 1979). The apprentice 
may help an experienced programmer by checking the program and help a
beginner by suggesting programming and data structures; it should be able
to explain its output.

The project should make use of modern design schemes ( for example patterns,
refactoring).   <BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Tools for the Analysis and Optimisation of Firewall Policies</H2></CENTER>
<B>Supervisor:</B>Naranker Dulay<BR>
<B>Room No.:</B>562<BR>
<B>E-mail:</B><A HREF="mailto:nd@doc.ic.ac.uk">nd@doc.ic.ac.uk</A><BR>
<HR><BR>To provide tools for the specification, analysis and optimisation of Firewall policies. <BR>
<HR><BR><BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Ubiquitous Theme Park</H2></CENTER>
<B>Supervisor:</B>Naranker Dulay<BR>
<B>Room No.:</B>562<BR>
<B>E-mail:</B><A HREF="mailto:nd@doc.ic.ac.uk">nd@doc.ic.ac.uk</A><BR>
<HR><BR>To develop and implement a set of applications that might be used in a Ubiquitous Theme Park of the future.<BR>
<HR><BR><BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Ubiquitous Hospital</H2></CENTER>
<B>Supervisor:</B>Naranker Dulay<BR>
<B>Room No.:</B>562<BR>
<B>E-mail:</B><A HREF="mailto:nd@doc.ic.ac.uk">nd@doc.ic.ac.uk</A><BR>
<HR><BR>To develop and implement a set of applications that might be used in a Ubiquitous Hospital of the future.<BR>
<HR><BR><BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Trust Model for Ubiquitous Computing</H2></CENTER>
<B>Supervisor:</B>Naranker Dulay<BR>
<B>Room No.:</B>562<BR>
<B>E-mail:</B><A HREF="mailto:nd@doc.ic.ac.uk">nd@doc.ic.ac.uk</A><BR>
<HR><BR>To investigate the requirements for trust in future ubiquitous computing. To develop a model for trust that can be used for the specification, analysis and implementation of effective ubiquitous applications. To implement the model along with a large-scale prototype.<BR>
<HR><BR><BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Compiling Python Programs</H2></CENTER>
<B>Supervisor:</B>Naranker Dulay<BR>
<B>Room No.:</B>562<BR>
<B>E-mail:</B><A HREF="mailto:nd@doc.ic.ac.uk">nd@doc.ic.ac.uk</A><BR>
<HR><BR>To investigate and implement techniques for compiling Python programs. This is a difficult project and requires a very dedicated student, one who is fluent with Python and has a keen interest in compilers.<BR>
<HR><BR><BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Modelling and Analysis of Cryptographic Protocols using LTSA</H2></CENTER>
<B>Supervisor:</B>Naranker Dulay<BR>
<B>Room No.:</B>562<BR>
<B>E-mail:</B><A HREF="mailto:nd@doc.ic.ac.uk">nd@doc.ic.ac.uk</A><BR>
<HR><BR>To survey current tool-based approaches to modelling and analysing cryptograhic protocols. To provide a cryptographic front-end parser to the LTSA. To investigate and implement appropriate extensions to LTSA.<BR>
<HR><BR>A good starting point for this project is "Modelling and Analysis of Security Protocols" by Peter Ryan and Steve Schneider, Addison-Wesley, 2001.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Policies for Sandboxing Unix programs</H2></CENTER>
<B>Supervisor:</B>Naranker Dulay<BR>
<B>Room No.:</B>562<BR>
<B>E-mail:</B><A HREF="mailto:nd@doc.ic.ac.uk">nd@doc.ic.ac.uk</A><BR>
<HR><BR>To investigate the degree of sandboxing possible for Unix programs.  To adopt and if necessary extend the Ponder policy language to specify sandboxing policies.  To provide an implementation based on OpenBSD's systrace feature.<BR>
<HR><BR><BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Management Policy Semantics</H2></CENTER>
<B>Supervisor:</B>Emil Lupu<BR>
<B>Room No.:</B>562<BR>
<B>E-mail:</B><A HREF="mailto:nd@doc.ic.ac.uk">nd@doc.ic.ac.uk</A><BR>
<HR><BR>To define a formal semantics for the specification of management policies and implement the compile time analysis tools for policy verification<BR>
<HR><BR>The use of policies for managing and adapting the behaviour of distributed application and network components according to the business needs is now promoted by many of the software and equipment vendors such as Hewlett-Packard, Intel, Cisco and 3COM. However in many cases the change in behaviour induced by a policy is implemented by ad-hoc means without a precise semantic specification. This project aims to define a formal semantics for a policy notation and implement the compile time analysis tools needed for policy verification.

Areas of interest: Language semantics, Compilers, Distributed Applications
<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Implementing semantic minimization of 3-valued propositional logic</H2></CENTER>
<B>Supervisor:</B>Michael Huth<BR>
<B>Room No.:</B>435<BR>
<B>E-mail:</B><A HREF="mailto:mrh@doc.ic.ac.uk">mrh@doc.ic.ac.uk</A><BR>
<HR><BR>To understand the state-of-the-art technique of semantically minimizing propositional logic formulas with respect to Kleene's strong 3-valued semantics. To implement one or several such minimazations with various representation back-ends: propositional logic syntax, pairs of binary decision diagrams, and ternary decision diagrams. To evaluate these implementations through performance comparisons. (This project is well suited for JMCs.)<BR>
<HR><BR>Propositional formulas -- such a "p or ¬p" -- may take on three values: 0, 1, and U, the latter for "don't know/don't care". Under Kleene's 3-valued semantics, 1 is then more precise than "p or ¬p". Semantic minimization transforms a formula into another one such that this loss of precision is somewhat minimized. Results from LICS 2002 suggest a form of minimization and possible algorithms. In this project, the student will explore such algorithms and possible back-ends for representing minimized formulas. An evaluation portion will compare such implementations in terms of their requirements for memory and time. (Applications of such implementations range from model checking and program analysis to problems in artificial intelligence.)<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Driving robots with I2C</H2></CENTER>
<B>Supervisor:</B>David J Adams<BR>
<B>Room No.:</B>228<BR>
<B>E-mail:</B><A HREF="mailto:dja@doc.ic.ac.uk">dja@doc.ic.ac.uk</A><BR>
<HR><BR>To write a linux driver for I2C control <BR>
<HR><BR>I2C is a two-wire bus designed by Philips to enable fast serial communications between Devices or integrated circuits. In Doc we have our own robotic system (Icaros) that uses I2C to connect sensors and motors to an onboard PC. Many High level languages suitable for Robotic applications run on a Linux platform. The driver would provide the link between high-level control algorithms and real-time activity. 
This project would appeal to someone with an interest in Linux and assembler programming.
See my web page for further details.
<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>A Direct Embedding of the Lambda-calculus into the Explicit Fusion Calculus</H2></CENTER>
<B>Supervisor:</B>Philippa Gardner<BR>
<B>Room No.:</B>452<BR>
<B>E-mail:</B><A HREF="mailto:pg@doc.ic.ac.uk">pg@doc.ic.ac.uk</A><BR>
<HR><BR>To connect a known behavioural equality associated with the
lambda-calculus with a behavioural equality give by its direct translation
into the explicit fusion calculus (a variant of the pi-calculus).<BR>
<HR><BR>The pi-calculus is a calculus for describing interaction between
processes, which will be taught in the course on `Models of Concurrent
Computation' and has similiarities with CSP described in the course on
`Concurrent Programming'.  There is a translation of the
lambda-calculus into the pi-calculus.  The translation is strong in
that it preserves certain behavioural equalities associated with the
lambda-terms. It is however quite complicated.

Gardner and Wischik have introduced the explicit fusion calculus,
which is a variation of the pi-calculus with several interesting
theoretical properties and a simpler distributed  implementation. In
particular, it is possible to give a more direct translation of the
lambda-calculus in the explicit fusion calculus.  The goal of this
project is to connect a known behavioural equality associated 
with the lambda-calculus with a behavioural equality give by its direct
translation into the explicit fusion calculus. This result is not
immediate from the previous work on the pi-calculus and would be 
publishable if done well.


This is a theoretical project, suitable for someone with a 
strong mathematical background who is taking the course on
`Models of Concurrent Computation'. <BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Probabilistic Program Semantics and Analysis</H2></CENTER>
<B>Supervisor:</B>Herbert Wiklicky<BR>
<B>Room No.:</B>444a<BR>
<B>E-mail:</B><A HREF="mailto:herbert@doc.ic.ac.uk">herbert@doc.ic.ac.uk</A><BR>
<HR><BR>Development and implementation of tools for the analysis of properties
of programs in a probabilistic programming language.
<BR>
<HR><BR>Consider a probabilistic programming language, i.e. a language where computations or the flow of information is determined by some element of chance (e.g. coin flipping). Starting point would be an operational semantics of some probabilistic language in terms of a probabilistic transition system, e.g. for Probabilistic While or Probabilistic Concurrent Constraint Programming.

The task would then be to develop/implement tools to analyse the (probabilistic) properties of the program. A two phase approach to this could be: (1) A generic ``compiler'' which transforms a probabilistic program into a Markov chain; (2) Analysis of the corresponding stochastic matrix in order to obtain information about the various properties of the program.

Analysis aspects which could be interesting are: (1) Termination Analysis (probability of termination), (2) Performance Analysis (average and worst case analysis of running time, etc), or (3) Security Analysis (detecting covert channels)
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Computer Supported Collaborative Authoring</H2></CENTER>
<B>Supervisor:</B>Herbert Wiklicky<BR>
<B>Room No.:</B>444a<BR>
<B>E-mail:</B><A HREF="mailto:herbert@doc.ic.ac.uk">herbert@doc.ic.ac.uk</A><BR>
<HR><BR>The aim is to develop a distributed authoring system for writing documents, papers and articles in LaTeX.
<BR>
<HR><BR>The task is to provide a CSCW environment and tools for authoring scientific papers (in LaTeX) such as: version control mechanisms, backup and archive system, change tracking, merging of different versions, annotation of papers, ensuring uniformity of notation, common bibliographic database, secure access, etc. for a small number of authors at different institutions via a common server.

The focus is not on specific LaTeX related issues - although basic knowledge of LaTeX/Tex and Emacs would be advantageous - but to facilitate easy exchange, update, backup, etc of scientific texts between collaborating authors.
<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Quantum Computation Tools</H2></CENTER>
<B>Supervisor:</B>Herbert Wiklicky<BR>
<B>Room No.:</B>444a<BR>
<B>E-mail:</B><A HREF="mailto:herbert@doc.ic.ac.uk">herbert@doc.ic.ac.uk</A><BR>
<HR><BR>The purpose is to provide an environment and/or tool-set for simulating basic quantum computations.
<BR>
<HR><BR>The aim is to provide a library and/or graphical environment enabling the user to simulate quantum circuits and computers in order to implement basic quantum algorithms. The system must be suitable for teaching and illustrating the basics of quantum computation. 

Basic knowledge of quantum computation would be advantageous but is not necessary.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Computer Vision and Graphics</H2></CENTER>
<B>Supervisor:</B>Daniel Rueckert<BR>
<B>Room No.:</B>306c<BR>
<B>E-mail:</B><A HREF="mailto:dr@doc.ic.ac.uk">dr@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>For project proposals look at http://www.doc.ic.ac.uk/~dr/teaching/projects.html
or contact me with your own proposals.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Real-time face recognition and identification using 3D surface models</H2></CENTER>
<B>Supervisor:</B>Daniel Rueckert<BR>
<B>Room No.:</B>306c<BR>
<B>E-mail:</B><A HREF="mailto:dr@doc.ic.ac.uk">dr@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>For more details look at http://www.doc.ic.ac.uk/~dr/teaching/projects.html<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Light field rendering for volume visualization of medical images</H2></CENTER>
<B>Supervisor:</B>Daniel Rueckert<BR>
<B>Room No.:</B>306c<BR>
<B>E-mail:</B><A HREF="mailto:dr@doc.ic.ac.uk">dr@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>For more details look at http://www.doc.ic.ac.uk/~dr/teaching/projects.html <BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Real-time tracking of faces in 3D for the animation of virtual actors</H2></CENTER>
<B>Supervisor:</B>Daniel Rueckert<BR>
<B>Room No.:</B>306c<BR>
<B>E-mail:</B><A HREF="mailto:dr@doc.ic.ac.uk">dr@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>For more details look at http://www.doc.ic.ac.uk/~dr/teaching/projects.html
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Knowledge discovery and data mining for image analysis in medicine and biology</H2></CENTER>
<B>Supervisor:</B>Daniel Rueckert<BR>
<B>Room No.:</B>306c<BR>
<B>E-mail:</B><A HREF="mailto:dr@doc.ic.ac.uk">dr@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>For more details look at http://www.doc.ic.ac.uk/~dr/teaching/projects.html<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Grid computing / E-science platform for image analysis in medicine and biology</H2></CENTER>
<B>Supervisor:</B>Daniel Rueckert<BR>
<B>Room No.:</B>306c<BR>
<B>E-mail:</B><A HREF="mailto:dr@doc.ic.ac.uk">dr@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>For more details look at http://www.doc.ic.ac.uk/~dr/teaching/projects.html<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Conference Organizer</H2></CENTER>
<B>Supervisor:</B>Istvan Maros<BR>
<B>Room No.:</B>377, Huxley<BR>
<B>E-mail:</B><A HREF="mailto:im@doc.ic.ac.uk">im@doc.ic.ac.uk</A><BR>
<HR><BR>To create an integrated system for assisting the organization of small conferences, including (pre)registration, paper submission and acceptance/rejection.<BR>
<HR><BR>The project will create an integrated web based system to assist the activities of the chairman of a conference, including the creation of the conference home page, setting up a programme committee (with expertise of members), electronic acceptance of submissions, automatic acknowledgement of receipts, assignment of papers to referees (members of the PC), tracing the refereeing process (quite complex!), recording decision on papers, notifying authors of the outcome. System must be based on a database management system. Working knowledge of preparing web based systems and experience with databases are required. <BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Implementation of Lazy OTDD package for hardware & software checking</H2></CENTER>
<B>Supervisor:</B>Michael Huth<BR>
<B>Room No.:</B>435<BR>
<B>E-mail:</B><A HREF="mailto:mrh@doc.ic.ac.uk">mrh@doc.ic.ac.uk</A><BR>
<HR><BR>To understand and implement the eager and lazy algorithms and ordered ternary decision diagram data structures for boolean functions with "don't care/don't know" values. To evaluate the implementation with LGSynth93 or comparative benchmarks. (This topic is potentially well suited for JMCs.)<BR>
<HR><BR>Boolean functions are vital for modeling and analyzing hardware (and increasingly software). Ternary boolean functions have three values -- 0, 1, and U -- where U stands for "don't care" (input) or don't know (output). OTDDs are the ternary version of binary decision diagrams and serve as a compact data structure for such functions. The student is expected to implement the abstract data type (ADT) of such functions as OTDDs where the algorithms use optimizations based on the semantics of three-valued (Kleene) logic. Ideally, the implementation of this ADT should be delivered as a component such that applications (e.g. a three-valued model checker) be able to use it as a back-end. The student evaluates the implementation with suitable benchmarks for boolean functions and may extend this evaluation to comparisons across
programming languages, if he or she implements the package in more than one programming language.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Solving Mazes with Intelligent cooperative Robots</H2></CENTER>
<B>Supervisor:</B>David J Adams<BR>
<B>Room No.:</B>228<BR>
<B>E-mail:</B><A HREF="mailto:dja@doc.ic.ac.uk">dja@doc.ic.ac.uk</A><BR>
<HR><BR>To explore the cooperation and communications of real robots in a maze environment<BR>
<HR><BR>Intelligent mechanical devices (robots) are becoming of great interest to many people. The advent of Programmable Interface Controlers (PICs) means that it is now possible to put considerable intelligence directly on the robot. We have designed and built a modular robot and some software to enable it to solve mazes. The exciting part of the project is the cooperation and communication between several of these robots. For more details see my project page<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Dynamic instrumentation, and dynamic aspect weaving using the TaskGraph library</H2></CENTER>
<B>Supervisor:</B>Paul Kelly<BR>
<B>Room No.:</B>423<BR>
<B>E-mail:</B><A HREF="mailto:phjk@doc.ic.ac.uk">phjk@doc.ic.ac.uk</A><BR>
<HR><BR>Build a flexible tool for run-time binary patching in source code terms.
Enhance the flexibility by borrowing aspect-oriented programming ideas to control how, when and where an application's code is augmented or replaced.<BR>
<HR><BR>The idea of this project is to build a portable tool to facilitate dynamic patching of application processes as they run.  Here is a sketch of the code you should be able to write using the tool the project is for:
<pre>
int main(int argc, char **argv) {
  int pid;
  sscanf(argv[1], "%d", &pid)

  Image p;
  p.attachProcess(pid);

  Set<Point> joinpoints = p.findFunction("public * graphics/*::draw(*)");

  TaskGraph patch;
  TaskGraph(patch) {
    cout << "Graphics module draw function called
";
  } endtaskgraph;

  p.deploy(patch, joinpoints);
}
</pre>
This code attaches itself to a specified process (given by pid).  It then finds all the functions which match the wildcard string given (ie all public methods in the graphics module whose name is "draw").  It then builds a piece of code (our TaskGraph llibrary provides syntactic sugar for building the abstract syntax tree for a piece of code on the fly).  Finally it adds this patch to the running application on the fly.
<p>
This tool has applications for debugging and performance analysis.  There are also potential applications for changing a program's behaviour mid-flight - perhaps adding or removing logging or security code.  You could even imagine some kind of dynamic performance optimisation.
<p>
This project is a fusion of three things:
<ul><li>The DynInst API/library - see http://www.dyninst.org/rel3.0/
<li> The TaskGraph library - see Linux directory /homes/phjk/SoftwareReleases
<li> Aspect-orient programming, in particular AspectJ - aspectj.org, and PROSE (http://www.inf.ethz.ch/department/IS/iks/publications/aosd02.ps)
</ul>
Getting the basic functionality to work shouldn't take that long.  Making it elegant and easy to use will take a little longer.  Packaging it for public release is a priority.  Finally, the most fun is in applying it for entertaining purposes - which should lead to an interesting couple of chapters in your report.
<p>
This is a challenging project; you need imagination, taste and a talent for getting scary code to work reliably.  Skills: C++, Linux.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>BioML Browser and tools</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR>Create a BioML Browser for display of biological information<BR>
<HR><BR>External Collaborator: Helen Field
<br><br>
Background for BioML (www.bioml.com)
<br><br>
BioML is an XML file formatted hierarchically by a zoologist. It was designed to contain all data pertaining to one biomolecule (e.g. insulin, chromosome, tissue, animal etc.). XML files may be readily interpreted: a browser, BioBrowser, is available. BioBrowser displays each field of the BioML file in a different way: protein sequence, DNA sequence, and text, or literature may be displayed. Key to its utility is the capability of taking the user straight to the URL from which the data was derived. The BioML project is open source (Fenyo 1997). The BioBrowser displays different kinds of information in different ways, and always permits the user to return to the original URL data source. Each data entry type tells BioBrowser how to display it. When developing BioML or BioBrowser, it is crucial to maintain URLs and tags, for one-click access to source, and for display, respectively.
<br><br>
A series of projects can be structured around BioML to cover one or more of the following areas
<OL>
<LI>Developing a java-based BioML browser: The BioBrowser is currently written in Visual C++, and requires rewriting in Java. Given the concepts displayed by the current version of BioBrowser, create a new application in Java, and show that Genbank files may be downloaded and displayed by the Java BioBrowser. Visual C++ files are available as guidelines.

<LI>Developing an Editor for BioML: The BioBrowser displays different kinds of information in different ways, and always permits the user to return to the original URL data source. Each data entry type tells BioBrowser how to display it. When developing BioML or BioBrowser, it is crucial to maintain URLs and tags, for one-click access to source, and for display, respectively

<LI>Developing parsers and tools for a selection of important biological databases, and creating a BioML XML DTD capable of logically combining the resulting fields. Currently BioML is limited to the fields outlined in the DTD. However, it was designed to combine new fields as they arise in different databases. Options include designing a GUI XML editor that allows a biological (naïve i.e. non-computer literate) user to review the current structure of BioML, and to add duplicate, named fields as required. Novel fields may also be added, however, the basic structure of the BioML DTD should be maintained. Bear in mind that the BioBrowser can display certain types of information and the kinds of fields displayed should be tagged appropriately. BioML has been tested on GenBank data. Since that time, there has been no emergent technology permitting a rapid data mining of all data pertaining to one biomolecule: BioML is a file format that can be sent to a colleague. The project should select around 5 important databases (e.g. Swiss Prot, EMBL or Genbank (they are synchronized), Proteome Analysis Database, Stanford Genome Database or MIPS (for yeast and some other organisms)), examine the data from each database, and design a DTD based on the original BioML and duplicating fields where necessary, that can combine all of the data. Then create parsers that create the unified BioML files from the databases.
</OL>

Skills Needed: Java, XML
<br><br>
<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Metabolic Pathways Representation for Drug Discovery</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR>Design and Implement graph visualization system to represent and query metabolic pathway information and their relationship to other experimental data.<BR>
<HR><BR>Metabolic pathway resources are playing an increasingly important role in the interpretation of genomic data. Metabolic pathways represent chemical processes that occur naturally in living organisms, for example the digestion of alcohol, or how the cells of an organism react to a particular drug. Studying such processes is very important for understanding the relationship between diseases, drugs and the genetic make-up of an organism. Typically, metabolic pathways are studies in conjunction with data from gene expression analysis, proteomic studies, etc. 
<br><br>
This project involves designing and implementing a graph visualization system to represent pathway information and its relationship to data about proteins, genes, drugs and diseases. 
<br><br>
Skills Needed: Java. 
<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Correspondence Analysis for Biological Data</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR>Implement a "Correspondence Analysis Technique" system to find associations between variables in biological data.<BR>
<HR><BR>The aim of this project is to build tools and case studies for finding associations between variables in biological data. One approach is Correspondence Analysis, which is a multivariate statistical technique for exploring an unknown dataset. Its aim it to find associations between variables in experimental results, for example those obtained from Micro-Array (Gene Chips) technology, which has produced a large amount of data relating to the expression of genes given a specific stimulus. 
<br><br>
The goal of this project is to implement a Correspondence Analysis system which should include a general purpose correspondence analysis components with an associate visualization mechanism (extension of an existing scatter plot visualizer) 
<br><br>
Skills Needed: Java 
<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Protein Sequence Analysis Pipeline</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR>Build tools and case studies for protein sequence analysis on the web<BR>
<HR><BR>External Collaborator: John Sgouros
<br><br>
This project aims to develop the tools that capture and automate protein analysis workflows using existing public databases and services and provide interactive tools for displaying the results. By gathering information using this tool, researchers can form new hypotheses about the role of a protein within a cell
<br><br>
A protein sequence, if known and well characterized, can be screened for domains using the PFAM database. PFAM is a collection of HMMs (Hidden Markov Models) and multiple sequence alignments representing many common domains of proteins, domains are structural units with functional characteristics (for example DNA binding). The data structures for each domain centre around:
<br><br>
<OL>
<LI>
Seed alignment: hand edited multiple sequence alignment representing the domain
<LI>
HMM: derived from the seed alignment, which can be used to find new members of the domain family and also to realign a set of sequences to the model, 
<LI>
Full alignment: an automated alignment of all the examples of the domain.
<LI>
Full alignment: an automated alignment of all the examples of the domain.
</OL>

A protein sequence can be submitted to PFAM to see if it contains any well-characterized domains. These are described in terms of where they lie within the sequence and any annotation about the domain(s). Results are classified into domains present within a statistical confidence range, and potential domain matches at a lower level of significance (low stringency results). Links are provided to PROSITE for good annotation of domains, and SCOP (structural classification of proteins) database so that the structures for a particular family can be viewed (there are often many structural variants for the same domain). 
<br><br>
For proteins with SWISSPROT entries (known proteins), the PFAM data is pre-computed and can be accessed by the SWISSPROT ID. Diagrams of domain occurrence over sequence length are produced and HTML links provided to their annotation. PFAM results generally give information on other proteins sharing features in common with the protein of interest.
<br><br>
If the search is fruitful, then using a mask and BLAST procedure may be useful in identifying other similar proteins not identified as significant in a PFAM like search. The presence of a particular domain in a protein sequence may bias BLAST results towards proteins containing that domain. If that particular domain knowledge is not of interest to the researcher, they may wish to eliminate that region of the sequence but still look for similar protein sequences. This is known as masking. 
<br><br>
Results of interest will then be selected from BLAST output and viewed as multiple alignments or evaluated as a multiple alignments using tools such as CLUSTALX/W. The information obtained will indicate the closeness of relationships between sequences and when and where they show regions of homology. Structural domain knowledge can indicate how and what a protein may bind to and how it may fold. It may be that the protein sequence belongs to a particular family of sequences that has known structural and functional roles. By gathering this information, researchers can form new hypotheses about the role of a protein within a cell. 
<br><br>
Skills Needed: Java. 
<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects.



<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Chemoinformatics: The current state and a future vision</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR>Provide a review of the state of the art in chemoinformatics and a vision for its future. <BR>
<HR><BR>With the advent of the Internet and GRID technologies Bioinformatics has become a well-established field, where researchers have access from their desktops to a wide range of online databases (e.g. to DNA and protein sequences databases metabolic pathways databases), and access to remote computational services (e.g. blast searches).
<br><br>
Chemoinformatics, a close cousin of BioInformatics, is quickly catching up. Online Databases of chemical compounds and remote access to chemical analysis tools (e.g. QSAR) are also available of the Internet. In addition, the use of standards such as CML (the chemical markup language) is becoming more widespread. 
<br><br>
This project aims to survey the state of the art in chemoinformatics, investigate the similarities and differences with bioinformatics, i.e. is there really a big difference between how chemists and biologists use the Internet to solve their scientific problems. The output of this project is a vision for the future tools and infrastructure required for a new generation of scientific discovery tools on the Internet.
<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Applications of Pattern Recognition to High Throughput Mass Spectrometry Data</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR>Implement a pattern matching and prediction tools to analyse Mass Spectrometry Data<BR>
<HR><BR>External Collaborator: Helen Field
<br><br>
Mass Spectrometry (MS) techniques can be used to analyse chemical compounds and proteins. Recently, MS of proteins has become very important, since tiny quantities of protein can be positively identified. MS of proteins is now as important as DNA sequencing, because it will allows determining which proteins bind which other biomolecules in a cell. In living cells, proteins are processed by adding additional biomolecules (e.g. carbohydrates, which may increase solubility). These post-translational modifications are highly varied and may not occupy the same site in a population of proteins. Still, some proteins maintain a sufficiently high population of carbohydrates to create patterns in MS.
<br><br>
Mass spectrometric identification of proteins proceeds by cleaving the proteins into smaller peptides with a biological protease, which cuts at a specific target defined by the protein sequence itself. MS heats the peptides up, and detects the resulting ions based on their mass/charge ratio (a protein spectrum is a spectrum of ions from its peptides, from peptides having carbohydrates or other modifications, and from impurities.
<br><br>
This project aims to investigate and compare the use of existing methods for analysing MS data patterns in general, and those arising from carbohydrate modifications of proteins as an example, and to develop new specialized algorithms covering one or more of the following areas:
<OL>
<LI>Return an estimate of which carbohydrates are returned from a given spectrum (D.J. Harvey, U. Oxford papers), and possibly provide a graphical output of the carbohydrates determined, based on those representations you see in the papers. Percentage of each structure in a population may be useful also.
<br><br>
<LI>
Develop pattern recognition techniques that can be used and to investigate indexing and retrieval of proteins and chemical compounds from large databases.
</OL>
Skills Needed: Java. 
<br><br>
<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects.


<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Multivariate Data Analysis Toolkit for Biological Data</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR>Implement multivariate data analysis toolkit. <BR>
<HR><BR>Multivariate statistical approaches can be used to discern significant patterns in complex data sets and are particularly appropriate in situations in which there are more variables than samples in the data set. Multivariate techniques can help researchers summarize data and reduce the number of variables in that data. Examples of these techniques include factor analysis, multidimensional scaling and cluster analysis. These tools can be used for developing taxonomies or systems of classification, investigating useful ways to conceptualise or group items, generating hypotheses and testing hypotheses.
<br><br>
This project aims to developing a toolkit of these techniques and their associated visualization tools and applying them to data from genomic and proteomic experiments. 
<br><br>
Skills Needed: Java. 
<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Web-based tools for Gene Expression Analysis</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR>Develop a web-based application for the analysis of gene expression data.<BR>
<HR><BR>The exponential increase in the amount of DNA sequences available in the public databases has resulted in the transformation of biology to an information science. Furthermore, the use of micro arrays for has become a widely used technique for analysing the behaviour of various genes and their functions. The computational analysis of genomic data complements laboratory work by generating new  hypotheses that can guide the design of experiments towards the elucidation of gene function. Whereas the comparison of DNA and protein sequences provides a static picture of the living cell, the analysis of gene expression data can reveal interactions between groups of genes and give hints about the biochemical pathways underlying cell processes such as malignant transformation. Gene expression analysis techniques address the following questions using gene expression data from different cell lines: - Which genes are expressed in each cell line - What are their levels of expression - Which gene groups are expressed at the same level - Which gene groups display similar variations in expression levels in response to an external stimulus, e.g. the addition of a drug Based on existing knowledge about the functions of these genes (extracted from the public databases), it is possible to classify the gene groups of interest by cellular role (e.g. peptide signalling), functional class (e.g. growth factor receptor) and chromosomal location.
<br><br>
The project involves creating a web-based application using the Kensington Data Mining Engine and Servlets to create an interface for carrying out the common techniques used for analysing gene expression data. The project involves developing several generic analysis templates that can be applied to the different data to extract and present different features in graphical charts.
<br><br>

There are several well know ways of analysing gene expression data, for example, one is Fold Change Analysis. This analysis is easily achievable in many data mining tools. The logic for this process can be encoded into a servlet and be used to generate a data-mining process that can be sent to a data-mining engine and the results returned and graphically visualised. This tool allows analysts to formulate repeatable tasks and quickly check results to see if they warrant further analysis in a more rigours investigation.
<br><br>

Skills: Java Servlets, XML
<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>DNA and Protein Homology Analysis Visualization Tools</H2></CENTER>
<B>Supervisor:</B>Moustafa M Ghanem<BR>
<B>Room No.:</B>355<BR>
<B>E-mail:</B><A HREF="mailto:mmg@doc.ic.ac.uk">mmg@doc.ic.ac.uk</A><BR>
<HR><BR>Implement DNA and protein homology analysis visualization tools and apply them to a homology case study <BR>
<HR><BR>This project aims towards developing flexible and interactive visualization tools for the analysis of similarities in DNA sequences (e.g. as returned from blast-n searches) and protein sequence (e.g. as returned from blast-p). 
<br><br>
Access to an existing BLAST visualization tool and its source code is available. However, one of the objectives of this project is to provide an interface that allows integrating information retrieved by the BLAST search engine with other sources of information on the relationship of gene or protein sequences. A possible case study in this field might be, for instance, to combine the analysis of differential gene expression data derived from DNA micro-arrays with the analysis of sequence alignment data with the objective of exploring the structural and functional relationship of genes.
<br><br>

Skills Needed: Java. 

<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Applications of Pattern Recognition Technology to the Analysis of NMR Data </H2></CENTER>
<B>Supervisor:</B>Moustafa M Ghanem<BR>
<B>Room No.:</B>355<BR>
<B>E-mail:</B><A HREF="mailto:mmg@doc.ic.ac.uk">mmg@doc.ic.ac.uk</A><BR>
<HR><BR>Implement a pattern matching tools to analyse NMR data. <BR>
<HR><BR>External Collaborator: Jeremy Nicholson 
<br><br>
This project aims to pattern recognition methods that can be used to analyse NMR spectra.
<br><br>
NMR spectra can be used to classify biological samples as being normal or abnormal, classify target-organ toxicity and the site and mechanism of action within the organ; identify biomarkers of toxic effect; and evaluate the time course of the effect. The information that is derived from the NMR spectra can be maximized using appropriate chemo-metric and multivariate analytical strategies.  
<br><br>

This project aims to investigate and compare the use of existing methods such as principal components analysis (PCA), clustering algorithms (k-means, and hierarchical clustering) and classification algorithms (SVM, Bayesian methods and decisions trees) to such data and develop new specialized pattern recognition techniques.

<br><br>
Skills Needed Java
<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>A Network Management Scenario with JMX and Ponder</H2></CENTER>
<B>Supervisor:</B>Emil Lupu<BR>
<B>Room No.:</B>564<BR>
<B>E-mail:</B><A HREF="mailto:ecl1@doc.ic.ac.uk">ecl1@doc.ic.ac.uk</A><BR>
<HR><BR>To integrate the implementations of Ponder and JMX and apply to a distributed management scenario. <BR>
<HR><BR><p><font face="Arial, Helvetica, sans-serif">Managing large distributed 
        systems is a continuous problem which despite numerous years of research 
        still poses significant problems. Policies attempt to reduce complexity 
        by defining the management actions that have to be performed by a set 
        of managers on the managed resources when certain events such as failures, 
        performance degradations or intrusions occur. Management agents interpret 
        the policies and perform the actions. The definition of which management 
        actions are possible is frequently included in an Information Model such 
        as <a href="http://www.dmtf.org/standards/standard_cim.php">CIM</a>.</font></p>
      <p><font face="Arial, Helvetica, sans-serif">Up to now different groups 
        within both industry and academia have worked on different aspects of 
        such frameworks: Sun have defined and provided a reference implementation 
        for the Java Management Extensions (JMX), various standards organisations 
        have been working on the definition of CIM and its implementation and 
        other groups have been working on Policy Languages. The aim of the project 
        is to integrate these various aspects in a consistent management framework 
        and to apply it to a concrete scenario. </font></p>
    <BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>A Web-based animation for an abstract machine</H2></CENTER>
<B>Supervisor:</B>Steffen van Bakel<BR>
<B>Room No.:</B>425, Huxley<BR>
<B>E-mail:</B><A HREF="mailto:svb@doc.ic.ac.uk">svb@doc.ic.ac.uk</A><BR>
<HR><BR>To develop a Web based teaching tool.<BR>
<HR><BR>The fourth edition of Tanenbaum's textbook "Structured Computer Architecture" provides a micro-programmed implementation of a subset of the Java Virtual Machine (IJVM). AN interface should be developed, using the flow-of-control diagram for the CPU as occurs in the book. The interface should be able to show on demand, by means of a graphical animation, all that happens in the circuitry of the hardware during a clock cycle, possibly allowing to zoom on details of particular interest.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Well-tempered Computer</H2></CENTER>
<B>Supervisor:</B>Iain Phillips<BR>
<B>Room No.:</B>427<BR>
<B>E-mail:</B><A HREF="mailto:iccp@doc.ic.ac.uk">iccp@doc.ic.ac.uk</A><BR>
<HR><BR>Make MIDI files (or keyboard instruments) more harmonious by using unequal temperaments.<BR>
<HR><BR>Create a program to pitch-bend MIDI files following various temperaments.
The standard temperament is "equal temperament" (all semitones have the same
ratio), but historically many others have been used, such as Mean Tone.

The program should be able to adapt unequal temperaments according to the
actual notes played, to avoid the "wolf tones" which plague unequal
temperaments.

The end result should be that the music sounds much more harmonious.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Hardware Compilation and 'Max Headroom' projects</H2></CENTER>
<B>Supervisor:</B>Ian Page<BR>
<B>Room No.:</B>H422<BR>
<B>E-mail:</B><A HREF="mailto:ipage@doc.ic.ac.uk">ipage@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR><p class=MsoNormal>Please see my <a
href="http://www.doc.ic.ac.uk/~ipage/projects/index.html">projects web page</a>
for further details.</p>
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Correlation in Internet Traffic</H2></CENTER>
<B>Supervisor:</B>Pete Harrison<BR>
<B>Room No.:</B>353<BR>
<B>E-mail:</B><A HREF="mailto:pgh@doc.ic.ac.uk">pgh@doc.ic.ac.uk</A><BR>
<HR><BR>To identify possible causes of correlation, to derive models of correlated traffic and to match long range observed correlations with those of a Markov modulated Poisson process (MMPP).<BR>
<HR><BR>It has been observed that internet traffic exhibits long-range correlation, i.e. current traffic patterns measured on a short time-scale (e.g. packet arrival rate) depend on similar patterns that occurred a long time ago -- autocorrelation.  The project will investigate this phenomenon and seek possible causes.  At the same time, MMPPs will be studied and applied to match a range of specified autocorrelations.  Alternative models will also be studied, e.g. fractals, and an attempt will be made to explain correlation by the occurrence of different classes of event on different time-scales.  The importance of good internet performance is indisputable, but to make progress the nature of traffic needs to be properly understood.  The project is therefore highly relevant to industry and (e)commmerce.

Prerequisites: Performance Analysis lectures, basic mathematical inclination (nothing too advanced), ideally (but not necessarily) Communications.
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Fork-join queues</H2></CENTER>
<B>Supervisor:</B>Pete Harrison<BR>
<B>Room No.:</B>353<BR>
<B>E-mail:</B><A HREF="mailto:pgh@doc.ic.ac.uk">pgh@doc.ic.ac.uk</A><BR>
<HR><BR>To determine the probabilistic properties of fork-join times, i.e. the maximum of a set of random variables, and to integrate the results into queueing models.  Then to apply the models to parallel systems such as redundant arrays of inexpensive disks (RAID).<BR>
<HR><BR>Queues and queueing networks provide a good representation of many contention systems such as routers, communication networks, computer architectures.  However, they cannot model (directly) synchronisation between tasks, simultaneous resource possession and multitasking.  This project will investigate fork-join queues where a task splits into subtasks which are executed on separate processors and then wait for the last one to complete before reforming the original task.  Thus the first step is to study the random variable which is the maximum of the sub-tasks' service times.  This can be done for exponential service times but the resulting recurrence formula is complex and expensive to implement without careful programming.  Attention will be paid to this and then to other service time distributions.  The results will then be integrated into queues and queueing networks representing the other characteristics of a parallel processing system, with particular attention to striped RAID systems.  The project is therefore highly relevant to industry as well as parallel processing research and development. Prerequisites: Performance Analysis lectures, basic mathematical inclination (nothing too advanced), ideally (but not necessarily) parallel architectures and/or storage systems. 
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Response time distributions by analytical methods</H2></CENTER>
<B>Supervisor:</B>Pete Harrison<BR>
<B>Room No.:</B>353<BR>
<B>E-mail:</B><A HREF="mailto:pgh@doc.ic.ac.uk">pgh@doc.ic.ac.uk</A><BR>
<HR><BR>To determine response time distributions by analytically inverting rational  Laplace transforms defined by recurrence formulas.  To match rational Laplace transforms to approximate those of other probability distributions and hence to estimate their quantiles.<BR>
<HR><BR>Quantiles of time delays are becoming increasingly important in the quantative analysis of complex computer and communication systems such as the internet.  However, unlike the mean, and sometimes higher moments such as variance, distributions (and hence quantiles) are expensive if not impossible (so far) to obtain.  Distributions can often be obtained as Laplace transforms but these are hard to invert (to get the required distribution) or numerically imprecise or unstable.  This project will work with a recurrence formula that yields the distribution of a sum of exponential random variables.  The recurrence is highly complex, akin to Ackermann's function (functional programmers!), and needs special techniques to make it efficient(ish).  This is the first part of the project.  The next part will be to approximate Laplace transforms of other distributions as rational functions and hence as mixtures of the type considered in the first part.  The result will be a general, approximate Laplace transform inverter that avoids numerical instabilities.  It is an open question as to how effective this approach will be, but any new results will be immediately publishable.  Prerequisites: Performance Analysis lectures, basic mathematical inclination (nothing too advanced), ideally (but not necessarily) Communications. 
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Synthesis of reversed processes</H2></CENTER>
<B>Supervisor:</B>Pete Harrison<BR>
<B>Room No.:</B>353<BR>
<B>E-mail:</B><A HREF="mailto:pgh@doc.ic.ac.uk">pgh@doc.ic.ac.uk</A><BR>
<HR><BR>To develop and implement a tool to synthesise reversed Markov processes from specifications made in a high level language called PEPA.  Hence to find simple 'product form' solutions to the processes' balance equations.<BR>
<HR><BR>Analytical performance models often involve solving a Markov process at equilibrium, but such processes are messy to specify directly and error-prone.  There are various high level formalisms to help in this specification and Markovian Process Algebra (MPA) is one such.  PEPA is an MPA.

The problem with these formalisms is to find simple solutions for steady state probabilities.  The project will investigate solution methods based on constructing reversed processes, intuitively the process observed by running time backwards, like playing a video backwards.  This synthesis will be implemented in PEPA and product-form solutions will follow.  One application will be an (almost) automatic proof of the product form result for queueing networks given in the Performance Analysis lectures.

Prerequisites:  Performance Analysis,  basic mathematical inclination (nothing too advanced), ideally (but not necessarily) Labelled Transition Systems.

Please come and see me to ind out more - the details are flexible
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Meta-learning algorithms and distributed data mining</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR>Implement componets for meta-learning and distributed data mining<BR>
<HR><BR>Meta-learning is a machine learning technique that consists in learning from models (a model can be defined as a concise / useful representation of a data set). Although meta-learning has been explored for classification models, the problem of learning from cluster analysis model is still an open-problem.
<br><br>
This project aims to explore a possible technique based on cluster tree aggregation and model-based clustering. This approach will be implemented in the context of the distributed data mining component platform, deployed and tested over distributed data sets.
<br><br>
Skills: Preferably MENG/MSc/MAC<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>A Graphical User Interface for Deploying Distributed Data Mining Components</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>Distributed data mining focuses on the analysis of distributed data sets using  for instance parallel or meta-learning approaches. Although these approaches have been studied from a theoretical point of view, there is a need to define a platform to easily build and deploy these strategies. This platform allows the definition of two separate roles: the analysis component developer who should not worry about distribution/data localization, synchronization primitives and other deployment issues, and a distributed data mining strategy deployer who will compose and connect components and setup configuration issues.
<br><br>
The project aims to build the front-end GUI tools to compose analysis components for dynamically deploying distributed data mining strategies. These tools must also enable allowing the user to choose the strategy, data sources and parameters.
<br><br><br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects

<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Support Vector Machines Classifiers for High Dimensional Sparse Data</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR>Develop a data analysis system based on the Support Vector Machine Approach<BR>
<HR><BR>Support Vector Machine (SVM) classification are based on finding hyper-planes that optimally separate data into distinct classes. By finding these hyper-planes in transformed feature spaces, SVM classifiers are able to easily partition data points that were non-linearly separable in the original feature space.
<br><br>The aim of this project is to implement a scalable support vector machine classifier. This will form the basis of investigating the performance and accuracy of support vector machines in classifying high dimensional sparse data, i.e. where the number of columns is huge in comparison to the number of training instances.
<br><br>
Skills: Implementation must be in C/C++ or Java, Candidate should have an excellent grasp of linear algebra and differential calculus
<br><br>
<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects

<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Interoperability of e-Science Platforms</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR>Investigate the integration of multi platforms for scientific data analysis<BR>
<HR><BR>Kensington and Matlab are two different platforms for scientific analysis. Both systems share a matrix based computation structure and are all well used in scientific data processing and analysis. 
<br><br>
The project is to investigate the approaches and the efficiency of integrating both systems.
<br><br>
Skills: Software Engineering 
<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects


<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Correspondence Analysis for Biological Data</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR>Implement a "Correspondance Analysis Technique" system to find associations between variables in biological data<BR>
<HR><BR>Correspondence Analysis is a multivariate statistical technique for exploring an unknown dataset. Its aim it to find associations between variables. Recently Micro-Array (Gene Chips) technology has produced a large amount of data relating to the expression of genes given a specific stimulus. 
<br><br>
The goal of this project it to implement a Correspondence Analysis system which should include a general purpose correspondence analysis components with an associate visualization mechanism (extension of an existing scatter plot visualizer)
<br><br>
Skills: Java
Student: Any 
<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects

<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Visualization tool for Self Organizing Maps (SOM)</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR>Develop a novel visualization tool for SOM<BR>
<HR><BR>Self-Organizing Map (SOM), is the most popular artificial neural network algorithm in the unsupervised learning category. Self-Organizing Map (SOM),  with its variants, is the most popular artificial neural network algorithm in the unsupervised learning category. Although SOM is widely applicable, the method of visualization the "map" is primitive.
<br><br>This project will address this need by

<OL>
<LI>	Building a new but generic visualisation for viewing models and data in a two dimensional map.
<LI>	Use topology and shapes to encode information such as data clusters and values.
<LI>	Employ intelligent zoom in/zoom out technique for viewing large scale data (ie. allow users to view overall shape of the map and then zoom in for details)
<LI>	Applying your results to a real-life example using data from the bioinformatic area.
<LI>	Extending this concept to support browsing of external but related data.
</OL>
Skills: Java, Java Advanced Imaging (JAI) package, Java2D
<br><br>
<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects



<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Meta-mining: Data mining over data mining procedures</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>Data mining is the process of finding non-trivial actionable patterns from large volumes of data. Data mining practitioners go through different stages of data preparation, modeling and model evaluation in order to find so called 'nuggets' of knowledge. In addition to finding these 'nuggets' analysts are usually interested in understanding and analyzing the processes that led to finding these nuggets. Meta-mining: applying data mining technology to analyze how data mining procedures are conducted. This is a useful, yet underused resource in its own right.


<br><br>This project involves investigating how the process of discovery can itself be mined to gain useful insight. Possible avenues of exploration:
<UL>
<LI>what feature vectors are useful to extract from data mining project descriptions for association rules, clustering, classification analysis

<LI>what useful knowledge can be found from the way user collaborate

<UL>


<br><br>
Visualization may also play a useful part in this kind of analysis.
<br><br>
Technology: Java, XML
<br><br>
Type: Meng/  MAC / MSc
 

<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Active reporting for e-Science applications</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>E-science applications require multiple users to share the analysis and results of scientific data sets across distributed locations. Typical existing methods are based on creating static reports that have limited interactivity. This project involves creating active web-based reports incorporating applets to enable for more interactive presentation of data, models and results for scientific data analysis.
<br><br>
This project will include designing a system to 
<UL>
<LI>	Organize the presentation of scientific data, models and results
<LI>	Transform data analysis and project descriptions in different ways (different HTML output   styles) 
<LI>	Develop interactive applets for visualizing the, models and results and to enable interaction between multiple users.
</UL>
Technology: Java, XML, XSLT
<br><br>
Type: Any


<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Visualization of Large data sets using a Client-Server approach</H2></CENTER>
<B>Supervisor:</B>Peter Au<BR>
<B>Room No.:</B><BR>
<B>E-mail:</B><A HREF="mailto:aktp@doc.ic.ac.uk">aktp@doc.ic.ac.uk</A><BR>
<HR><BR>The objective of the project is to design, develop and investigate the performance of a distributed architecture for interactively visualizing large data set.<BR>
<HR><BR>Visualizing large data is a big challenge, especially when there is a need to conduct interactive data analysis and data mining. The fundamental problem is that the number of data points to be interactively analyzed can be much larger than can be stored in the memory of a desktop machine.
<br><br>
This research project aims to investigate how a client-server approach to the interactive visualization of large data sets can be efficiently implemented. For example, the whole data set can be stored only on a server machine, which can have more memory than available on the client machine than is available on a thin client. In this case, the client needs only to display either a summary of the whole data or the segment of the sub-set of the data in a currently zoomed in area. Both the client and server need to communicate to exchange information about context, data selections and the data currently displayed.
<br><br>
An extension to the project can deal with the more important challenge arising visualizing giga bytes and tera bytes of data. Clearly, even a large server may not have enough memory available to keep such data sets in its memory. In this case, the server implementation needs to be more scalable by using methods that do not load the whole data set in its memory, e.g. by performing the required operations directly on data stored on database or in a file.  
<br><br>
Programming tools: Java and RMI
<br><br>
Level: Any student
<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects

<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Text Mining Tool kit</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR>Develop a toolkit for text mining<BR>
<HR><BR>The increasing amount of available information is well documented. Unfortunately tools to analyze this information are limited to very specific tasks. To gain understanding about large quantities of text "Text Mining" tools can be used. Text mining products can use simple assumptions about text that is not valid in all cases. 
<br><br>
This project aims to build a component based toolkit that can analyze text in a variety of different ways  to support the different tasks found text mining.
<UL>
<LI>	Initial Features includes:
<LI>	Character spectrum
<LI>	Bag of words model
<LI>	NGramm model
<LI>	Stemming and Stopping/Accepting words
</UL>
Skills: Java/C++
<br>
<br>
Type of student: Any

<br><br>
Check <a href="http://ruby.doc.ic.ac.uk/student_projects/">Data Mining Group
Projects</a> for related projects
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Image Mining Tool kit</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR>Design and develop data mining tools for analysisng images<BR>
<HR><BR>If a picture speaks a thousand words - what are the words and can we mine them?. The goal of this project is to be able to transform a set of images from the image domain to a form suitable for data mining. Then data mining tools can be used to extract new nuggets of information from a set of images.
<br><br>
Initial Feaures can include
<UL>
<LI>	Colour Intensity plot.
<LI>    Spectral Plots
<LI>	Extraction of Edge and Corner 
</UL>
Skills: Java/C++
<br><br>
Type of student: Any
 
<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Advanced Signal Analysis in Data Mining</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR>Design and develop data mining tools for signal analysis<BR>
<HR><BR>Spectral Transforms have been applied successfully in many fields of data analysis. But they have so far been underused in data mining. This project involves the application of wavelets and other spectral analysis methods in data mining in the analysis of time series. Using Financial Time series as the raw data it is proposed that wavelets can be used to extract interesting and comparable features so that different stocks can be related and behavior understood.
<br><br>
Skills: Java/C++
<br><br>
Type of student: Any

<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Solving systems of imprecise linear equations</H2></CENTER>
<B>Supervisor:</B>Abbas Edalat<BR>
<B>Room No.:</B>420<BR>
<B>E-mail:</B><A HREF="mailto:ae@doc.ic.ac.uk">ae@doc.ic.ac.uk</A><BR>
<HR><BR>To develop and implement an algorithm to solve for the solution of a system of n linear equations which are given by imprecise coefficients.<BR>
<HR><BR>The classical solution of systems of linear equations is inherently unstable. Small errors in the input coefficients can produce gross errors in the solution. For example, if two lines in the plane are nearly parallel then an input error can produce either no solution, a single solution or an infinite set of solutions. Implemented with floating point arithmetic, such solutions therefore become unreliable. We have recently developed a framework, based on projective geometry and partial orders, for solving linear equations with imprecise coefficients which in the limit gives you the correct solution of classical systems of linear equations. The aim of the project is to develop an algorithm in this framework to find the solution of impercise equations and investigate its feasibility for solving systems fo linear equations. A good background in geometry and linear algebra is required.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Designing geometric objects in CAD: the Minkowski sum</H2></CENTER>
<B>Supervisor:</B>Abbas Edalat<BR>
<B>Room No.:</B>420<BR>
<B>E-mail:</B><A HREF="mailto:ae@doc.ic.ac.uk">ae@doc.ic.ac.uk</A><BR>
<HR><BR>To develop and implement an algorithm to obtain the Minkowski sum, i.e. the offset, of a rational polyhedron with a sphere <BR>
<HR><BR>In all CAD systems, finding the offset (or the Minkowski sum) of a given geometric object with, say, a sphere is inherently unreliable. This non-robustness is caused by the classical framework for geometry which is based on non-continuous and therefore non-computable operations and predicates. We have recently constructed a computable framework for geometry which supports the design of robust algorithms. The aim of the project is to develop and implement a robust algorithm in this framework for the offset of a rational polyhedra in 3d with a shpere. Teh project requires basic mathematical and programming skills.  <BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>A data-type for solving differential equations</H2></CENTER>
<B>Supervisor:</B>Abbas Edalat            <BR>
<B>Room No.:</B>420, Huxley <BR>
<B>E-mail:</B><A HREF="mailto:ae@doc.ic.ac.uk">ae@doc.ic.ac.uk</A><BR>
<HR><BR>To develop and implement a data-type for differential equations
<BR>
<HR><BR>A new theory for solving differential equations using partially
ordered sets has recently been developed. It gives rise to a proper
data-type for differential equations. In particular, it enables us to solve 
differential equations given by partial functions, which are
approximations to totally defined functions. One can obtain
increasingly better approximations to the solution as the input data
is refined. When the differential equation is actually given by a total
function, these approximations converge to the classical solution of
the differential equation. The aim of this project is to develop this
data type further and implement it for some simple differential equations.
<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Basic robust algorithms for computational geometry</H2></CENTER>
<B>Supervisor:</B>Abbas Edalat<BR>
<B>Room No.:</B>420, Huxley<BR>
<B>E-mail:</B><A HREF="mailto:ae@doc.ic.ac.uk">ae@doc.ic.ac.uk</A><BR>
<HR><BR>To implement some basic robust algorithms in computational geometry by 
approximation with rational polyhedra.
<BR>
<HR><BR>Correctness of algorithms in computational geometry is usually proved
using the Real RAM machine model of computation in which real numbers
are treated as floating point numbers. Since this model in
unrealistic, correct algorithms, when implemented, turn into
unreliable programs which can result in logical inconsistency. For
example if the convex hull of a finite number of points in the plane
contains two consecutive edges whose three vertices are nearly
collinear, then a floating point implementation of any algorithm to
obtain the convex hull can fail to output these two edges and instead
output only one or even none of these edges. We have now developed a
proper data-type in solid-modelling and computational geometry which
gives sound and robust, i.e. reliable, algorithms. The idea is to
approximate an object, for example the convex hull, by two sequences
of rational polygons, one approximating the object from its interior
and one approximating it from its exterior. The user can obtain an
approximation to the object up to any desired accuracy. The project
aims to implement some basic algorithms in this setting, including
intersection of lines, and determining the convex hull and the Voronoi
diagram of a finite number of points in the plane. A basic familiarity
with coordinate geometry is required.
<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Boolean and isometric operations on rational polyhedra</H2></CENTER>
<B>Supervisor:</B>Abbas Edalat<BR>
<B>Room No.:</B>420, Huxley<BR>
<B>E-mail:</B><A HREF="mailto:ae@doc.ic.ac.uk">ae@doc.ic.ac.uk</A><BR>
<HR><BR>To develop and implement efficient algorithms for Boolean operations
and simple isometric transformation on rational polyhedra in 2D and 3D.<BR>
<HR><BR>A promising framework for computational geometry and solid-modelling,
under development now at Imperial College, is based on approximating objects
with sequences of rational polyhedra. Operations and transformations
on objects are then reduced to operations and transformations on these
rational polyhedra. This project aims to develop and implement efficient
algorithms for basic Boolean operations, i.e. intersection and union,
as well as simple isometrics, translations and inversions, on rational 
polyhedra in 2D and 3D. Competence in coordinate geometry is required.
<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2> Exact real arithmetic based on the interval [-1,1]</H2></CENTER>
<B>Supervisor:</B>Abbas Edalat<BR>
<B>Room No.:</B>420, Huxley<BR>
<B>E-mail:</B><A HREF="mailto:ae@doc.ic.ac.uk">ae@doc.ic.ac.uk</A><BR>
<HR><BR>To develop and implement algorithms for exact real arithmetic using
linear fractional transformations (lft's) with [-1,1] as its base
interval<BR>
<HR><BR>Floating point computation suffers from the problem of round-off
errors which can accumulate and give a gross error in the end result
of a numerical computation. A framework for exact real number
computation has been developed at Imperial College in the past few
years which overcomes this problem. This enables the user to specify
the accuracy required in the computation of a numerical expression,
and the final result meets this specification. The framework uses
linear fractional transformations (lft's) to encode real numbers and
real functions. It has been based on the base interval [0,infinity],
the nonnegative extended real numbers, in essentially the same way
that the decimal system is based on the interval [0,1] and any other
number can be obtained from one in this interval by multiplication
with a power of 10 and a possible change of sign. A complete C library
of all elementary functions such as tan, log, sin and cos now exists
in this setting. The project aims to change the base interval to
[-1,1] which, one can argue, is a more natural base and is closer to
more standard numeric systems; it may turn out to be more efficient as 
well. The idea is similar to the change of base from say the binary to 
the decimal system. The suitable student will have to be
mathematically competent.
<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Visualization of systems security information</H2></CENTER>
<B>Supervisor:</B>Emil Lupu<BR>
<B>Room No.:</B>564<BR>
<B>E-mail:</B><A HREF="mailto:ecl1@doc.ic.ac.uk">ecl1@doc.ic.ac.uk</A><BR>
<HR><BR>To design a framework and user interface for visualizing security information <BR>
<HR><BR>Security information is difficult to visualise in an effective way because there are multiple facets of a systems security. Interfaces for a single security aspect e.g., file access, secure/unsecured connections can be design. Putting together multiple aspects relating to a system's security, coordinating between different views and different categories of information such as user's authentication, access rights and data integrity is a difficult problem which requires new ideas and solutions. <BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2><b><font color="#990000">3D Representation and Navigation of UML models</font></b></H2></CENTER>
<B>Supervisor:</B>Emil Lupu<BR>
<B>Room No.:</B>564<BR>
<B>E-mail:</B><A HREF="mailto:ecl1@doc.ic.ac.uk">ecl1@doc.ic.ac.uk</A><BR>
<HR><BR>To investigate the use of 3D visualisation for the representation of complex UML models<BR>
<HR><BR><p><font face="Arial, Helvetica, sans-serif">UML has become the standard 
        used in practice for representing software engineering models whether 
        at the conceptual level or at the implementation. There is across the 
        academia and industry a significant push to widen the use of UML in software 
        engineering. This is backed by the <a href="http://www.omg.org">Object 
        Management Group </a>under the name of Model Driven Architectures. </font></p>
      <p><font face="Arial, Helvetica, sans-serif">However, UML diagrams for large 
        numbers of objects are notoriously difficult to represent, navigate and 
        use effectively. This project will investigate the use of 3D rendering 
        techniques for the representation of complex UML diagrams. </font></p>
      <BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>A self-optimising vector/matrix library - run-time fusion and code selection</H2></CENTER>
<B>Supervisor:</B>Paul Kelly<BR>
<B>Room No.:</B>423<BR>
<B>E-mail:</B><A HREF="mailto:phjk@doc.ic.ac.uk">phjk@doc.ic.ac.uk</A><BR>
<HR><BR>Summary: Using a good library allows the programmer to program at a higher
conceptual level, but hides performance optimisation opportunities.&nbsp;
Your job is to fix this using a smart library, that extracts the client
code's dependence structure and builds an optimised implementation of a
whole sequence of library function calls.<BR>
<HR><BR><h4>
Background: the OSCAR project</h4>
One of the major continuing projects in the Software Performance Optimisation
research group is called OSCAR, "Optimising scientific applications at
run-time".&nbsp; The project is based on Olav Beckmann's PhD work, and
this project concerns one of the new directions in which we want to develop
the ideas.
<h4>
Background: Delayed-evaluation, self-optimising libraries</h4>
If you have a large, complex application and you want to enhance its performance
(or solve bigger problems) you have three options:
<ol>
<li>
Use a better compiler.</li>

<li>
Hack the source code</li>

<li>
Replace the key library functions on which the application is based with
faster ones</li>
</ol>
The advantage of the library approach is that minimal changes are needed,
and no damage is done to your application code structure.&nbsp; It only
works if most of the time is spent in library functions - but restructuring
to increase use of libraries is a good idea anyway.&nbsp; The major downside
is that the performance can still be disappointing.
<p>The way to improve performance is to optimise across successive calls
to library functions.&nbsp; This can, in theory, be done by a compiler
- provided the application's structure isn't too messy.&nbsp; Instead,
we advocate optimising across library calls at run-time, within the library
itself.
<p>The idea is that when you call a function, such as a matrix-vector multiply,
the operation isn't executed right-away.&nbsp; Instead, the library returns
a handle representing a recipe for the computation.&nbsp; As execution
proceeds, a sequence - in fact an expression graph - is built up.&nbsp;
When the application finally needs a value (for example in a conditional,
or to print), execution is forced.
<p>At this point, the library code has a representation of what calculations
to do, and how each result will be used.&nbsp; It can exploit this context
information (together, perhaps, with information about the available resources),
to plan the execution.
<p>Olav's thesis was based on the idea that each library function would
be executed in parallel ("data parallelism") across a parallel machines
such as a PC cluster.&nbsp; His optimisation aims to minimise redistribution
of vector and array operands.&nbsp; This project, by contrast, is about
optimising <i>sequential</i> performance (we plan to integrate the results
into the parallel system later).
<h4>
This project</h4>
The goal of this project is to use a similar approach to do loop fusion.&nbsp;
For example, consider a sequence of adjacent library function calls such
as:
<blockquote>B = jacobi1D(A);
<br>norm = sum(B)/B.size();</blockquote>
This results in two (almost) adjacent loops:
<blockquote>for (i=1; i&lt;A.size(); i++)
<br>&nbsp;&nbsp;&nbsp; B[i] = (A[i-1] + A[i+1])/2;
<br>r = 0;
<br>for (i=1; i&lt;B.size(); i++)
<br>&nbsp;&nbsp;&nbsp; r += B[i];
<br>norm = r/B.size();</blockquote>
This code is rather inefficient; we really want to run this:
<blockquote>r = 0;
<br>for (i=1; i&lt;A.size(); i++)
<br>&nbsp;&nbsp;&nbsp; B[i] = (A[i-1] + A[i+1])/2;
<br>&nbsp;&nbsp;&nbsp; r += B[i];
<br>norm = r/B.size();</blockquote>
Your job is to make it so.&nbsp; Luckily we have built some of the component
parts of the solution already.&nbsp; There are various parts to the task:
<ol>
<li>
Start from the C++ bindings for Olav's DESOBLAS library.&nbsp; This provides
a fairly tidy vector/array class and already does delayed evaluation and
allows you to build a data flow graph representing the computation to be
optimised.</li>

<li>
Also start with Alastair Houghton's TaskGraph library.&nbsp; This is a
neat C++ library (based on a 1999-2000 ISE4 project) which makes it easy
to build, manipulate, analyse and compile code at run-time (see ~phjk/OldStudentProjects/AlastairHoughton/TaskGraph).&nbsp;
Alastair's library already includes code to determine whether a pair of
adjacent loops can be fused.</li>

<li>
Modify the vector/array class above so that instead of just building a
graph of delayed function calls, it builds a TaskGraph containing all the
function bodies.&nbsp; Then, when execution is forced, we get the TaskGraph
library to write the entire thing to a file, call the C compiler on it,
and link the resulting binary back into the running application - and run
it.</li>

<li>
Add a hash table to your implementation to maintain a cache of previously-compiled
code - so we don't have to reoptimise and recompile a graph when it recurs
(see how Olav did this).</li>

<li>
Enhance the TaskGraph library's primitive loop fusion so that it handles
non-adjacent loops.</li>

<li>
Evaluate your prototype using various benchmark programs to see how well
it works.</li>

<li>
Extensions, scope for research:</li>

<ol>
<li>
Does the optimisation take a lot of time?&nbsp; Can we save having to reanalyse
each loop in each context?</li>

<li>
Look at cases where loop fusion is possible, but turns out to slow the
code down.&nbsp; Can we avoid this?</li>

<li>
In the example above, the array B may never be used again, so doesn't have
to be written to.&nbsp; Can we exploit this idea?</li>

<li>
Manufacturers of high-performance computers provide hand-optimised implementations
of certain key loops - this can offer a big improvement.&nbsp; Search the
graph for opportunities to use hand-optimised code (algorithms to do this
are used for instruction selection in optimising compilers).&nbsp; Is it
better to forgo a loop fusion opportunity in order to use a hand-optimised
implementation of part of the computation?</li>
</ol>
</ol>

<h4>
Tools</h4>
Olav's library is currently implemented in C, though you are encouraged
to use C++ where appropriate.&nbsp; The main challenges are
<ol>
<li>
Getting to grips with research prototype software (Olav will be on hand
to help)</li>

<li>
Understanding the mathematical framework we use to represent the loop dependence
information</li>
</ol>
The maths is not actually hard - mostly elementary matrix algebra (similar
to the unimodular matrix model of loop execution you may have seen from
the Advanced Computer Architecture course, Ch.5).&nbsp; You will need to
learn a bit about the internals of optimising compilers.
<h4>
Is this project for you?</h4>
This is a challenging project; this is research-level material and if you
are successful and complete the evaluation we hope to publish the results
as a conference paper, with, of course, your name on it.&nbsp; There is
also a significant possibility that people might actually use your code.&nbsp;
You will need substantial experience with C/C++ under Unix and a talent
for programming.&nbsp; This project is especially suitable for JMC and
ISE students because of the mathematical element - but I'm sure good CS
students can figure it out.&nbsp; It's unlikely to be suitable for MSc(Conversion)
students.
<p>
See my home page, <a href="http://www.doc.ic.ac.uk/~phjk">http://www.doc.ic.ac.uk/~phjk</a><BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Task Parallelism in Scientific Linear Algebra Codes</H2></CENTER>
<B>Supervisor:</B>Olav Beckmann<BR>
<B>Room No.:</B>449<BR>
<B>E-mail:</B><A HREF="mailto:ob3@doc.ic.ac.uk">ob3@doc.ic.ac.uk</A><BR>
<HR><BR>Extend an existing parallel linear algebra library to search for and exploit opportunities for using task parallelism.
<BR>
<HR><BR>    <center>
    <h2> Task Parallelism in Scientific Linear Algebra Codes</h2>
      <img src="blurulr6.gif" alt="-----------------------">
    </center>

    <h3>Motivation</h3> 

    <p> We have a library which allows application programmers to
      automatically and more or less transparently execute certain
      computationally intensive parts of scientific programs in
      parallel. This library was initially written with a C interface,
      but, thanks to a recent UROP project, it now also has C++
      interface: 
    </p>

<PRE>
<FONT color=#0000ff>/*</FONT><FONT color=#0000ff> </FONT>
<FONT color=#0000ff> * A is an N-by-N matrix</FONT>
<FONT color=#0000ff> * r, z, p, q, x are N-element vectors</FONT>
<FONT color=#0000ff> * rho, rho_o, beta, alpha and err are scalars </FONT>
<FONT color=#0000ff> */</FONT>
<B><FONT color=#a52a2a>for</FONT></B> ( i = <FONT color=#ff00ff>1</FONT>; i &lt;= max_iter; i++ ) {
  <FONT color=#0000ff>/*</FONT><FONT color=#0000ff> ... */</FONT>
  rho = r * z;
  <B><FONT color=#a52a2a>if</FONT></B> (i == <FONT color=#ff00ff>1</FONT>) { 
    p = z;
  } <B><FONT color=#a52a2a>else</FONT></B> { 
    z = z + (rho / rho_o) * p;
    p = z;
  }

  q = A * p;
  alpha = rho / (p * q);
  x = x + alpha * p;
  r = r - alpha * q;

  err = nrm2(r); <FONT color=#0000ff>/*</FONT><FONT color=#0000ff> Check convergence */</FONT> 
  <FONT color=#0000ff>/*</FONT><FONT color=#0000ff> ... */</FONT> 
}

</PRE>

    <p>This is a cut-down version of a real program that uses the
    non-preconditioned conjugate gradient method to solve the equation
    <i>Ax = b</i> (where <i>x</i> is the unknown vector to be found)
    in parallel.
    </p>

    <p><b>Data Parallelism.</b> Currently, our library only uses the
    data-parallel programming model for achieving parallelism. This
    means that the <em>data</em> is fully distributed (partitioned)
    over all available processors and that computation is then
    performed according to the &quot;owner computes&quot; rule: each
    processor computes that part of the overall data that it owns
    according to the manner in which the data has been
    distributed. (Not all data-parallel programs use the owner
    computes rule, but the principle that the data is fully
    distributed is always the same.) In the data-parallel programming
    model, it is therefore generally true that all processors will at
    any one point in time be working on the same operation, such as
    the vector update <code>x = x + alpha * p</code> (except that some
    may be idle). The advantage of this is that it is a relatively
    easy parallel programming model to reason about; the drawback is
    that it can sometimes (often??) be sub-optimal. </p>

    <p><em>Optimising Data-Parallel Programs.</em> The performance of
      data-parallel programs is almost completely determined by any
      inter-processor communication that is required. It is possible
      to minimise the cost of such communications by carefully
      choosing the data placements used. Our existing library performs
      such data placement optimisation. This is based on 
    <ol>
      <li>Using delayed evaluation to capture
	the data-flow graph of library operations before they are
	executed 
      <li>A mathematical model of data placement
      <li>A mathematical model of the placement requirements of
	data-parallel operations
      <li>A very simple cost model for any communications that are
	required
      <li>A simple search algorithm that tries to find such data
	placements that minimise the overall cost of communication. 
    </ol>
    </p>

    <p><b>Task Parallelism.</b> On more careful inspection, it is
    clear that the operations <code>x = x + alpha * p;</code> and
    <code> r = r - alpha * q;</code> in the above program are in fact
    independent, and could therefore, provided we have a suitable
    processor configuration, be executed <em>in parallel with each
    other</em>, as well as each being parallel operations
    themselves. In order to achieve this, we would have to place
    <code>x</code> and <code>r</code> on disjoint sets of
    processors. </p>

    <p><em>Optimising Task-Parallel Programs. </em> The issues
      involved in optimising task-parallel programs are wider than in
      the data-parallel case: 
    <ol>
      <li>We need to search the data-flow graph of library operations
	for independent sections. 
      <li>We need a model not only of the cost of communication, but
	also of the cost of the actual operations in order to be able
	to balance the amount of time each independent computation
	takes. 
      <li>We may have to extend our current model of data placement in
	order to place the data involved in independent computations
	on distinct processor groups. 
    </ol>


    <h3>The Task</h3>
    
    <p> <strong>Extend our existing parallel linear algebra library to
    search for and exploit opportunities for using task
    parallelism. </strong>
      
    <ul>
      
      <li> <p>Install and use our existing data-parallel library,
      understand how the delayed evaluation system works and how
      data-flow of parallel operations is stored internally. </p>
	
      <li><p>Develop a model for the computation cost of operations;
      investigate whether this could be transparently determined at
      runtime, rather than having to be provided beforehand.</p>
      
      <li><p>Search data-flow graphs for possible task parallelism,
      check for load balance (Optimising load balance is very complex
      and possibly not that interesting - what we want to do is make
      sure that we do not make anything worse by introducing task
      parallelism.)</p>

      <li><p>Possibly extend the current model of the parallel
      platform and/or the current model of data placement in order to
      generate data placements that make task-parallel execution of
      independent operations possible. </p>

      <li><p>Evaluate your work using various benchmarks.</p>

    </ul>
    </p>

<p>This is a research-level project with enormous potential for
extending the work. To do this project, you must not be scared to pick
up and work with an existing software system, and you must have a
reasonably good understanding of basic linear algebra in order to work
with the existing data placement representation.

<p align="center"> 
<img src="blurulr6.gif" alt="--------------------"> </p>

<p align="right">
Olav Beckmann <br>
<!-- hhmts start -->
Last modified: Tue Oct  2 17:12:30 BST 2001
<!-- hhmts end -->
</p>
<br>


<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Extending Fickle</H2></CENTER>
<B>Supervisor:</B>Sophia Drossopoulou<BR>
<B>Room No.:</B>559<BR>
<B>E-mail:</B><A HREF="mailto:scd@doc.ic.ac.uk">scd@doc.ic.ac.uk</A><BR>
<HR><BR>Extend an experimental object oriented language which supports objects changing class.
 
<BR>
<HR><BR>
In a recent paper, we designed a language and type system which would allow objects to change their class at run-time. Thus, an object of class "EmptyStack" might at run-time become a "NonEmptyStack" object, or a "GoldenPlusAccount" object might become an "OverdrawnAccount" object.
<br> <br>

More on fickle objects can be found at http://www.di.unito.it/~damiani/papers/dor.html.
<br><br>

In this project we will aim to extend Fickle to fit a larger language which supports  more features, e.g. constructors, threads and non-mutable types.
<br><br>

The course "Advanced Issues in Object Oreinted Programming", from  http://www.doc.ic.ac.uk/~scd/Teaching/AdvOO.html will give necessary foundations to that project.

<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2></H2></CENTER>
<B>Supervisor:</B><BR>
<B>Room No.:</B><BR>
<B>E-mail:</B><A HREF="mailto:scd@doc.ic.ac.uk">scd@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>

The tool should consist of 

     a data base of PhD students containing all appropriate data (e.g. name, supevisor, room number, data of registration, date of
     submission of three month report, date of MPhil to PhD transfer, etc etc) 
     PhD students go through a lifecycle of events, which are expected to happen at certain times, and which need to happen in certain
     order. The database should keep track of the events per student. 
     The databse needs to reflect (and treat differently) the status of the student (part time vs full time) and the leaves of absence taken by
     student 
     different views onto the data base (e.g. supervisors only see state of their students, the head of the department sees all students, the
     postgraduate tutor may modify all entries) 
     consideration of related security issues 
     report generation and consistency checks 
     automatic generatation of email depending on students' status (e.g. send email requesting submission of the three month report, or
     send email to supervisors requesting submission of the EPSRC report) 
     population of the data base out of data already existing in textual form of specified format. 

There exists already a version of such a tool, and the students are expected to improve its functionality, although they do not need to use the
same rechnology. 

An advanced version of the tool will address issues around dynamic modification of the database, eg the possibility to add events to the the
students' lifecycle.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Design and analysis of secure programming environments.</H2></CENTER>
<B>Supervisor:</B>Michael Huth<BR>
<B>Room No.:</B>435<BR>
<B>E-mail:</B><A HREF="mailto:mrh@doc.ic.ac.uk">mrh@doc.ic.ac.uk</A><BR>
<HR><BR>To learn about formal approaches in the design and analysis of secure communicating systems. To be able to implement a semantic analysis of
program or protocol security.<BR>
<HR><BR>Please contact Michael Huth for further project details.<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Computer Vision, Perceptual Intelligence, Image Processing, Multimedia Applications (see http://www.doc.ic.ac.uk/~gzy for details)  </H2></CENTER>
<B>Supervisor:</B>Guang-Zhong Yang<BR>
<B>Room No.:</B>306<BR>
<B>E-mail:</B><A HREF="mailto:gzy@doc.ic.ac.uk">gzy@doc.ic.ac.uk</A><BR>
<HR><BR>Computer Vision, Perceptual Intelligence, Image Processing, Multimedia Applications <BR>
<HR><BR>Computer Vision, Perceptual Intelligence, Image Processing, Multimedia Applications (see http://www.doc.ic.ac.uk/~gzy for details)<BR>
<HR><B>Level:</B>Any student<BR>
<HR>
<CENTER><H2>Soundness of the C++ Type System</H2></CENTER>
<B>Supervisor:</B>Sophia Drossopoulou<BR>
<B>Room No.:</B>559<BR>
<B>E-mail:</B><A HREF="mailto:scd@doc.ic.ac.uk">scd@doc.ic.ac.uk</A><BR>
<HR><BR>Model a substantial subset of
 C++  and prove soundness of its type system.<BR>
<HR><BR>C++ has a powerful and complex type system, which allows for dynamic binding, polymorphism, licit type conversions,
references and pointers, and combines these with type checking and efficient programming support. The aim of the project
is to produce a formal proof of the soundness of the type system; ie that in a type correct program at run run-time all
variables would contain values of the type predicted by the compiler. The
C++ type system is especially interesting in what concerns the use of
pointers and arrays.
<p>
Proving soundness of C++ is a relavant, and non-trivial aim: for
example, the type system of Eiffel, a highly successful and relatively simple oo programming language, has been
discovered not to be sound, a couple of years after the development of the language. 
<p>
The project would start with the
selection of an appropriate subset of C++ to reflect the important issues to do with typing and binding. This would be
expressed in an appropriate object calculus (several object calculi to describe oo programming have been developed
recently) to describe the operational semantics of this C++ subset. 
Then aim to prove the soundness theorem, stating that
evaluation of C++ terms yields objects of a subclass of the class predicted by the type checker. 
<p>
Good mathematical skills
and enthusiasm are prerequisite. Attendance to the Semantics course and knowledge of C++ would be helpful but not
indispensable. 
<p>
A paper, dealing with the Java type system, can serve as initial guidance: Sophia Drossopoulou and Susan
Eisenbach: Is the Java Type System Sound?,
and can be found  
<a href="http://www-dse.doc.ic.ac.uk/projects/slurp/pubs.html">
at http://www-dse.doc.ic.ac.uk/projects/slurp/pubs.html<a>.
Also, at <a href="http://www.doc.ic.ac.uk/~scd/Teaching/AdvOO.html">
Sophia's teaching page</a> there is some relvant material for that
topic. This project has been attempted by an MSc student from 2000-2001.<BR>
<HR><B>Level:</B>Both<BR>
<HR>
<CENTER><H2>Quantum Computing</H2></CENTER>
<B>Supervisor:</B>Iain Stewart<BR>
<B>Room No.:</B>372 Huxley<BR>
<B>E-mail:</B><A HREF="mailto:ids@doc.ic.ac.uk">ids@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR><p>You're nearly there...</p>

<p>
The project proposals database used to allow pasting in of whole web pages,
but now it doesn't (or is hopelessly erratic about it anyway).
So you'll just have to go to my "proper" quantum computing project page, with one more click:
</p>

<a href="http://www.doc.ic.ac.uk/~ids/dotdot/misc/projects/QuantumComputing/proposal.html">http://www.doc.ic.ac.uk/~ids/dotdot/misc/projects/QuantumComputing/proposal.html</a><BR>
<HR><B>Level:</B>Both<BR>
<HR>
<CENTER><H2>Annotating the web</H2></CENTER>
<B>Supervisor:</B>Iain Stewart<BR>
<B>Room No.:</B>372 Huxley<BR>
<B>E-mail:</B><A HREF="mailto:ids@doc.ic.ac.uk">ids@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR><p>You're nearly there...</p>

<p>
The project proposals database used to allow pasting in of whole web pages,
but now it doesn't (or is hopelessly erratic about it anyway).
So you'll just have to go to my "proper" annotating the web project page, with one more click:
</p>

<a href="http://www.doc.ic.ac.uk/~ids/dotdot/misc/projects/AnnotatingTheWeb/proposal.html">http://www.doc.ic.ac.uk/~ids/dotdot/misc/projects/AnnotatingTheWeb/proposal.html</a><BR>
<HR><B>Level:</B>Both<BR>
<HR>
<CENTER><H2>Artificial Life</H2></CENTER>
<B>Supervisor:</B>Iain Stewart<BR>
<B>Room No.:</B>372 Huxley<BR>
<B>E-mail:</B><A HREF="mailto:ids@doc.ic.ac.uk">ids@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR><p>You're nearly there...</p>

<p>
The project proposals database used to allow pasting in of whole web pages,
but now it doesn't (or is hopelessly erratic about it anyway).
So you'll just have to go to my "proper" artificial life project page, with one more click:
</p>

<a href="http://www.doc.ic.ac.uk/~ids/dotdot/misc/projects/ArtificialLife/proposal.html">http://www.doc.ic.ac.uk/~ids/dotdot/misc/projects/ArtificialLife/proposal.html</a><BR>
<HR><B>Level:</B>Both<BR>
<HR>
<CENTER><H2>Conquest - the Strategy Game of Dice</H2></CENTER>
<B>Supervisor:</B>Iain Stewart<BR>
<B>Room No.:</B>372 Huxley<BR>
<B>E-mail:</B><A HREF="mailto:ids@doc.ic.ac.uk">ids@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR><p>You're nearly there...</p>

<p>
The project proposals database used to allow pasting in of whole web pages,
but now it doesn't (or is hopelessly erratic about it anyway).
So you'll just have to go to my "proper" Conquest project page, with one more click:
</p>

<a href="http://www.doc.ic.ac.uk/~ids/dotdot/misc/projects/Conquest/proposal.html">http://www.doc.ic.ac.uk/~ids/dotdot/misc/projects/Conquest/proposal.html</a><BR>
<HR><B>Level:</B>Both<BR>
<HR>
<CENTER><H2>Current Proposals</H2></CENTER>
<B>Supervisor:</B> Ian Harries<BR>
<B>Room No.:</B> 360<BR>
<B>E-mail:</B><A HREF="mailto: ih@doc.ic.ac.uk"> ih@doc.ic.ac.uk</A><BR>
<HR><BR>My projects involve

<p>
<ul>
<li>Communications and multimedia
<p>

<li>Interfacing and real-time control
</ul>
</p>
<!--
<p>
<b>BEng/MEng and MSc(Conversion) only</b>
</p>
--><BR>
<HR><BR><p>
Go to my
<a href="http://www.doc.ic.ac.uk/~ih/teaching/projprop.html">
Project Proposals Page</a>
for full details
</p><BR>
<HR><B>Level:</B>Both<BR>
<HR>
<CENTER><H2>Object-oriented hardware design, computer arithmetic, custom computing, and Internet technology</H2></CENTER>
<B>Supervisor:</B>Oskar Mencer            <BR>
<B>Room No.:</B><BR>
<B>E-mail:</B><A HREF="mailto:oskar@doc.ic.ac.uk">oskar@doc.ic.ac.uk</A><BR>
<HR><BR>A list of projects is 
<A HREF="http://www.doc.ic.ac.uk/~oskar/projects.html">here</A>.

<BR>
<HR><BR>Please check my list above to get an idea what kind of projects I am 
interested in. I am also open to suggestions. <BR>
<HR><B>Level:</B>Both<BR>
<HR>
<CENTER><H2>Projects in the areas of Databases and/or Finance </H2></CENTER>
<B>Supervisor:</B>James Jacobson          <BR>
<B>Room No.:</B>440, Huxley <BR>
<B>E-mail:</B><A HREF="mailto:jj@doc.ic.ac.uk">jj@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>Students with an interest in these areas are welcome to come and discuss their ideas with me.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Graphical Term Graph Rewriting</H2></CENTER>
<B>Supervisor:</B>Steffen van Bakel       <BR>
<B>Room No.:</B>425, Huxley <BR>
<B>E-mail:</B><A HREF="mailto:svb@doc.ic.ac.uk">svb@doc.ic.ac.uk</A><BR>
<HR><BR>To develop a system that graphically represents execution of a functional program.<BR>
<HR><BR>A well studied implementation framework for functional programming languages is that of term graph rewriting.  Using this tool, the project aims to represent programs as graphs, and to mimic the execution of a program be graph manipulation.  This projects result should run on the web. It requiers knowledge of writing applets, parsers, graphics and compiler construction.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Web based system for type-checking functional programs</H2></CENTER>
<B>Supervisor:</B>Steffen van Bakel       <BR>
<B>Room No.:</B>425, Huxley <BR>
<B>E-mail:</B><A HREF="mailto:svb@doc.ic.ac.uk">svb@doc.ic.ac.uk</A><BR>
<HR><BR>To develop a parser and type check algorithms for funtional programming languages.<BR>
<HR><BR>For functional programming languages, many type systems are proposed and implemented, like the Hindley-Milner polymorphic system for ML, intersection types, subtypes. A Web tool will be developed that gives the user the opportunity to insert a program and have it type-checked against the type system chosen. This project involves writing a parser and implementing (existing) type check algorithms.<BR>
<HR><B>Level:</B>Both<BR>
<HR>
<CENTER><H2></H2></CENTER>
<B>Supervisor:</B><BR>
<B>Room No.:</B><BR>
<B>E-mail:</B><A HREF="mailto:"></A><BR>
<HR><BR><BR>
<HR><BR><BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Computer Graphics</H2></CENTER>
<B>Supervisor:</B>Duncan Gillies<BR>
<B>Room No.:</B>306a, Huxley<BR>
<B>E-mail:</B><A HREF="mailto:dfg@doc.ic.ac.uk">dfg@doc.ic.ac.uk</A><BR>
<HR><BR>Building Graphics Applications<BR>
<HR><BR>I have a variety of bio-medical visualisation problems which would be of interest to those who like graphics. I'm also happy to discuss students ideas for graphics based projects.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Music learning program</H2></CENTER>
<B>Supervisor:</B>Iain Phillips<BR>
<B>Room No.:</B>427, Huxley<BR>
<B>E-mail:</B><A HREF="mailto:iccp@doc.ic.ac.uk">iccp@doc.ic.ac.uk</A><BR>
<HR><BR>Write a program which learns how to compose.<BR>
<HR><BR>The most ambitious goal would be to write a program to learn harmony in the
style of say Palestrina, somewhat on the lines of programs which learn
successful strategies in games such as Othello. One could see for instance
whether the program could learn to avoid consecutive fifths or doubled
thirds. In fact the project could be angled in a number of directions: as
an expert system, as a program for marking students' compositions, as a
program which would harmonise a given melody or even produce its own
"compositions".
.<BR>
<HR><B>Level:</B>Both<BR>
<HR>
<CENTER><H2>Ear training program</H2></CENTER>
<B>Supervisor:</B>Iain Phillips<BR>
<B>Room No.:</B>427, Huxley<BR>
<B>E-mail:</B><A HREF="mailto:iccp@doc.ic.ac.uk">iccp@doc.ic.ac.uk</A><BR>
<HR><BR>Create a program to help students of music with ear training.<BR>
<HR><BR><P>Create a program to help students of music with ear training.
Features could include
<UL>
<LI>interval recognition
<LI>sharp/flat note recognition
<LI>cadence recognition
<LI>modulation recognition
<LI>random exercises
<LI>different levels of difficulty
<LI>the program discovers where the student's weak spots are, and
concentrates on these.
</UL>
<BR>
<HR><B>Level:</B>Both<BR>
<HR>
<CENTER><H2>Statement of interests</H2></CENTER>
<B>Supervisor:</B>Iain Phillips<BR>
<B>Room No.:</B>427<BR>
<B>E-mail:</B><A HREF="mailto:iccp@doc.ic.ac.uk">iccp@doc.ic.ac.uk</A><BR>
<HR><BR>I am interested in projects in areas such
as concurrency, world-wide web, security, music, algorithm analysis; and in
projects with a logical or mathematical content in general.<BR>
<HR><BR><A HREF='http://www.doc.ic.ac.uk/~iccp/projects'>More information</A><BR>
<HR><B>Level:</B>Both<BR>
<HR>
<CENTER><H2>Hardware/Software Partitioning of C Programs</H2></CENTER>
<B>Supervisor:</B>Markus Weinhardt<BR>
<B>Room No.:</B>48186<BR>
<B>E-mail:</B><A HREF="mailto:mw8@doc.ic.ac.uk">mw8@doc.ic.ac.uk</A><BR>
<HR><BR>The objective of this project is to partition a program in software and hardware parts for a hardware compiler. Program loops must be analysed in order to decide if they can be accelerated by FPGA-based reconfigurable coprocessors. The partitioner will be used in a codesign system which is currently being developed using the flexible compiler framework SUIF.<BR>
<HR><BR>The project includes the development and implementation of the following main stages: 
- develop hardware area estimates to assess the feasibility of a hardware implementation 
- develop hardware timing estimates and software runtime estimates (profiling or static analysis) 
- use these estimates to select useful loops for hardware implementation
- devise methods to communicate the results to subsequent compiler passes 

Prerequisites include: C or C++ programming knowledge; experience (or at least interest in) UNIX/Linux; and willingness to learn about and use the SUIF compiler framework. Background knowledge of compiler construction and hardware design will be useful, but not necessary. 

More projects in the area of hardware compilation are available (see http://www.doc.ic.ac.uk/~wl/icprojects/msc.html), and they can be adjusted to a student's individual interests.<BR>
<HR><B>Level:</B>Both<BR>
<HR>
<CENTER><H2>PORTFOLIO OPTIMIZATION WITH DOWNSIDE RISK</H2></CENTER>
<B>Supervisor:</B>Berc Rustem<BR>
<B>Room No.:</B>307b<BR>
<B>E-mail:</B><A HREF="mailto:br@doc.ic.ac.uk">br@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>Optimal portfolios are normally computed using the portfolio risk measured in terms of its variance. This implies that the risk to be guarded against is symmetric. However, performance risk is a problem if the portfolio may not perform well. This involves the extension of the quadratic optimization procedure to define and handle downside risk only.

Tools: Quadratic programming software. 

     To be developed: A return model for FTSE100 stocks (such as CAPM),
the evaluation of
     historical covariance and forecast covariance. The evaluation of
historical scenarios to be used in
     determining the downside risk. A visual tool to display, the
mean-variance, risk-return frontier.
     When you click on the frontier, the corresponding portfolio should
be displayed. 

     Languages: C or Fortran for connecting with optimization software. 

     References: Elton & Gruber: Modern Portfolio Theory; D. Luenberger:
Investment Science; D.
     Luenberger: Linear & Nonlinear Programming; D. Bertsekas: Nonlinear
Programming; papers to
     be given. 

     <BR>
<HR><B>Level:</B>Both<BR>
<HR>
<CENTER><H2>COMPUTING INTERNATIONALLY DIVERSIFIED PORTFOLIOS</H2></CENTER>
<B>Supervisor:</B>Berc Rustem<BR>
<B>Room No.:</B>307b<BR>
<B>E-mail:</B><A HREF="mailto:br@doc.ic.ac.uk">br@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>Project Description: When exchange rate risk is considered
separately from the return risk in a
     given currency, we need to construct portfolios that can take
account of both sources of risk. This
     can be done by extending the classical mean-variance structure. The
rest of the details are similar
     to the one-sided risk project.<BR>
<HR><B>Level:</B>Both<BR>
<HR>
<CENTER><H2>PARALLELISATION STRATEGY FOR OPTIMIZATION ALGORITHMS</H2></CENTER>
<B>Supervisor:</B>Berc Rustem<BR>
<B>Room No.:</B>307b<BR>
<B>E-mail:</B><A HREF="mailto:br@doc.ic.ac.uk">br@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>Project Description: The main parallelisation strategy is to assign
the optimization of part of the
     problem to each processor while making sure that these parallel
executions do not go too far down
     the road at any stage. Thus the parallel algorithm penalizes
departure from the current point so that
     a little progress is assured on each processor at every iteration.
The project is concerned with this
     basic strategy but may also involve the implementation of fully
specified simple optimization
     algorithms to test their parallelisation 

     Tools: quadratic programming software to be used as the solver of
subproblems. 

     Language: C or Fortran 

     Equipment: Fujitsu AP3000 

     Students must be familiar with numerical computing. 

     References:D. Bertsekas: Nonlinear Programming; Bertsekas and
Tsitsiklis: Parallel and
     Distributed Computing; other papers will be provided.<BR>
<HR><B>Level:</B>Both<BR>
<HR>
<CENTER><H2>Two-person and n-person games</H2></CENTER>
<B>Supervisor:</B>Berc Rustem<BR>
<B>Room No.:</B>307B<BR>
<B>E-mail:</B><A HREF="mailto:Br@doc">Br@doc</A><BR>
<HR><BR><BR>
<HR><BR><BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Parallel implementation of a Branch and Cut algorithm</H2></CENTER>
<B>Supervisor:</B>Berc Rustem<BR>
<B>Room No.:</B>307a, Huxley<BR>
<B>E-mail:</B><A HREF="mailto:br@doc.ic.ac.uk">br@doc.ic.ac.uk</A><BR>
<HR><BR>To design, implement and evaluate the performance of a Branch and Cut algorithm on a parallel computer.<BR>
<HR><BR>Branch and Cut  is a combination of Branch and Bound and Cutting Plane methods. It is a very efficient method for solving Mixed Integer Linear Programming (MILP) problems arising in many areas of Finance, Management Science and Engineering. The project involves the design and implementation of an existing sequential Branch and Cut algorithm on a parallel computer. The implementation will be tested on some MILP test problems which will be input using an existing algorithm. The evaluation of the performance of the Branch and Cut algorithm will also be addressed. Useful prerequisites include: C, Parallel Computing
and Operations Research.<BR>
<HR><B>Level:</B>Both<BR>
<HR>
<CENTER><H2>Visualisation for medical data analysis</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375, Huxley<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR>Develop visualisation tool for analysing medical data<BR>
<HR><BR>The aim of the project is to develop a new and innovative visualisation module
for analysing cancer-related medical data. Student will gain experience in 
genome data analysis and will work closely with researchers from the Imperial Cancer Research Fund. 
	
The best starting point is to extend a popular tool called "parallel coordinates".
(see http://atkosoft.com/parcovi1.htm)
	
Programming tools: Java<BR>
<HR><B>Level:</B>Both<BR>
<HR>
<CENTER><H2>Java, Databases, ODBC and everything!</H2></CENTER>
<B>Supervisor:</B>Stuart Cox<BR>
<B>Room No.:</B>357, Huxley<BR>
<B>E-mail:</B><A HREF="mailto:smc@doc.ic.ac.uk">smc@doc.ic.ac.uk</A><BR>
<HR><BR>To explore the implementation, peformance and practicalities of implementing a variety of front ends to a high performance database.<BR>
<HR><BR>High performance, robust SQL databases are one of the biggest commercial uses of computing. Extracting, displaying and modifying the data is usually (but not always) done through Front End applications running on remote machines, possibly very remote! This project examines a number of important issues with regard to distributing information in this way.

In essence, the student(s) will be required to implement a realistically large database on some suitable SQL engine. Front ends using a variety of techniques will then be constructed to demonstrate the technology and to provide a framework for establishing performance metrics. In particular, Java (through JDBC and ODBC), Web based (again through JDBC), Office (Access & Excel through ODBC) and "other" (ie C++ or Delphi) front ends will be built and tested.

If you want a project "relevant to the commercial world" this is it! BUT be warned, this is NOT for the faint hearted!!!!<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Program Analysis</H2></CENTER>
<B>Supervisor:</B>Chris Hankin<BR>
<B>Room No.:</B>420<BR>
<B>E-mail:</B><A HREF="mailto:clh@doc.ic.ac.uk">clh@doc.ic.ac.uk</A><BR>
<HR><BR>To implement algorithms for program analysis.<BR>
<HR><BR>I am currently finishing a manuscript on program analysis techniques.  It
contains a number of project suggestions, ranging from implementations to
theoretical investigations.  I would be willing to supervise up to 5 projects
in this area.  The specific nature of individual projects will be a matter for
negotiation.<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Down-hole Data Mining</H2></CENTER>
<B>Supervisor:</B>Martin Kohler<BR>
<B>Room No.:</B>362<BR>
<B>E-mail:</B><A HREF="mailto:mk@doc.ic.ac.uk">mk@doc.ic.ac.uk</A><BR>
<HR><BR>A wide range of instruments are used in the wellbore to measure physical 
properties of reservoir formations. These measurements provide essential 
information about the in situ rock and fluid properties necessary for field 
development planning and reservoir management. 
Analysis of the data from different sources, and often reflecting various 
length scales, is important for optimising the oil and gas production.<BR>
<HR><BR>In this collaborative project between the TH Huxley School and the Department of 
Computing, we will employ data mining techniques to analyse "down-hole" 
data obtained from well logs.  The project will have access to real sensor 
data provided by industrial partners. The results will be compared against findings from other analytical techniques.

<p>
The project will use the Data Mining Group's enterprise data mining system and 
other tools as required. 

<p>
A candidate from either the Department of Computing or TH Huxley School with 
strong analytical capabilities.  Candidates from Computing should have a 
background in machine learning/data mining; candidates from TH Huxley 
School should have knowledge of the down-hole environment and measurement 
physics.  In either case, an understanding of statistical methods would be beneficial.

<p>
The interdisciplinary training will be provided by staff from both departments. The collaborators are, in Computing, Yike Guo (yg@doc.ic.ac.uk), Martin Kohler (mk@doc.ic.ac.uk), and at TH Huxley School: Xudong Jing (x.jing@ic.ac.uk)<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Real Time Data Mining for Managing Distributed Information Systems</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR>Problem: Consider a large organisation with a distributed information system running over a networked computing environment consisting of thousands computers distributed all over the world.
This is not a fiction. In an investment bank such as J.P. Morgan, a trading system contains more than five thousands machines.  How could one manage such a system?  Do you think the conventional way of system administration can still work?
<BR>
<HR><BR>Approach: Data mining is a new technology of automatically discovering useful patterns in large databases. This technology could be applied to managing distributed information systems resulting in a new approach of system administration. Imagine that the system is managed by a set of agents that check and report to a central database the system status from time to time. This system status data is accumulated and then analysed to detect any system problems. More importantly, by applying machine learning technology, important correlation among the system errors can be discovered. The impact of such an intelligent system administration is not hard to imagine.

<p>
Project: Design a framework of such an intelligent system administration system and build up a system prototype.

Supervisors/collaborators: Dr. Yike Guo, Prof. Darlington and Mr. Stefan Hedvall <BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>High Performance Text Search Engine</H2></CENTER>
<B>Supervisor:</B>Yike Guo<BR>
<B>Room No.:</B>375<BR>
<B>E-mail:</B><A HREF="mailto:yg@doc.ic.ac.uk">yg@doc.ic.ac.uk</A><BR>
<HR><BR>Problem:  You must know Yahoo or  Altavista. So you must know what a text search engine is, it indexes the words of documents, ranking the important words so that you can find documents when giving key words.<BR>
<HR><BR>Approach:  Text indexing is a very well researched area. There are quite a lot of efficient algorithms. This project is concerned with applying some of them to build up a simple but efficient text search engine for an enterprise knowledge management system.

<p>
Collaborators: Dr. Yike Guo and Dr. Stefan Ruger (smr3@doc.ic.ac.uk)<BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<CENTER><H2>Animated Turing Machine</H2></CENTER>
<B>Supervisor:</B>Margaret Cunningham<BR>
<B>Room No.:</B>422 Huxley<BR>
<B>E-mail:</B><A HREF="mailto:mrc@doc.ic.ac.uk">mrc@doc.ic.ac.uk</A><BR>
<HR><BR><BR>
<HR><BR>

To produce a Turing machine teaching and demonstration system. 

This is an application project whose aim is to provide a working tool which permits exploration of turing machine operation.
This could be used for demonstration purposes in the second year Algorithms course. A basic 1-tape system prototype
followed by various extensions and enhancements is envisaged. The platform/language etc. to be determined as part of the
initial investigation stage. <BR>
<HR><B>Level:</B>Undergraduate<BR>
<HR>
<A HREF="/~sjn5/docpp/">Back to main page</A><BR><A HREF="http://www.doc.ic.ac.uk/~sjn5/docpp/cgi-bin/listall.cgi?level=Undergraduate">New Search</A>
</body></html>